{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "LendingClub_Modelling_NN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yGjgpGCgpuGo",
        "JgN02Qv6uL3Z",
        "Q69vPaiYuL4w",
        "sQtfx4aLuL5H",
        "mUw3-AWSDwU7",
        "Px6dGmZ0adRu",
        "iuxlyilDjSBh",
        "gvbpY9UcuL66",
        "opUlmJ483eyg",
        "7xtHwW2d4GwP",
        "GkRoBeOtHYUg",
        "B0OiB3NFkJfm",
        "wlo3xTdkKycH"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT_Pt3HMo2NT",
        "colab_type": "text"
      },
      "source": [
        "#Import Required Methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lWwzaW0uL0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import mean\n",
        "\n",
        "import datetime as dt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Sklearn\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, RepeatedStratifiedKFold, cross_validate, GridSearchCV,\\\n",
        "StratifiedKFold\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler, StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, SGDClassifier\n",
        "from sklearn.utils import resample, class_weight\n",
        "from sklearn.metrics import precision_recall_curve, auc, make_scorer, average_precision_score, accuracy_score,\\\n",
        "recall_score, precision_score, f1_score, roc_curve, balanced_accuracy_score, roc_auc_score, classification_report, confusion_matrix,\\\n",
        "brier_score_loss\n",
        "\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.under_sampling import RandomUnderSampler\n"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VkgAxq-eIsv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Imports for Neural Network.\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import models, layers, applications, optimizers, regularizers\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dropout\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHJaev8hpE-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Access files from Google Drive"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nfj_pr8apY2L",
        "colab_type": "text"
      },
      "source": [
        "# Global Parameters, Options, and Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2dujdcfbuN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Global parameter for setting randon_state in various methods.\n",
        "rs = 0"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tDXv_VTuL1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "pd.options.display.max_rows = 200"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1zFbNZ2uL1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Numerical features used in modelling.\n",
        "numModCol = ['acc_open_past_24mths', 'annual_inc', 'avg_cur_bal', 'bc_open_to_buy', 'credit_hist_months',\n",
        "            'dti', 'fico', 'inq_last_6mths', 'installment', 'mo_sin_rcnt_rev_tl_op',\n",
        "            'mo_sin_rcnt_tl', 'mort_acc', 'mths_since_recent_bc', 'num_actv_rev_tl', 'num_tl_op_past_12m', \n",
        "            'open_acc', 'percent_bc_gt_75', 'pub_rec', 'revol_bal', 'total_rev_hi_lim', 'int_rate']\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPljlSd1uL1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Categorical features used in modelling.\n",
        "catModCol = ['term', 'purpose', 'emp_length', 'home_ownership', 'verification_status', 'grade']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8whTG8MpSgy",
        "colab_type": "text"
      },
      "source": [
        "# Access files from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUc_XHNMJ576",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "a83f5b3b-f4c6-41cb-d95b-522370fbd850"
      },
      "source": [
        "#Get access to Google Drive where files are stored.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True) "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHq-Q8UYKC-8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "193be148-4290-4af0-8c24-ba040dba7da2"
      },
      "source": [
        "#Switch directory in Google Drive.\n",
        "%cd /content/gdrive/My Drive/MRP/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/MRP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmUmLcIzuL2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load pickled dataframe.\n",
        "dfFinal = pd.read_pickle('dfFinalPickleColab.pkl')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJ5mKpEYuL2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dataframe with just the model features.\n",
        "dfModel = dfFinal[numModCol+catModCol]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGjgpGCgpuGo",
        "colab_type": "text"
      },
      "source": [
        "# Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCxOmQmbuL24",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "outputId": "e4db882d-0202-4b77-b537-402eeed9fb3f"
      },
      "source": [
        "#Columns with missing values and percentage of instances containing them that need to be addressed.\n",
        "dfMissing = pd.DataFrame((dfModel.isna().sum() / dfModel.shape[0] * 100)[dfModel.isna().sum() > 0])\n",
        "dfMissing.index.name = 'Feature'\n",
        "dfMissing.columns = ['Instance %']\n",
        "dfMissing = dfMissing.round(3)\n",
        "dfMissing = dfMissing.sort_values(by = ['Instance %'])\n",
        "dfMissing"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Instance %</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Feature</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>dti</th>\n",
              "      <td>0.004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>acc_open_past_24mths</th>\n",
              "      <td>4.250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mort_acc</th>\n",
              "      <td>4.250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mths_since_recent_bc</th>\n",
              "      <td>5.171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bc_open_to_buy</th>\n",
              "      <td>5.239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>percent_bc_gt_75</th>\n",
              "      <td>5.275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mo_sin_rcnt_rev_tl_op</th>\n",
              "      <td>6.142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mo_sin_rcnt_tl</th>\n",
              "      <td>6.142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>num_actv_rev_tl</th>\n",
              "      <td>6.142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>num_tl_op_past_12m</th>\n",
              "      <td>6.142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total_rev_hi_lim</th>\n",
              "      <td>6.142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>avg_cur_bal</th>\n",
              "      <td>6.143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Instance %\n",
              "Feature                          \n",
              "dti                         0.004\n",
              "acc_open_past_24mths        4.250\n",
              "mort_acc                    4.250\n",
              "mths_since_recent_bc        5.171\n",
              "bc_open_to_buy              5.239\n",
              "percent_bc_gt_75            5.275\n",
              "mo_sin_rcnt_rev_tl_op       6.142\n",
              "mo_sin_rcnt_tl              6.142\n",
              "num_actv_rev_tl             6.142\n",
              "num_tl_op_past_12m          6.142\n",
              "total_rev_hi_lim            6.142\n",
              "avg_cur_bal                 6.143"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5XYFIlmuL3G",
        "colab_type": "text"
      },
      "source": [
        "## Drop unused categorical labels in categorical features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMWCORL6uL3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for col in catModCol:\n",
        "    dfFinal.loc[:, col] = dfFinal.loc[:,col].cat.remove_unused_categories()\n",
        "    "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgN02Qv6uL3Z",
        "colab_type": "text"
      },
      "source": [
        "## Establishing Training and Testing Instances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MaZalwQeuL3d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Percentage of records by term and year.\n",
        "yearTermQty = dfFinal.groupby(['issue_d_year', 'term'], observed=True).size()\n",
        "termQty = dfFinal.groupby(['term'], observed=True).size()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7IdeKJIuL3l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "50f02b1d-1be0-44dc-ad0e-21e92bf1b3a8"
      },
      "source": [
        "yearTermQty.div(termQty, axis='index')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "issue_d_year  term     \n",
              "2007          36 months    0.000259\n",
              "2008          36 months    0.001417\n",
              "2009          36 months    0.004980\n",
              "2010          36 months    0.008554\n",
              "              60 months    0.019774\n",
              "2011          36 months    0.014904\n",
              "              60 months    0.055729\n",
              "2012          36 months    0.046153\n",
              "              60 months    0.077711\n",
              "2013          36 months    0.106669\n",
              "              60 months    0.271018\n",
              "2014          36 months    0.172686\n",
              "              60 months    0.575768\n",
              "2015          36 months    0.300794\n",
              "2016          36 months    0.343583\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVvF1mreuL3u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "ea5b54a9-2ac8-40be-bdb6-d66aca609db7"
      },
      "source": [
        "#Checking the breakdown of 60 month loans by month in 2014 to establish cut-off.\n",
        "group1 = dfFinal[(dfFinal.issue_d_year == '2014') & (dfFinal.term_numeric==60)].groupby(['issue_d_month']).size()\n",
        "totalQty = dfFinal[(dfFinal.issue_d_year == '2014') & (dfFinal.term_numeric==60)].shape[0]\n",
        "np.cumsum(group1.div(totalQty))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "issue_d_month\n",
              "1          0.056575\n",
              "2          0.115791\n",
              "3          0.182550\n",
              "4          0.262025\n",
              "5          0.344033\n",
              "6          0.421661\n",
              "7          0.549854\n",
              "8          0.625565\n",
              "9          0.669847\n",
              "10         0.836970\n",
              "11         0.953062\n",
              "12         1.000000\n",
              "Missing    1.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rGTYbKkuL30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Locations of 36 months training and testing data.\n",
        "train36 = ((dfFinal.term_numeric==36) & (dfFinal.issue_d <= dt.datetime(year=2015, month =12, day=31)))\n",
        "test36 = ((dfFinal.term_numeric==36) & (dfFinal.issue_d > dt.datetime(year=2015, month =12, day=31)))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zTOTKIAuL37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Locations of 60 months training and testing data.\n",
        "train60 = ((dfFinal.term_numeric==60) & (dfFinal.issue_d <= dt.datetime(year = 2014, month = 6, day = 30)))\n",
        "test60 = ((dfFinal.term_numeric==60) & (dfFinal.issue_d > dt.datetime(year = 2014, month = 6, day = 30)))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zk64K8PuL4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Count of each type of loan based on term.\n",
        "count36 = (dfFinal.term_numeric==36).sum()\n",
        "count60 = (dfFinal.term_numeric==60).sum()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te4ssNW0uL4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainAll = (train36 | train60)\n",
        "testAll = (test36 | test60)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diVFpxgYuL4N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "97892822-ffa1-417a-a4ed-976e8150a63c"
      },
      "source": [
        "trainTest36 = pd.Series([train36.sum()/count36, test36.sum()/count36], name = '36 Months')\n",
        "trainTest60 = pd.Series([train60.sum()/count60, test60.sum()/count60], name = '60 Months')\n",
        "trainTestAll = pd.Series([trainAll.sum() / dfFinal.shape[0], testAll.sum()/dfFinal.shape[0]], name = 'All Data')\n",
        "df = (pd.DataFrame([trainTest36, trainTest60, trainTestAll]).T*100).round(1)\n",
        "df.index = ['Train %', 'Test %']\n",
        "df.T"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train %</th>\n",
              "      <th>Test %</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>36 Months</th>\n",
              "      <td>65.6</td>\n",
              "      <td>34.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60 Months</th>\n",
              "      <td>66.7</td>\n",
              "      <td>33.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All Data</th>\n",
              "      <td>65.8</td>\n",
              "      <td>34.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Train %  Test %\n",
              "36 Months     65.6    34.4\n",
              "60 Months     66.7    33.3\n",
              "All Data      65.8    34.2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bo4vpp2uL4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainLabels = pd.get_dummies(dfFinal.loan_status)['Charged Off'][trainAll]\n",
        "testLabels = pd.get_dummies(dfFinal.loan_status)['Charged Off'][testAll]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q69vPaiYuL4w",
        "colab_type": "text"
      },
      "source": [
        "# Create Scalers for Numeric Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6G5YVQkuL4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = StandardScaler()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWBO3UbluL42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = scaler.fit(dfFinal.loc[trainAll, numModCol])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLRJhu-muL49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaledArray = scaler.transform(dfFinal[numModCol])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94NEDKYsuL5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfScaled = pd.DataFrame(scaledArray, columns=numModCol, index =dfFinal[numModCol].index )"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQtfx4aLuL5H",
        "colab_type": "text"
      },
      "source": [
        "# Create one-hot encoded indicator columns for all the categorical features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnSJ34JbuL5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oneEncoder = OneHotEncoder()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dlHpoV0uL5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oneHotArray = oneEncoder.fit_transform(dfFinal[catModCol])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9XuiB3MuL5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oneHotColumns = oneEncoder.get_feature_names(catModCol)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FGZDLKDuL5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfFinalOne = pd.concat([dfScaled, pd.DataFrame(oneHotArray.toarray(), columns=oneHotColumns, index = dfScaled.index)], axis = 1)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tztt5nbeuL5h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ded296e6-7948-4d42-e291-8e1f08b0f056"
      },
      "source": [
        "#Excludes original categorical columns.\n",
        "dfFinalOneLimit = dfFinalOne[numModCol + oneHotColumns.tolist()]\n",
        "dfFinalOneLimit.head()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acc_open_past_24mths</th>\n",
              "      <th>annual_inc</th>\n",
              "      <th>avg_cur_bal</th>\n",
              "      <th>bc_open_to_buy</th>\n",
              "      <th>credit_hist_months</th>\n",
              "      <th>dti</th>\n",
              "      <th>fico</th>\n",
              "      <th>inq_last_6mths</th>\n",
              "      <th>installment</th>\n",
              "      <th>mo_sin_rcnt_rev_tl_op</th>\n",
              "      <th>mo_sin_rcnt_tl</th>\n",
              "      <th>mort_acc</th>\n",
              "      <th>mths_since_recent_bc</th>\n",
              "      <th>num_actv_rev_tl</th>\n",
              "      <th>num_tl_op_past_12m</th>\n",
              "      <th>open_acc</th>\n",
              "      <th>percent_bc_gt_75</th>\n",
              "      <th>pub_rec</th>\n",
              "      <th>revol_bal</th>\n",
              "      <th>total_rev_hi_lim</th>\n",
              "      <th>int_rate</th>\n",
              "      <th>term_36 months</th>\n",
              "      <th>term_60 months</th>\n",
              "      <th>purpose_car</th>\n",
              "      <th>purpose_credit_card</th>\n",
              "      <th>purpose_debt_consolidation</th>\n",
              "      <th>purpose_educational</th>\n",
              "      <th>purpose_home_improvement</th>\n",
              "      <th>purpose_house</th>\n",
              "      <th>purpose_major_purchase</th>\n",
              "      <th>purpose_medical</th>\n",
              "      <th>purpose_moving</th>\n",
              "      <th>purpose_other</th>\n",
              "      <th>purpose_renewable_energy</th>\n",
              "      <th>purpose_small_business</th>\n",
              "      <th>purpose_vacation</th>\n",
              "      <th>purpose_wedding</th>\n",
              "      <th>emp_length_1 year</th>\n",
              "      <th>emp_length_10+ years</th>\n",
              "      <th>emp_length_2 years</th>\n",
              "      <th>emp_length_3 years</th>\n",
              "      <th>emp_length_4 years</th>\n",
              "      <th>emp_length_5 years</th>\n",
              "      <th>emp_length_6 years</th>\n",
              "      <th>emp_length_7 years</th>\n",
              "      <th>emp_length_8 years</th>\n",
              "      <th>emp_length_9 years</th>\n",
              "      <th>emp_length_&lt; 1 year</th>\n",
              "      <th>emp_length_Missing</th>\n",
              "      <th>home_ownership_ANY</th>\n",
              "      <th>home_ownership_MORTGAGE</th>\n",
              "      <th>home_ownership_NONE</th>\n",
              "      <th>home_ownership_OTHER</th>\n",
              "      <th>home_ownership_OWN</th>\n",
              "      <th>home_ownership_RENT</th>\n",
              "      <th>verification_status_Not Verified</th>\n",
              "      <th>verification_status_Source Verified</th>\n",
              "      <th>verification_status_Verified</th>\n",
              "      <th>grade_A</th>\n",
              "      <th>grade_B</th>\n",
              "      <th>grade_C</th>\n",
              "      <th>grade_D</th>\n",
              "      <th>grade_E</th>\n",
              "      <th>grade_F</th>\n",
              "      <th>grade_G</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.580095</td>\n",
              "      <td>-0.047358</td>\n",
              "      <td>2.309900</td>\n",
              "      <td>-0.498368</td>\n",
              "      <td>0.119843</td>\n",
              "      <td>-1.079649</td>\n",
              "      <td>0.637486</td>\n",
              "      <td>0.296605</td>\n",
              "      <td>-0.371608</td>\n",
              "      <td>0.340303</td>\n",
              "      <td>-0.568557</td>\n",
              "      <td>1.586125</td>\n",
              "      <td>-0.185791</td>\n",
              "      <td>-0.851168</td>\n",
              "      <td>2.335077</td>\n",
              "      <td>-0.248784</td>\n",
              "      <td>-1.385753</td>\n",
              "      <td>-0.333064</td>\n",
              "      <td>-0.660921</td>\n",
              "      <td>-0.699985</td>\n",
              "      <td>-0.281675</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.133706</td>\n",
              "      <td>-0.734901</td>\n",
              "      <td>-0.665976</td>\n",
              "      <td>-0.295089</td>\n",
              "      <td>1.518996</td>\n",
              "      <td>1.884512</td>\n",
              "      <td>0.637486</td>\n",
              "      <td>0.296605</td>\n",
              "      <td>-0.343091</td>\n",
              "      <td>-0.628604</td>\n",
              "      <td>-0.568557</td>\n",
              "      <td>-0.814465</td>\n",
              "      <td>-0.705763</td>\n",
              "      <td>0.093699</td>\n",
              "      <td>-0.598523</td>\n",
              "      <td>-0.248784</td>\n",
              "      <td>-0.446996</td>\n",
              "      <td>1.367555</td>\n",
              "      <td>-0.386778</td>\n",
              "      <td>-0.281345</td>\n",
              "      <td>0.077076</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.472931</td>\n",
              "      <td>-0.624495</td>\n",
              "      <td>-0.560560</td>\n",
              "      <td>-0.331473</td>\n",
              "      <td>-0.634388</td>\n",
              "      <td>0.199341</td>\n",
              "      <td>0.960813</td>\n",
              "      <td>-0.719712</td>\n",
              "      <td>0.567444</td>\n",
              "      <td>1.793664</td>\n",
              "      <td>2.237010</td>\n",
              "      <td>-0.814465</td>\n",
              "      <td>0.594166</td>\n",
              "      <td>-0.851168</td>\n",
              "      <td>-1.185243</td>\n",
              "      <td>-1.212674</td>\n",
              "      <td>0.494581</td>\n",
              "      <td>-0.333064</td>\n",
              "      <td>0.011673</td>\n",
              "      <td>-0.270879</td>\n",
              "      <td>0.424025</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.223194</td>\n",
              "      <td>0.102885</td>\n",
              "      <td>-0.649397</td>\n",
              "      <td>0.983254</td>\n",
              "      <td>1.431549</td>\n",
              "      <td>0.290006</td>\n",
              "      <td>1.769133</td>\n",
              "      <td>-0.719712</td>\n",
              "      <td>-0.719057</td>\n",
              "      <td>-0.507490</td>\n",
              "      <td>-0.352744</td>\n",
              "      <td>-0.814465</td>\n",
              "      <td>-0.640766</td>\n",
              "      <td>1.353522</td>\n",
              "      <td>0.574917</td>\n",
              "      <td>0.522328</td>\n",
              "      <td>-0.579493</td>\n",
              "      <td>-0.333064</td>\n",
              "      <td>-0.224812</td>\n",
              "      <td>0.320449</td>\n",
              "      <td>-1.733198</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.901645</td>\n",
              "      <td>-0.740144</td>\n",
              "      <td>-0.548986</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.929522</td>\n",
              "      <td>1.078192</td>\n",
              "      <td>1.769133</td>\n",
              "      <td>-0.719712</td>\n",
              "      <td>-1.023848</td>\n",
              "      <td>0.037520</td>\n",
              "      <td>-0.352744</td>\n",
              "      <td>-0.814465</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1.166123</td>\n",
              "      <td>0.574917</td>\n",
              "      <td>-1.019896</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.333064</td>\n",
              "      <td>-0.430548</td>\n",
              "      <td>-0.370306</td>\n",
              "      <td>-0.451609</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   acc_open_past_24mths  annual_inc  avg_cur_bal  bc_open_to_buy  \\\n",
              "0              1.580095   -0.047358     2.309900       -0.498368   \n",
              "1             -1.133706   -0.734901    -0.665976       -0.295089   \n",
              "2             -1.472931   -0.624495    -0.560560       -0.331473   \n",
              "3              0.223194    0.102885    -0.649397        0.983254   \n",
              "4              0.901645   -0.740144    -0.548986             NaN   \n",
              "\n",
              "   credit_hist_months       dti      fico  inq_last_6mths  installment  \\\n",
              "0            0.119843 -1.079649  0.637486        0.296605    -0.371608   \n",
              "1            1.518996  1.884512  0.637486        0.296605    -0.343091   \n",
              "2           -0.634388  0.199341  0.960813       -0.719712     0.567444   \n",
              "3            1.431549  0.290006  1.769133       -0.719712    -0.719057   \n",
              "4           -0.929522  1.078192  1.769133       -0.719712    -1.023848   \n",
              "\n",
              "   mo_sin_rcnt_rev_tl_op  mo_sin_rcnt_tl  mort_acc  mths_since_recent_bc  \\\n",
              "0               0.340303       -0.568557  1.586125             -0.185791   \n",
              "1              -0.628604       -0.568557 -0.814465             -0.705763   \n",
              "2               1.793664        2.237010 -0.814465              0.594166   \n",
              "3              -0.507490       -0.352744 -0.814465             -0.640766   \n",
              "4               0.037520       -0.352744 -0.814465                   NaN   \n",
              "\n",
              "   num_actv_rev_tl  num_tl_op_past_12m  open_acc  percent_bc_gt_75   pub_rec  \\\n",
              "0        -0.851168            2.335077 -0.248784         -1.385753 -0.333064   \n",
              "1         0.093699           -0.598523 -0.248784         -0.446996  1.367555   \n",
              "2        -0.851168           -1.185243 -1.212674          0.494581 -0.333064   \n",
              "3         1.353522            0.574917  0.522328         -0.579493 -0.333064   \n",
              "4        -1.166123            0.574917 -1.019896               NaN -0.333064   \n",
              "\n",
              "   revol_bal  total_rev_hi_lim  int_rate  term_36 months  term_60 months  \\\n",
              "0  -0.660921         -0.699985 -0.281675             1.0             0.0   \n",
              "1  -0.386778         -0.281345  0.077076             1.0             0.0   \n",
              "2   0.011673         -0.270879  0.424025             1.0             0.0   \n",
              "3  -0.224812          0.320449 -1.733198             1.0             0.0   \n",
              "4  -0.430548         -0.370306 -0.451609             1.0             0.0   \n",
              "\n",
              "   purpose_car  purpose_credit_card  purpose_debt_consolidation  \\\n",
              "0          0.0                  0.0                         1.0   \n",
              "1          0.0                  1.0                         0.0   \n",
              "2          0.0                  0.0                         1.0   \n",
              "3          0.0                  0.0                         0.0   \n",
              "4          0.0                  0.0                         1.0   \n",
              "\n",
              "   purpose_educational  purpose_home_improvement  purpose_house  \\\n",
              "0                  0.0                       0.0            0.0   \n",
              "1                  0.0                       0.0            0.0   \n",
              "2                  0.0                       0.0            0.0   \n",
              "3                  0.0                       0.0            0.0   \n",
              "4                  0.0                       0.0            0.0   \n",
              "\n",
              "   purpose_major_purchase  purpose_medical  purpose_moving  purpose_other  \\\n",
              "0                     0.0              0.0             0.0            0.0   \n",
              "1                     0.0              0.0             0.0            0.0   \n",
              "2                     0.0              0.0             0.0            0.0   \n",
              "3                     0.0              0.0             0.0            0.0   \n",
              "4                     0.0              0.0             0.0            0.0   \n",
              "\n",
              "   purpose_renewable_energy  purpose_small_business  purpose_vacation  \\\n",
              "0                       0.0                     0.0               0.0   \n",
              "1                       0.0                     0.0               0.0   \n",
              "2                       0.0                     0.0               0.0   \n",
              "3                       0.0                     0.0               1.0   \n",
              "4                       0.0                     0.0               0.0   \n",
              "\n",
              "   purpose_wedding  emp_length_1 year  emp_length_10+ years  \\\n",
              "0              0.0                0.0                   0.0   \n",
              "1              0.0                0.0                   0.0   \n",
              "2              0.0                0.0                   0.0   \n",
              "3              0.0                0.0                   1.0   \n",
              "4              0.0                0.0                   1.0   \n",
              "\n",
              "   emp_length_2 years  emp_length_3 years  emp_length_4 years  \\\n",
              "0                 0.0                 0.0                 0.0   \n",
              "1                 0.0                 0.0                 0.0   \n",
              "2                 0.0                 0.0                 1.0   \n",
              "3                 0.0                 0.0                 0.0   \n",
              "4                 0.0                 0.0                 0.0   \n",
              "\n",
              "   emp_length_5 years  emp_length_6 years  emp_length_7 years  \\\n",
              "0                 0.0                 0.0                 0.0   \n",
              "1                 0.0                 1.0                 0.0   \n",
              "2                 0.0                 0.0                 0.0   \n",
              "3                 0.0                 0.0                 0.0   \n",
              "4                 0.0                 0.0                 0.0   \n",
              "\n",
              "   emp_length_8 years  emp_length_9 years  emp_length_< 1 year  \\\n",
              "0                 0.0                 0.0                  0.0   \n",
              "1                 0.0                 0.0                  0.0   \n",
              "2                 0.0                 0.0                  0.0   \n",
              "3                 0.0                 0.0                  0.0   \n",
              "4                 0.0                 0.0                  0.0   \n",
              "\n",
              "   emp_length_Missing  home_ownership_ANY  home_ownership_MORTGAGE  \\\n",
              "0                 1.0                 0.0                      1.0   \n",
              "1                 0.0                 0.0                      0.0   \n",
              "2                 0.0                 0.0                      1.0   \n",
              "3                 0.0                 0.0                      0.0   \n",
              "4                 0.0                 0.0                      0.0   \n",
              "\n",
              "   home_ownership_NONE  home_ownership_OTHER  home_ownership_OWN  \\\n",
              "0                  0.0                   0.0                 0.0   \n",
              "1                  0.0                   0.0                 0.0   \n",
              "2                  0.0                   0.0                 0.0   \n",
              "3                  0.0                   0.0                 0.0   \n",
              "4                  0.0                   0.0                 0.0   \n",
              "\n",
              "   home_ownership_RENT  verification_status_Not Verified  \\\n",
              "0                  0.0                               0.0   \n",
              "1                  1.0                               0.0   \n",
              "2                  0.0                               0.0   \n",
              "3                  1.0                               0.0   \n",
              "4                  1.0                               0.0   \n",
              "\n",
              "   verification_status_Source Verified  verification_status_Verified  grade_A  \\\n",
              "0                                  0.0                           1.0      0.0   \n",
              "1                                  1.0                           0.0      0.0   \n",
              "2                                  1.0                           0.0      0.0   \n",
              "3                                  1.0                           0.0      1.0   \n",
              "4                                  1.0                           0.0      0.0   \n",
              "\n",
              "   grade_B  grade_C  grade_D  grade_E  grade_F  grade_G  \n",
              "0      1.0      0.0      0.0      0.0      0.0      0.0  \n",
              "1      0.0      1.0      0.0      0.0      0.0      0.0  \n",
              "2      0.0      1.0      0.0      0.0      0.0      0.0  \n",
              "3      0.0      0.0      0.0      0.0      0.0      0.0  \n",
              "4      1.0      0.0      0.0      0.0      0.0      0.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH3odHL-uL5n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "bede9db4-baa7-44ba-f10d-c6a74c0448fe"
      },
      "source": [
        "dfFinalOneLimit.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1068298, 65)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUw3-AWSDwU7",
        "colab_type": "text"
      },
      "source": [
        "# Get Missing Values from Imputed File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ut9KZEwlV4lc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imputedArray = pd.read_csv('missingImputs.csv')\n",
        "missingColumns=imputedArray.columns"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwkUpZkzWbDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfFinalOneLimit.loc[:,missingColumns] = imputedArray.values"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwrGpFQNuL6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfPostImpute = dfFinalOneLimit"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px6dGmZ0adRu",
        "colab_type": "text"
      },
      "source": [
        "# Sample for performing cross validation grid search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6bx5Qd-aQWC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dfTrain, dfTest, yTrain, yTest = train_test_split(dfPostImpute[trainAll], trainLabels, stratify = trainLabels, train_size =0.7, random_state=rs)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuxlyilDjSBh",
        "colab_type": "text"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIuEMSETJV8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calcCostRev(y, y_pred, cost = (1,4), returnThreshold = False):\n",
        "    #y_true must be a single column of binary labels for positive class.\n",
        "    #y_prob must be single column of probabilities for positive class.\n",
        "    \n",
        "    thresholds = [0.5]\n",
        "    result = y_pred.reshape(-1,1) >=  np.array(thresholds)\n",
        "    \n",
        "    #Convert boolean result array into binary array.\n",
        "    resultBinary = result.astype('int')\n",
        "    \n",
        "    #Calculate loss from False Negatives\n",
        "    lossFN = np.sum((y.values.reshape(-1,1) > resultBinary), axis=0)*cost[1]\n",
        "    \n",
        "    #Calculate loss from False Positive\n",
        "    lossFP = np.sum((y.values.reshape(-1,1) < resultBinary), axis=0)*cost[0]\n",
        "    \n",
        "    totalLoss = lossFN + lossFP\n",
        "    \n",
        "    minInd = np.argmin(totalLoss)\n",
        "    minThres = thresholds[minInd]\n",
        "    minLoss = totalLoss[minInd]\n",
        "    \n",
        "    if returnThreshold:\n",
        "        return minLoss, minThres\n",
        "    else:\n",
        "        return minLoss"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA1bkQYAuL_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calcCost(y, y_pred, cost = (1,4), returnThreshold = False):\n",
        "    #y_true must be a single column of binary labels for positive class.\n",
        "    #y_prob must be single column of probabilities for positive class.\n",
        "    \n",
        "    thresholds = np.arange(0, 1, 0.001)\n",
        "    result = y_pred.reshape(-1,1) >=  np.array(thresholds)\n",
        "    \n",
        "    #Convert boolean result array into binary array.\n",
        "    resultBinary = result.astype('int')\n",
        "    \n",
        "    #Calculate loss from False Negatives\n",
        "    lossFN = np.sum((y.values.reshape(-1,1) > resultBinary), axis=0)*cost[1]\n",
        "    \n",
        "    #Calculate loss from False Positive\n",
        "    lossFP = np.sum((y.values.reshape(-1,1) < resultBinary), axis=0)*cost[0]\n",
        "    \n",
        "    totalLoss = lossFN + lossFP\n",
        "    \n",
        "    minInd = np.argmin(totalLoss)\n",
        "    minThres = thresholds[minInd]\n",
        "    minLoss = totalLoss[minInd]\n",
        "    \n",
        "    if returnThreshold:\n",
        "        return minLoss, minThres\n",
        "    else:\n",
        "        return minLoss"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lD92f_uquL_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getLoss(y, y_hat, cost = (1,5)):\n",
        "    #Calculate loss from False Negatives\n",
        "    lossFN = np.sum(y > y_hat)*cost[1]\n",
        "    \n",
        "    #Calculate loss from False Positive\n",
        "    lossFP = np.sum(y < y_hat)*cost[0]\n",
        "    \n",
        "    return lossFN+lossFP"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptLj-mp4uL_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictLoss = make_scorer(score_func=calcCost, greater_is_better=False, needs_proba=True, cost = (1,4), returnThreshold = False)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2vWVroquL_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getFScore(y, y_prob):\n",
        "    prec, recl, thres = precision_recall_curve(y, y_prob)\n",
        "    fscore = (2 * prec * recl) / (prec + recl)\n",
        "    maxInd = np.nanargmax(fscore)\n",
        "    return fscore[maxInd]"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9gsqm3yuL_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "highFScore = make_scorer(score_func=getFScore, greater_is_better=True, needs_proba=True)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmES2fLIuL_c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_roc(y_true, y_prob, plt, labelName):\n",
        "    fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
        "    aucScore = np.round(roc_auc_score(y_true, y_prob),3)\n",
        "    plt.plot(fpr, tpr, label = labelName + '- AUC: '+str(aucScore))\n",
        "    plt.legend(loc = 'center left', bbox_to_anchor=(1, 0.5))\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVqC8uM-uL_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_pre_recl(y_true, y_prob, plt, labelName):\n",
        "    precision, recall, thresholds = precision_recall_curve(y_true, y_prob)\n",
        "    plt.plot(recall, precision, label = labelName)\n",
        "    plt.legend(loc = 'center left', bbox_to_anchor=(1, 0.5))\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BmowNEVuL_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getScores(y_true, y_pred, y_prob):\n",
        "    scoresDict ={}\n",
        "    scoresDict['Accuracy'] = accuracy_score(y_true, y_pred)\n",
        "    scoresDict['Precision(+)'] = precision_score(y_true, y_pred)\n",
        "    scoresDict['Recall(+)'] = recall_score(y_true, y_pred)\n",
        "    scoresDict['AUC'] = roc_auc_score(y_true, y_prob)\n",
        "    scoresDict['Error Cost'] = getLoss(y_true, y_pred)\n",
        "    return pd.DataFrame(scoresDict, index=['Result'])\n",
        "    "
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVjRvwSIuL_k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_labels(origProb, threshold):\n",
        "    result = origProb >= threshold\n",
        "    return result.astype('int')"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6Ngw9aDuL_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fScoreThres(y, y_prob):\n",
        "    prec, recl, thres = precision_recall_curve(y, y_prob)\n",
        "    fscore = (2 * prec * recl) / (prec + recl)\n",
        "    maxInd = np.argmax(fscore)\n",
        "    return fscore[maxInd], thres[maxInd]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbUzrLQauL_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def aucPreRec(y, y_prob):\n",
        "    prec, recl, thres = precision_recall_curve(y, y_prob)\n",
        "    aucScore = auc(prec, recl)\n",
        "    return aucScore"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTdl-zyzuL_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotGridScores(gridObj):\n",
        "    allResults = {}\n",
        "    for score in gridObj.scorer_.keys():\n",
        "        allResults[score] = gridObj.cv_results_['mean_test_'+score].tolist()\n",
        "    pd.DataFrame.from_dict(allResults).plot()"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvbpY9UcuL66",
        "colab_type": "text"
      },
      "source": [
        "#Global Parameters for Grid Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KmLcVwvuL7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scoringDict2 = {'accuracy': make_scorer(accuracy_score), \n",
        "                'balanced_accuracy': make_scorer(balanced_accuracy_score),\n",
        "               'f1': make_scorer(f1_score),\n",
        "              'average_precision': make_scorer(average_precision_score, needs_proba=True), \n",
        "               'roc_auc': make_scorer(roc_auc_score, needs_proba=True), \n",
        "               'loan_loss': make_scorer(score_func=calcCostRev, greater_is_better=False, needs_proba=True, cost = (1,3.7), returnThreshold = False),\n",
        "               'neg_brier_score': make_scorer(brier_score_loss, needs_proba=True)}"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXmVy7KDuL7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "kFold = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5r2OSe9j5o7",
        "colab_type": "text"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cTnEsQUFRnr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#AUC metric for Keras neural net\n",
        "auc = tf.keras.metrics.AUC(\n",
        "    num_thresholds=200, curve='ROC', summation_method='interpolation', name=None,\n",
        "    dtype=None, thresholds=None, multi_label=False, label_weights=None\n",
        ")"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOFPfeKpzJox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model1(actF = 'tanh', optim='rmsprop'):\n",
        "  NN = Sequential()\n",
        "  NN.add(layers.Dense(64, input_dim=dfPostImpute.shape[1], activation=actF))\n",
        "  NN.add(Dropout(0.2))\n",
        "  NN.add(layers.Dense(32, activation=actF))\n",
        "  NN.add(Dropout(0.2))\n",
        "  NN.add(layers.Dense(1, activation='sigmoid'))\n",
        "  NN.compile(loss='binary_crossentropy', optimizer=optim, metrics=[auc, 'accuracy'])\n",
        "  return NN"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBXCWSAD4R1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model2(actF = 'tanh', optim='rmsprop'):\n",
        "  NN = Sequential()\n",
        "  NN.add(layers.Dense(32, input_dim=dfPostImpute.shape[1], activation=actF))\n",
        "  NN.add(layers.Dense(16, activation=actF))\n",
        "  NN.add(layers.Dense(1, activation='sigmoid'))\n",
        "  NN.compile(loss='binary_crossentropy', optimizer=optim, metrics=[auc, 'accuracy'])\n",
        "  return NN"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "h_6WfFdVDDR7",
        "colab": {}
      },
      "source": [
        "def create_model3(actF = 'tanh', optim='rmsprop'):\n",
        "  NN = Sequential()\n",
        "  NN.add(layers.Dense(32, input_dim=dfPostImpute.shape[1], activation=actF))\n",
        "  NN.add(layers.Dense(1, activation='sigmoid'))\n",
        "  NN.compile(loss='binary_crossentropy', optimizer=optim, metrics=[auc, 'accuracy'])\n",
        "  return NN"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJj1eS90lyIV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = dfTrain\n",
        "y_train = yTrain\n",
        "X_test = dfTest\n",
        "y_test = yTest"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LZIuZRmmbQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_weights = class_weight.compute_class_weight('balanced', np.unique(trainLabels), trainLabels )\n",
        "d_class_weights = dict(enumerate(class_weights.tolist()))"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opUlmJ483eyg",
        "colab_type": "text"
      },
      "source": [
        "# NN - Grid 1 - epochs, batch_size, and activation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlMME1Jw-2wS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Setup pipeline.\n",
        "stepsNN = [('model', KerasClassifier(build_fn=create_model3, verbose=2))]\n",
        "pipelineNN = Pipeline(steps=stepsNN)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfUu54e4_-qK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Parameters for grid search.\n",
        "param_gridNN = [{'model__epochs': [50, 75, 100, 125],\n",
        "              'model__batch_size': [1000, 5000, 10000, 15000, 20000],\n",
        "              'model__actF': ['tanh', 'relu']}]"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S213_5b1BIFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Grid search object\n",
        "gridNN_1 = GridSearchCV(pipelineNN, param_grid=param_gridNN, scoring=scoringDict2, cv = kFold2, verbose=2,\n",
        "                                        refit='roc_auc', n_jobs=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idGXOXtyBluW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "558bec4c-6389-4998-ef9b-8753d8bfb3d4"
      },
      "source": [
        "#Perform cross validation with grid search object.\n",
        "gridNN_1.fit(X=dfPostImpute[trainAll], y=trainLabels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed: 48.0min\n",
            "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed: 116.4min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "47/47 - 0s - loss: 0.6269 - auc: 0.5126 - accuracy: 0.6509\n",
            "Epoch 2/100\n",
            "47/47 - 0s - loss: 0.4249 - auc: 0.6169 - accuracy: 0.8463\n",
            "Epoch 3/100\n",
            "47/47 - 0s - loss: 0.4068 - auc: 0.6636 - accuracy: 0.8465\n",
            "Epoch 4/100\n",
            "47/47 - 0s - loss: 0.4031 - auc: 0.6759 - accuracy: 0.8464\n",
            "Epoch 5/100\n",
            "47/47 - 0s - loss: 0.4014 - auc: 0.6812 - accuracy: 0.8465\n",
            "Epoch 6/100\n",
            "47/47 - 0s - loss: 0.4003 - auc: 0.6845 - accuracy: 0.8466\n",
            "Epoch 7/100\n",
            "47/47 - 0s - loss: 0.3995 - auc: 0.6866 - accuracy: 0.8466\n",
            "Epoch 8/100\n",
            "47/47 - 0s - loss: 0.3989 - auc: 0.6883 - accuracy: 0.8466\n",
            "Epoch 9/100\n",
            "47/47 - 0s - loss: 0.3984 - auc: 0.6895 - accuracy: 0.8467\n",
            "Epoch 10/100\n",
            "47/47 - 0s - loss: 0.3980 - auc: 0.6906 - accuracy: 0.8467\n",
            "Epoch 11/100\n",
            "47/47 - 0s - loss: 0.3977 - auc: 0.6914 - accuracy: 0.8467\n",
            "Epoch 12/100\n",
            "47/47 - 0s - loss: 0.3974 - auc: 0.6922 - accuracy: 0.8467\n",
            "Epoch 13/100\n",
            "47/47 - 0s - loss: 0.3972 - auc: 0.6928 - accuracy: 0.8468\n",
            "Epoch 14/100\n",
            "47/47 - 0s - loss: 0.3969 - auc: 0.6935 - accuracy: 0.8468\n",
            "Epoch 15/100\n",
            "47/47 - 0s - loss: 0.3968 - auc: 0.6940 - accuracy: 0.8468\n",
            "Epoch 16/100\n",
            "47/47 - 0s - loss: 0.3966 - auc: 0.6945 - accuracy: 0.8468\n",
            "Epoch 17/100\n",
            "47/47 - 0s - loss: 0.3964 - auc: 0.6950 - accuracy: 0.8468\n",
            "Epoch 18/100\n",
            "47/47 - 0s - loss: 0.3963 - auc: 0.6954 - accuracy: 0.8468\n",
            "Epoch 19/100\n",
            "47/47 - 0s - loss: 0.3961 - auc: 0.6958 - accuracy: 0.8468\n",
            "Epoch 20/100\n",
            "47/47 - 0s - loss: 0.3960 - auc: 0.6962 - accuracy: 0.8469\n",
            "Epoch 21/100\n",
            "47/47 - 0s - loss: 0.3958 - auc: 0.6965 - accuracy: 0.8469\n",
            "Epoch 22/100\n",
            "47/47 - 0s - loss: 0.3957 - auc: 0.6968 - accuracy: 0.8469\n",
            "Epoch 23/100\n",
            "47/47 - 0s - loss: 0.3956 - auc: 0.6971 - accuracy: 0.8469\n",
            "Epoch 24/100\n",
            "47/47 - 0s - loss: 0.3955 - auc: 0.6974 - accuracy: 0.8469\n",
            "Epoch 25/100\n",
            "47/47 - 0s - loss: 0.3954 - auc: 0.6976 - accuracy: 0.8469\n",
            "Epoch 26/100\n",
            "47/47 - 0s - loss: 0.3953 - auc: 0.6979 - accuracy: 0.8469\n",
            "Epoch 27/100\n",
            "47/47 - 0s - loss: 0.3952 - auc: 0.6982 - accuracy: 0.8469\n",
            "Epoch 28/100\n",
            "47/47 - 0s - loss: 0.3951 - auc: 0.6984 - accuracy: 0.8469\n",
            "Epoch 29/100\n",
            "47/47 - 0s - loss: 0.3950 - auc: 0.6986 - accuracy: 0.8469\n",
            "Epoch 30/100\n",
            "47/47 - 0s - loss: 0.3950 - auc: 0.6989 - accuracy: 0.8469\n",
            "Epoch 31/100\n",
            "47/47 - 0s - loss: 0.3949 - auc: 0.6991 - accuracy: 0.8469\n",
            "Epoch 32/100\n",
            "47/47 - 0s - loss: 0.3948 - auc: 0.6993 - accuracy: 0.8469\n",
            "Epoch 33/100\n",
            "47/47 - 0s - loss: 0.3947 - auc: 0.6995 - accuracy: 0.8469\n",
            "Epoch 34/100\n",
            "47/47 - 0s - loss: 0.3947 - auc: 0.6997 - accuracy: 0.8469\n",
            "Epoch 35/100\n",
            "47/47 - 0s - loss: 0.3946 - auc: 0.6999 - accuracy: 0.8469\n",
            "Epoch 36/100\n",
            "47/47 - 0s - loss: 0.3945 - auc: 0.7001 - accuracy: 0.8470\n",
            "Epoch 37/100\n",
            "47/47 - 0s - loss: 0.3944 - auc: 0.7003 - accuracy: 0.8470\n",
            "Epoch 38/100\n",
            "47/47 - 0s - loss: 0.3944 - auc: 0.7004 - accuracy: 0.8469\n",
            "Epoch 39/100\n",
            "47/47 - 0s - loss: 0.3943 - auc: 0.7006 - accuracy: 0.8470\n",
            "Epoch 40/100\n",
            "47/47 - 0s - loss: 0.3942 - auc: 0.7008 - accuracy: 0.8470\n",
            "Epoch 41/100\n",
            "47/47 - 0s - loss: 0.3942 - auc: 0.7009 - accuracy: 0.8470\n",
            "Epoch 42/100\n",
            "47/47 - 0s - loss: 0.3941 - auc: 0.7010 - accuracy: 0.8470\n",
            "Epoch 43/100\n",
            "47/47 - 0s - loss: 0.3941 - auc: 0.7013 - accuracy: 0.8470\n",
            "Epoch 44/100\n",
            "47/47 - 0s - loss: 0.3940 - auc: 0.7013 - accuracy: 0.8470\n",
            "Epoch 45/100\n",
            "47/47 - 0s - loss: 0.3940 - auc: 0.7015 - accuracy: 0.8470\n",
            "Epoch 46/100\n",
            "47/47 - 0s - loss: 0.3940 - auc: 0.7015 - accuracy: 0.8470\n",
            "Epoch 47/100\n",
            "47/47 - 0s - loss: 0.3939 - auc: 0.7017 - accuracy: 0.8470\n",
            "Epoch 48/100\n",
            "47/47 - 0s - loss: 0.3939 - auc: 0.7018 - accuracy: 0.8471\n",
            "Epoch 49/100\n",
            "47/47 - 0s - loss: 0.3938 - auc: 0.7020 - accuracy: 0.8470\n",
            "Epoch 50/100\n",
            "47/47 - 0s - loss: 0.3938 - auc: 0.7021 - accuracy: 0.8470\n",
            "Epoch 51/100\n",
            "47/47 - 0s - loss: 0.3937 - auc: 0.7022 - accuracy: 0.8471\n",
            "Epoch 52/100\n",
            "47/47 - 0s - loss: 0.3937 - auc: 0.7023 - accuracy: 0.8470\n",
            "Epoch 53/100\n",
            "47/47 - 0s - loss: 0.3936 - auc: 0.7024 - accuracy: 0.8470\n",
            "Epoch 54/100\n",
            "47/47 - 0s - loss: 0.3936 - auc: 0.7025 - accuracy: 0.8471\n",
            "Epoch 55/100\n",
            "47/47 - 0s - loss: 0.3936 - auc: 0.7025 - accuracy: 0.8471\n",
            "Epoch 56/100\n",
            "47/47 - 0s - loss: 0.3935 - auc: 0.7027 - accuracy: 0.8470\n",
            "Epoch 57/100\n",
            "47/47 - 0s - loss: 0.3935 - auc: 0.7027 - accuracy: 0.8470\n",
            "Epoch 58/100\n",
            "47/47 - 0s - loss: 0.3935 - auc: 0.7028 - accuracy: 0.8470\n",
            "Epoch 59/100\n",
            "47/47 - 0s - loss: 0.3935 - auc: 0.7029 - accuracy: 0.8470\n",
            "Epoch 60/100\n",
            "47/47 - 0s - loss: 0.3934 - auc: 0.7030 - accuracy: 0.8470\n",
            "Epoch 61/100\n",
            "47/47 - 0s - loss: 0.3934 - auc: 0.7030 - accuracy: 0.8470\n",
            "Epoch 62/100\n",
            "47/47 - 0s - loss: 0.3934 - auc: 0.7031 - accuracy: 0.8470\n",
            "Epoch 63/100\n",
            "47/47 - 0s - loss: 0.3933 - auc: 0.7033 - accuracy: 0.8471\n",
            "Epoch 64/100\n",
            "47/47 - 0s - loss: 0.3933 - auc: 0.7032 - accuracy: 0.8471\n",
            "Epoch 65/100\n",
            "47/47 - 0s - loss: 0.3933 - auc: 0.7033 - accuracy: 0.8471\n",
            "Epoch 66/100\n",
            "47/47 - 0s - loss: 0.3933 - auc: 0.7034 - accuracy: 0.8471\n",
            "Epoch 67/100\n",
            "47/47 - 0s - loss: 0.3932 - auc: 0.7035 - accuracy: 0.8471\n",
            "Epoch 68/100\n",
            "47/47 - 0s - loss: 0.3932 - auc: 0.7035 - accuracy: 0.8470\n",
            "Epoch 69/100\n",
            "47/47 - 0s - loss: 0.3932 - auc: 0.7036 - accuracy: 0.8470\n",
            "Epoch 70/100\n",
            "47/47 - 0s - loss: 0.3932 - auc: 0.7037 - accuracy: 0.8471\n",
            "Epoch 71/100\n",
            "47/47 - 0s - loss: 0.3932 - auc: 0.7036 - accuracy: 0.8471\n",
            "Epoch 72/100\n",
            "47/47 - 0s - loss: 0.3931 - auc: 0.7038 - accuracy: 0.8470\n",
            "Epoch 73/100\n",
            "47/47 - 0s - loss: 0.3931 - auc: 0.7039 - accuracy: 0.8470\n",
            "Epoch 74/100\n",
            "47/47 - 0s - loss: 0.3931 - auc: 0.7039 - accuracy: 0.8470\n",
            "Epoch 75/100\n",
            "47/47 - 0s - loss: 0.3930 - auc: 0.7040 - accuracy: 0.8470\n",
            "Epoch 76/100\n",
            "47/47 - 0s - loss: 0.3930 - auc: 0.7040 - accuracy: 0.8470\n",
            "Epoch 77/100\n",
            "47/47 - 0s - loss: 0.3930 - auc: 0.7041 - accuracy: 0.8470\n",
            "Epoch 78/100\n",
            "47/47 - 0s - loss: 0.3930 - auc: 0.7041 - accuracy: 0.8471\n",
            "Epoch 79/100\n",
            "47/47 - 0s - loss: 0.3930 - auc: 0.7042 - accuracy: 0.8470\n",
            "Epoch 80/100\n",
            "47/47 - 0s - loss: 0.3929 - auc: 0.7043 - accuracy: 0.8470\n",
            "Epoch 81/100\n",
            "47/47 - 0s - loss: 0.3929 - auc: 0.7044 - accuracy: 0.8470\n",
            "Epoch 82/100\n",
            "47/47 - 0s - loss: 0.3929 - auc: 0.7043 - accuracy: 0.8471\n",
            "Epoch 83/100\n",
            "47/47 - 0s - loss: 0.3929 - auc: 0.7044 - accuracy: 0.8470\n",
            "Epoch 84/100\n",
            "47/47 - 0s - loss: 0.3929 - auc: 0.7044 - accuracy: 0.8471\n",
            "Epoch 85/100\n",
            "47/47 - 0s - loss: 0.3928 - auc: 0.7046 - accuracy: 0.8470\n",
            "Epoch 86/100\n",
            "47/47 - 0s - loss: 0.3928 - auc: 0.7045 - accuracy: 0.8470\n",
            "Epoch 87/100\n",
            "47/47 - 0s - loss: 0.3928 - auc: 0.7046 - accuracy: 0.8470\n",
            "Epoch 88/100\n",
            "47/47 - 0s - loss: 0.3928 - auc: 0.7047 - accuracy: 0.8470\n",
            "Epoch 89/100\n",
            "47/47 - 0s - loss: 0.3928 - auc: 0.7047 - accuracy: 0.8470\n",
            "Epoch 90/100\n",
            "47/47 - 0s - loss: 0.3928 - auc: 0.7047 - accuracy: 0.8470\n",
            "Epoch 91/100\n",
            "47/47 - 0s - loss: 0.3928 - auc: 0.7047 - accuracy: 0.8470\n",
            "Epoch 92/100\n",
            "47/47 - 0s - loss: 0.3927 - auc: 0.7048 - accuracy: 0.8470\n",
            "Epoch 93/100\n",
            "47/47 - 0s - loss: 0.3927 - auc: 0.7048 - accuracy: 0.8470\n",
            "Epoch 94/100\n",
            "47/47 - 0s - loss: 0.3927 - auc: 0.7048 - accuracy: 0.8470\n",
            "Epoch 95/100\n",
            "47/47 - 0s - loss: 0.3927 - auc: 0.7049 - accuracy: 0.8471\n",
            "Epoch 96/100\n",
            "47/47 - 0s - loss: 0.3927 - auc: 0.7050 - accuracy: 0.8470\n",
            "Epoch 97/100\n",
            "47/47 - 0s - loss: 0.3927 - auc: 0.7049 - accuracy: 0.8470\n",
            "Epoch 98/100\n",
            "47/47 - 0s - loss: 0.3926 - auc: 0.7050 - accuracy: 0.8470\n",
            "Epoch 99/100\n",
            "47/47 - 0s - loss: 0.3926 - auc: 0.7051 - accuracy: 0.8470\n",
            "Epoch 100/100\n",
            "47/47 - 0s - loss: 0.3926 - auc: 0.7051 - accuracy: 0.8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=0, shuffle=True),\n",
              "             error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('model',\n",
              "                                        <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f8f06878b38>)],\n",
              "                                verbose=False),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid=[{'model__actF': ['tanh', 'relu'],\n",
              "                          'model__batch_size': [1000, 5000, 10000, 15000...\n",
              "                      'average_precision': make_scorer(average_precision_score, needs_proba=True),\n",
              "                      'balanced_accuracy': make_scorer(balanced_accuracy_score),\n",
              "                      'f1': make_scorer(f1_score),\n",
              "                      'loan_loss': make_scorer(calcCostRev, greater_is_better=False, needs_proba=True, cost=(1, 3.7), returnThreshold=False),\n",
              "                      'neg_brier_score': make_scorer(brier_score_loss, needs_proba=True),\n",
              "                      'roc_auc': make_scorer(roc_auc_score, needs_proba=True)},\n",
              "             verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r97pkOGxaf6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Assign results of grid search.\n",
        "results_Grid1_NN = gridNN_1.cv_results_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LA3ZMdJlh_gG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "2412e9da-0255-49b6-fd21-d93dd670db59"
      },
      "source": [
        "#Best parameters based on AUC:\n",
        "ind = np.argmin(results_Grid1_NN['rank_test_roc_auc'])\n",
        "print('Parameters:', results_Grid1_NN['params'][ind])\n",
        "print('ROC-AUC:', results_Grid1_NN['mean_test_roc_auc'][ind])\n",
        "print('F1:', results_Grid1_NN['mean_test_f1'][ind])\n",
        "print('Accuracy:', results_Grid1_NN['mean_test_accuracy'][ind])\n",
        "print('Balanced Accuracy:', results_Grid1_NN['mean_test_balanced_accuracy'][ind])\n",
        "print('Loan Loss:', results_Grid1_NN['mean_test_loan_loss'][ind])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters: {'model__actF': 'relu', 'model__batch_size': 15000, 'model__epochs': 100}\n",
            "ROC-AUC: 0.6989683507867918\n",
            "F1: 0.01931538273595983\n",
            "Accuracy: 0.8468088922576699\n",
            "Balanced Accuracy: 0.5040215219973407\n",
            "Loan Loss: -131777.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bb000UJoYqs7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "8a50f535-5b1f-45ef-cd6d-f02cd6667db3"
      },
      "source": [
        "#Best parameters based on loan loss:\n",
        "ind = np.argmin(results_Grid1_NN['rank_test_loan_loss'])\n",
        "print('Parameters:', results_Grid1_NN['params'][ind])\n",
        "print('ROC-AUC:', results_Grid1_NN['mean_test_roc_auc'][ind])\n",
        "print('F1:', results_Grid1_NN['mean_test_f1'][ind])\n",
        "print('Accuracy:', results_Grid1_NN['mean_test_accuracy'][ind])\n",
        "print('Balanced Accuracy:', results_Grid1_NN['mean_test_balanced_accuracy'][ind])\n",
        "print('Loan Loss:', results_Grid1_NN['mean_test_loan_loss'][ind])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters: {'model__actF': 'tanh', 'model__batch_size': 1000, 'model__epochs': 75}\n",
            "ROC-AUC: 0.6977938893079347\n",
            "F1: 0.02852222383393682\n",
            "Accuracy: 0.8465612380342035\n",
            "Balanced Accuracy: 0.5058733318779411\n",
            "Loan Loss: -131362.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7xtHwW2d4GwP"
      },
      "source": [
        "\n",
        "# NN - Grid 2 - Undersampling and optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C5HISu5_4GwW",
        "colab": {}
      },
      "source": [
        "#Setup pipeline.\n",
        "stepsNN = [('under', RandomUnderSampler()), ('model', KerasClassifier(build_fn=create_model3, verbose=2))]\n",
        "pipelineNN = Pipeline(steps=stepsNN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cXBesO6r4Gws",
        "colab": {}
      },
      "source": [
        "#Parameters for gridsearch.\n",
        "param_gridNN = [{'model__epochs': [75],\n",
        "              'model__batch_size': [1000],\n",
        "              'under': [None,\n",
        "                        RandomUnderSampler(sampling_strategy=0.2, random_state=rs),\n",
        "                        RandomUnderSampler(sampling_strategy=0.6, random_state=rs),\n",
        "                        RandomUnderSampler(sampling_strategy=1.0, random_state=rs)],\n",
        "                 'model__optim': ['adam', 'adadelta', 'adagrad', 'rmsprop']}]"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "60UTVtUE4GxJ",
        "colab": {}
      },
      "source": [
        "#Grid search object.\n",
        "gridNN = GridSearchCV(pipelineNN, param_grid=param_gridNN, scoring=scoringDict2, cv = kFold2, verbose=2,\n",
        "                                        refit='roc_auc', n_jobs=-1, pre_dispatch=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IsIuVq9G4GxW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "303d64cc-f1dd-4509-feab-8f67fab31fdb"
      },
      "source": [
        "#Perform cross validation using grid search.\n",
        "gridNN.fit(X=dfPostImpute[trainAll], y=trainLabels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed: 50.3min\n",
            "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed: 58.4min finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "646/646 - 2s - loss: 0.4247 - auc: 0.6771 - accuracy: 0.8306\n",
            "Epoch 2/75\n",
            "646/646 - 2s - loss: 0.4176 - auc: 0.6923 - accuracy: 0.8334\n",
            "Epoch 3/75\n",
            "646/646 - 2s - loss: 0.4171 - auc: 0.6938 - accuracy: 0.8334\n",
            "Epoch 4/75\n",
            "646/646 - 2s - loss: 0.4165 - auc: 0.6951 - accuracy: 0.8335\n",
            "Epoch 5/75\n",
            "646/646 - 2s - loss: 0.4161 - auc: 0.6963 - accuracy: 0.8334\n",
            "Epoch 6/75\n",
            "646/646 - 2s - loss: 0.4158 - auc: 0.6969 - accuracy: 0.8335\n",
            "Epoch 7/75\n",
            "646/646 - 2s - loss: 0.4155 - auc: 0.6978 - accuracy: 0.8335\n",
            "Epoch 8/75\n",
            "646/646 - 2s - loss: 0.4152 - auc: 0.6984 - accuracy: 0.8335\n",
            "Epoch 9/75\n",
            "646/646 - 2s - loss: 0.4149 - auc: 0.6990 - accuracy: 0.8335\n",
            "Epoch 10/75\n",
            "646/646 - 2s - loss: 0.4147 - auc: 0.6997 - accuracy: 0.8335\n",
            "Epoch 11/75\n",
            "646/646 - 2s - loss: 0.4145 - auc: 0.7002 - accuracy: 0.8336\n",
            "Epoch 12/75\n",
            "646/646 - 2s - loss: 0.4144 - auc: 0.7005 - accuracy: 0.8335\n",
            "Epoch 13/75\n",
            "646/646 - 2s - loss: 0.4143 - auc: 0.7007 - accuracy: 0.8335\n",
            "Epoch 14/75\n",
            "646/646 - 2s - loss: 0.4141 - auc: 0.7012 - accuracy: 0.8335\n",
            "Epoch 15/75\n",
            "646/646 - 2s - loss: 0.4139 - auc: 0.7016 - accuracy: 0.8335\n",
            "Epoch 16/75\n",
            "646/646 - 2s - loss: 0.4138 - auc: 0.7018 - accuracy: 0.8336\n",
            "Epoch 17/75\n",
            "646/646 - 2s - loss: 0.4138 - auc: 0.7020 - accuracy: 0.8337\n",
            "Epoch 18/75\n",
            "646/646 - 2s - loss: 0.4136 - auc: 0.7023 - accuracy: 0.8336\n",
            "Epoch 19/75\n",
            "646/646 - 2s - loss: 0.4136 - auc: 0.7025 - accuracy: 0.8336\n",
            "Epoch 20/75\n",
            "646/646 - 2s - loss: 0.4135 - auc: 0.7027 - accuracy: 0.8336\n",
            "Epoch 21/75\n",
            "646/646 - 2s - loss: 0.4134 - auc: 0.7029 - accuracy: 0.8336\n",
            "Epoch 22/75\n",
            "646/646 - 2s - loss: 0.4133 - auc: 0.7031 - accuracy: 0.8336\n",
            "Epoch 23/75\n",
            "646/646 - 2s - loss: 0.4133 - auc: 0.7033 - accuracy: 0.8336\n",
            "Epoch 24/75\n",
            "646/646 - 2s - loss: 0.4132 - auc: 0.7033 - accuracy: 0.8336\n",
            "Epoch 25/75\n",
            "646/646 - 2s - loss: 0.4132 - auc: 0.7034 - accuracy: 0.8336\n",
            "Epoch 26/75\n",
            "646/646 - 2s - loss: 0.4131 - auc: 0.7036 - accuracy: 0.8337\n",
            "Epoch 27/75\n",
            "646/646 - 2s - loss: 0.4131 - auc: 0.7037 - accuracy: 0.8337\n",
            "Epoch 28/75\n",
            "646/646 - 2s - loss: 0.4130 - auc: 0.7040 - accuracy: 0.8337\n",
            "Epoch 29/75\n",
            "646/646 - 2s - loss: 0.4129 - auc: 0.7040 - accuracy: 0.8337\n",
            "Epoch 30/75\n",
            "646/646 - 2s - loss: 0.4129 - auc: 0.7041 - accuracy: 0.8336\n",
            "Epoch 31/75\n",
            "646/646 - 2s - loss: 0.4128 - auc: 0.7043 - accuracy: 0.8337\n",
            "Epoch 32/75\n",
            "646/646 - 2s - loss: 0.4128 - auc: 0.7044 - accuracy: 0.8337\n",
            "Epoch 33/75\n",
            "646/646 - 2s - loss: 0.4128 - auc: 0.7044 - accuracy: 0.8337\n",
            "Epoch 34/75\n",
            "646/646 - 2s - loss: 0.4127 - auc: 0.7045 - accuracy: 0.8337\n",
            "Epoch 35/75\n",
            "646/646 - 2s - loss: 0.4127 - auc: 0.7046 - accuracy: 0.8336\n",
            "Epoch 36/75\n",
            "646/646 - 2s - loss: 0.4126 - auc: 0.7047 - accuracy: 0.8337\n",
            "Epoch 37/75\n",
            "646/646 - 2s - loss: 0.4126 - auc: 0.7049 - accuracy: 0.8336\n",
            "Epoch 38/75\n",
            "646/646 - 2s - loss: 0.4126 - auc: 0.7049 - accuracy: 0.8337\n",
            "Epoch 39/75\n",
            "646/646 - 2s - loss: 0.4126 - auc: 0.7049 - accuracy: 0.8337\n",
            "Epoch 40/75\n",
            "646/646 - 2s - loss: 0.4126 - auc: 0.7048 - accuracy: 0.8338\n",
            "Epoch 41/75\n",
            "646/646 - 2s - loss: 0.4125 - auc: 0.7050 - accuracy: 0.8338\n",
            "Epoch 42/75\n",
            "646/646 - 2s - loss: 0.4125 - auc: 0.7052 - accuracy: 0.8338\n",
            "Epoch 43/75\n",
            "646/646 - 2s - loss: 0.4125 - auc: 0.7050 - accuracy: 0.8338\n",
            "Epoch 44/75\n",
            "646/646 - 2s - loss: 0.4125 - auc: 0.7051 - accuracy: 0.8338\n",
            "Epoch 45/75\n",
            "646/646 - 2s - loss: 0.4124 - auc: 0.7053 - accuracy: 0.8337\n",
            "Epoch 46/75\n",
            "646/646 - 2s - loss: 0.4124 - auc: 0.7053 - accuracy: 0.8338\n",
            "Epoch 47/75\n",
            "646/646 - 2s - loss: 0.4123 - auc: 0.7054 - accuracy: 0.8337\n",
            "Epoch 48/75\n",
            "646/646 - 2s - loss: 0.4123 - auc: 0.7054 - accuracy: 0.8338\n",
            "Epoch 49/75\n",
            "646/646 - 2s - loss: 0.4123 - auc: 0.7055 - accuracy: 0.8338\n",
            "Epoch 50/75\n",
            "646/646 - 2s - loss: 0.4123 - auc: 0.7055 - accuracy: 0.8338\n",
            "Epoch 51/75\n",
            "646/646 - 2s - loss: 0.4122 - auc: 0.7056 - accuracy: 0.8337\n",
            "Epoch 52/75\n",
            "646/646 - 2s - loss: 0.4122 - auc: 0.7056 - accuracy: 0.8338\n",
            "Epoch 53/75\n",
            "646/646 - 2s - loss: 0.4122 - auc: 0.7057 - accuracy: 0.8338\n",
            "Epoch 54/75\n",
            "646/646 - 2s - loss: 0.4122 - auc: 0.7057 - accuracy: 0.8338\n",
            "Epoch 55/75\n",
            "646/646 - 2s - loss: 0.4122 - auc: 0.7058 - accuracy: 0.8337\n",
            "Epoch 56/75\n",
            "646/646 - 2s - loss: 0.4121 - auc: 0.7058 - accuracy: 0.8338\n",
            "Epoch 57/75\n",
            "646/646 - 2s - loss: 0.4121 - auc: 0.7059 - accuracy: 0.8338\n",
            "Epoch 58/75\n",
            "646/646 - 2s - loss: 0.4121 - auc: 0.7060 - accuracy: 0.8338\n",
            "Epoch 59/75\n",
            "646/646 - 2s - loss: 0.4121 - auc: 0.7061 - accuracy: 0.8338\n",
            "Epoch 60/75\n",
            "646/646 - 2s - loss: 0.4121 - auc: 0.7061 - accuracy: 0.8339\n",
            "Epoch 61/75\n",
            "646/646 - 2s - loss: 0.4121 - auc: 0.7060 - accuracy: 0.8338\n",
            "Epoch 62/75\n",
            "646/646 - 2s - loss: 0.4120 - auc: 0.7061 - accuracy: 0.8339\n",
            "Epoch 63/75\n",
            "646/646 - 2s - loss: 0.4120 - auc: 0.7062 - accuracy: 0.8339\n",
            "Epoch 64/75\n",
            "646/646 - 2s - loss: 0.4120 - auc: 0.7062 - accuracy: 0.8338\n",
            "Epoch 65/75\n",
            "646/646 - 2s - loss: 0.4120 - auc: 0.7062 - accuracy: 0.8339\n",
            "Epoch 66/75\n",
            "646/646 - 2s - loss: 0.4120 - auc: 0.7061 - accuracy: 0.8337\n",
            "Epoch 67/75\n",
            "646/646 - 2s - loss: 0.4120 - auc: 0.7063 - accuracy: 0.8339\n",
            "Epoch 68/75\n",
            "646/646 - 2s - loss: 0.4119 - auc: 0.7064 - accuracy: 0.8339\n",
            "Epoch 69/75\n",
            "646/646 - 2s - loss: 0.4119 - auc: 0.7065 - accuracy: 0.8339\n",
            "Epoch 70/75\n",
            "646/646 - 2s - loss: 0.4119 - auc: 0.7063 - accuracy: 0.8337\n",
            "Epoch 71/75\n",
            "646/646 - 2s - loss: 0.4119 - auc: 0.7064 - accuracy: 0.8338\n",
            "Epoch 72/75\n",
            "646/646 - 2s - loss: 0.4119 - auc: 0.7066 - accuracy: 0.8339\n",
            "Epoch 73/75\n",
            "646/646 - 2s - loss: 0.4119 - auc: 0.7065 - accuracy: 0.8339\n",
            "Epoch 74/75\n",
            "646/646 - 2s - loss: 0.4119 - auc: 0.7065 - accuracy: 0.8338\n",
            "Epoch 75/75\n",
            "646/646 - 2s - loss: 0.4119 - auc: 0.7065 - accuracy: 0.8338\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=0, shuffle=True),\n",
              "             error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('under',\n",
              "                                        RandomUnderSampler(random_state=None,\n",
              "                                                           ratio=None,\n",
              "                                                           replacement=False,\n",
              "                                                           return_indices=False,\n",
              "                                                           sampling_strategy='auto')),\n",
              "                                       ('model',\n",
              "                                        <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fd4d3836668>)],\n",
              "                                verb...\n",
              "                      'average_precision': make_scorer(average_precision_score, needs_proba=True),\n",
              "                      'balanced_accuracy': make_scorer(balanced_accuracy_score),\n",
              "                      'f1': make_scorer(f1_score),\n",
              "                      'loan_loss': make_scorer(calcCostRev, greater_is_better=False, needs_proba=True, cost=(1, 3.7), returnThreshold=False),\n",
              "                      'neg_brier_score': make_scorer(brier_score_loss, needs_proba=True),\n",
              "                      'roc_auc': make_scorer(roc_auc_score, needs_proba=True)},\n",
              "             verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7wNjfXVgztU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Assign results of gridsearch\n",
        "results_Grid2_NN_2 = gridNN.cv_results_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwFO02kCgmte",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "c9a46dc2-bdbb-4840-8991-07fb776c041c"
      },
      "source": [
        "#Best parameters based on AUC:\n",
        "ind = np.argmin(results_Grid2_NN_2['rank_test_roc_auc'])\n",
        "print('Parameters:', results_Grid2_NN_2['params'][ind])\n",
        "print('ROC-AUC:', results_Grid2_NN_2['mean_test_roc_auc'][ind])\n",
        "print('F1:', results_Grid2_NN_2['mean_test_f1'][ind])\n",
        "print('Accuracy:', results_Grid2_NN_2['mean_test_accuracy'][ind])\n",
        "print('Balanced Accuracy:', results_Grid2_NN_2['mean_test_balanced_accuracy'][ind])\n",
        "print('Loan Loss:', results_Grid2_NN_2['mean_test_loan_loss'][ind])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters: {'model__batch_size': 1000, 'model__epochs': 75, 'model__optim': 'adam', 'under': RandomUnderSampler(random_state=0, ratio=None, replacement=False,\n",
            "                   return_indices=False, sampling_strategy=0.2)}\n",
            "ROC-AUC: 0.6977989876477055\n",
            "F1: 0.04392049856764455\n",
            "Accuracy: 0.8463135839748256\n",
            "Balanced Accuracy: 0.5091485043524085\n",
            "Loan Loss: -130611.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOxqZ5wag-io",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "778759fc-b6c0-4508-feaa-a93ed7508803"
      },
      "source": [
        "#Best parameters based on Loan Loss:\n",
        "ind = np.argmin(results_Grid2_NN_2['rank_test_loan_loss'])\n",
        "print('Parameters:', results_Grid2_NN_2['params'][ind])\n",
        "print('ROC-AUC:', results_Grid2_NN_2['mean_test_roc_auc'][ind])\n",
        "print('F1:', results_Grid2_NN_2['mean_test_f1'][ind])\n",
        "print('Accuracy:', results_Grid2_NN_2['mean_test_accuracy'][ind])\n",
        "print('Balanced Accuracy:', results_Grid2_NN_2['mean_test_balanced_accuracy'][ind])\n",
        "print('Loan Loss:', results_Grid2_NN_2['mean_test_loan_loss'][ind])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters: {'model__batch_size': 1000, 'model__epochs': 75, 'model__optim': 'rmsprop', 'under': RandomUnderSampler(random_state=0, ratio=None, replacement=False,\n",
            "                   return_indices=False, sampling_strategy=0.6)}\n",
            "ROC-AUC: 0.6966796492083605\n",
            "F1: 0.3378787973025011\n",
            "Accuracy: 0.7598267780900327\n",
            "Balanced Accuracy: 0.6130396371842498\n",
            "Loan Loss: -114222.40000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GkRoBeOtHYUg"
      },
      "source": [
        "# NN - Grid 3 - Fine tuning Undersampler.\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5nvuyZk7HYUm",
        "colab": {}
      },
      "source": [
        "#Setup pipeline.\n",
        "stepsNN = [('under', RandomUnderSampler(random_state=rs, sampling_strategy=0.6)), ('model', KerasClassifier(build_fn=create_model3, verbose=0))]\n",
        "pipelineNN = Pipeline(steps=stepsNN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eSZry7seHYU2",
        "colab": {}
      },
      "source": [
        "#Parameters for gridsearch.\n",
        "param_gridNN = [{'model__epochs': [75],\n",
        "              'model__batch_size': [1000],\n",
        "              'under': [RandomUnderSampler(sampling_strategy=0.3, random_state=rs),\n",
        "                        RandomUnderSampler(sampling_strategy=0.4, random_state=rs),\n",
        "                        RandomUnderSampler(sampling_strategy=0.5, random_state=rs),\n",
        "                        RandomUnderSampler(sampling_strategy=0.6, random_state=rs),\n",
        "                        RandomUnderSampler(sampling_strategy=0.7, random_state=rs),\n",
        "                        RandomUnderSampler(sampling_strategy=0.8, random_state=rs),\n",
        "                        RandomUnderSampler(sampling_strategy=0.9, random_state=rs)],\n",
        "                 'model__optim': ['rmsprop']}]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Y-wbiyuoHYVV",
        "colab": {}
      },
      "source": [
        "#Grid search object.\n",
        "gridNN = GridSearchCV(pipelineNN, param_grid=param_gridNN, scoring=scoringDict2, cv = kFold2, verbose=0,\n",
        "                                        refit='roc_auc', n_jobs=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zqn8W-POHYVn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2316ec71-0dc4-438e-e7e0-a69146ddf897"
      },
      "source": [
        "#Cross validation using grid search.\n",
        "gridNN.fit(X=dfPostImpute[trainAll], y=trainLabels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py:264: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use `model.predict()` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=0, shuffle=True),\n",
              "             error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('under',\n",
              "                                        RandomUnderSampler(random_state=0,\n",
              "                                                           ratio=None,\n",
              "                                                           replacement=False,\n",
              "                                                           return_indices=False,\n",
              "                                                           sampling_strategy=0.6)),\n",
              "                                       ('model',\n",
              "                                        <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7fd4d3835e80>)],\n",
              "                                verbose=Fa...\n",
              "                      'average_precision': make_scorer(average_precision_score, needs_proba=True),\n",
              "                      'balanced_accuracy': make_scorer(balanced_accuracy_score),\n",
              "                      'f1': make_scorer(f1_score),\n",
              "                      'loan_loss': make_scorer(calcCostRev, greater_is_better=False, needs_proba=True, cost=(1, 3.7), returnThreshold=False),\n",
              "                      'neg_brier_score': make_scorer(brier_score_loss, needs_proba=True),\n",
              "                      'roc_auc': make_scorer(roc_auc_score, needs_proba=True)},\n",
              "             verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi00l44AvB25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Assign results of grid search.\n",
        "results_Grid3_NN = gridNN.cv_results_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4fiPaANu1Y3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "bbdd6ea7-6c0a-4763-ac6f-35a1c37eeedf"
      },
      "source": [
        "#Best parameters based on AUC:\n",
        "ind = np.argmin(results_Grid3_NN['rank_test_roc_auc'])\n",
        "print('Parameters:', results_Grid3_NN['params'][ind])\n",
        "print('ROC-AUC:', results_Grid3_NN['mean_test_roc_auc'][ind])\n",
        "print('F1:', results_Grid3_NN['mean_test_f1'][ind])\n",
        "print('Accuracy:', results_Grid3_NN['mean_test_accuracy'][ind])\n",
        "print('Balanced Accuracy:', results_Grid3_NN['mean_test_balanced_accuracy'][ind])\n",
        "print('Loan Loss:', results_Grid3_NN['mean_test_loan_loss'][ind])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters: {'model__batch_size': 1000, 'model__epochs': 75, 'model__optim': 'rmsprop', 'under': RandomUnderSampler(random_state=0, ratio=None, replacement=False,\n",
            "                   return_indices=False, sampling_strategy=0.3)}\n",
            "ROC-AUC: 0.6973125094948979\n",
            "F1: 0.13513223141187106\n",
            "Accuracy: 0.8408566548008514\n",
            "Balanced Accuracy: 0.5297507172100174\n",
            "Loan Loss: -126255.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH9JGnn60H1P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "b938a8cf-840e-4d9b-8663-400b315550f9"
      },
      "source": [
        "#Best parameters based on loan loss:\n",
        "ind = np.argmin(results_Grid3_NN['rank_test_loan_loss'])\n",
        "print('Parameters:', results_Grid3_NN['params'][ind])\n",
        "print('ROC-AUC:', results_Grid3_NN['mean_test_roc_auc'][ind])\n",
        "print('F1:', results_Grid3_NN['mean_test_f1'][ind])\n",
        "print('Accuracy:', results_Grid3_NN['mean_test_accuracy'][ind])\n",
        "print('Balanced Accuracy:', results_Grid3_NN['mean_test_balanced_accuracy'][ind])\n",
        "print('Loan Loss:', results_Grid3_NN['mean_test_loan_loss'][ind])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters: {'model__batch_size': 1000, 'model__epochs': 75, 'model__optim': 'rmsprop', 'under': RandomUnderSampler(random_state=0, ratio=None, replacement=False,\n",
            "                   return_indices=False, sampling_strategy=0.7)}\n",
            "ROC-AUC: 0.6964972230277678\n",
            "F1: 0.35104766148273847\n",
            "Accuracy: 0.727946329191048\n",
            "Balanced Accuracy: 0.6265844125943969\n",
            "Loan Loss: -114034.23333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "B0OiB3NFkJfm"
      },
      "source": [
        "# NN: Differemt Architectures\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z93m2ymVr_bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "512befb0-b0c9-41ee-c876-50533172a01d"
      },
      "source": [
        "#First architecture\n",
        "cvModel1 = cross_validate(estimator=KerasClassifier(build_fn=create_model1, verbose=2, optim = 'rmsprop'), X=dfPostImpute[trainAll], y=trainLabels, scoring=scoringDict2, cv = kFold,\n",
        "                          fit_params = dict(batch_size=1000, epochs=75))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "469/469 - 2s - loss: 0.4120 - auc: 0.6920 - accuracy: 0.8421\n",
            "Epoch 2/75\n",
            "469/469 - 2s - loss: 0.4016 - auc: 0.6806 - accuracy: 0.8465\n",
            "Epoch 3/75\n",
            "469/469 - 2s - loss: 0.4003 - auc: 0.6842 - accuracy: 0.8465\n",
            "Epoch 4/75\n",
            "469/469 - 2s - loss: 0.3995 - auc: 0.6867 - accuracy: 0.8466\n",
            "Epoch 5/75\n",
            "469/469 - 2s - loss: 0.3993 - auc: 0.6876 - accuracy: 0.8467\n",
            "Epoch 6/75\n",
            "469/469 - 2s - loss: 0.3990 - auc: 0.6884 - accuracy: 0.8468\n",
            "Epoch 7/75\n",
            "469/469 - 2s - loss: 0.3985 - auc: 0.6899 - accuracy: 0.8467\n",
            "Epoch 8/75\n",
            "469/469 - 2s - loss: 0.3985 - auc: 0.6900 - accuracy: 0.8467\n",
            "Epoch 9/75\n",
            "469/469 - 2s - loss: 0.3983 - auc: 0.6906 - accuracy: 0.8467\n",
            "Epoch 10/75\n",
            "469/469 - 2s - loss: 0.3980 - auc: 0.6913 - accuracy: 0.8468\n",
            "Epoch 11/75\n",
            "469/469 - 2s - loss: 0.3978 - auc: 0.6916 - accuracy: 0.8468\n",
            "Epoch 12/75\n",
            "469/469 - 2s - loss: 0.3978 - auc: 0.6919 - accuracy: 0.8467\n",
            "Epoch 13/75\n",
            "469/469 - 2s - loss: 0.3980 - auc: 0.6912 - accuracy: 0.8469\n",
            "Epoch 14/75\n",
            "469/469 - 2s - loss: 0.3976 - auc: 0.6923 - accuracy: 0.8468\n",
            "Epoch 15/75\n",
            "469/469 - 2s - loss: 0.3976 - auc: 0.6925 - accuracy: 0.8467\n",
            "Epoch 16/75\n",
            "469/469 - 2s - loss: 0.3974 - auc: 0.6931 - accuracy: 0.8468\n",
            "Epoch 17/75\n",
            "469/469 - 2s - loss: 0.3974 - auc: 0.6930 - accuracy: 0.8469\n",
            "Epoch 18/75\n",
            "469/469 - 2s - loss: 0.3971 - auc: 0.6936 - accuracy: 0.8468\n",
            "Epoch 19/75\n",
            "469/469 - 2s - loss: 0.3971 - auc: 0.6938 - accuracy: 0.8469\n",
            "Epoch 20/75\n",
            "469/469 - 2s - loss: 0.3971 - auc: 0.6939 - accuracy: 0.8467\n",
            "Epoch 21/75\n",
            "469/469 - 2s - loss: 0.3971 - auc: 0.6940 - accuracy: 0.8469\n",
            "Epoch 22/75\n",
            "469/469 - 2s - loss: 0.3969 - auc: 0.6944 - accuracy: 0.8467\n",
            "Epoch 23/75\n",
            "469/469 - 2s - loss: 0.3970 - auc: 0.6942 - accuracy: 0.8468\n",
            "Epoch 24/75\n",
            "469/469 - 2s - loss: 0.3968 - auc: 0.6947 - accuracy: 0.8468\n",
            "Epoch 25/75\n",
            "469/469 - 2s - loss: 0.3969 - auc: 0.6944 - accuracy: 0.8468\n",
            "Epoch 26/75\n",
            "469/469 - 2s - loss: 0.3969 - auc: 0.6944 - accuracy: 0.8468\n",
            "Epoch 27/75\n",
            "469/469 - 2s - loss: 0.3968 - auc: 0.6946 - accuracy: 0.8469\n",
            "Epoch 28/75\n",
            "469/469 - 2s - loss: 0.3967 - auc: 0.6951 - accuracy: 0.8467\n",
            "Epoch 29/75\n",
            "469/469 - 2s - loss: 0.3967 - auc: 0.6948 - accuracy: 0.8468\n",
            "Epoch 30/75\n",
            "469/469 - 2s - loss: 0.3966 - auc: 0.6952 - accuracy: 0.8468\n",
            "Epoch 31/75\n",
            "469/469 - 2s - loss: 0.3964 - auc: 0.6958 - accuracy: 0.8469\n",
            "Epoch 32/75\n",
            "469/469 - 2s - loss: 0.3966 - auc: 0.6953 - accuracy: 0.8468\n",
            "Epoch 33/75\n",
            "469/469 - 2s - loss: 0.3964 - auc: 0.6959 - accuracy: 0.8467\n",
            "Epoch 34/75\n",
            "469/469 - 2s - loss: 0.3965 - auc: 0.6955 - accuracy: 0.8467\n",
            "Epoch 35/75\n",
            "469/469 - 2s - loss: 0.3963 - auc: 0.6960 - accuracy: 0.8468\n",
            "Epoch 36/75\n",
            "469/469 - 2s - loss: 0.3964 - auc: 0.6960 - accuracy: 0.8467\n",
            "Epoch 37/75\n",
            "469/469 - 2s - loss: 0.3962 - auc: 0.6962 - accuracy: 0.8469\n",
            "Epoch 38/75\n",
            "469/469 - 2s - loss: 0.3962 - auc: 0.6963 - accuracy: 0.8469\n",
            "Epoch 39/75\n",
            "469/469 - 2s - loss: 0.3962 - auc: 0.6964 - accuracy: 0.8469\n",
            "Epoch 40/75\n",
            "469/469 - 2s - loss: 0.3963 - auc: 0.6961 - accuracy: 0.8468\n",
            "Epoch 41/75\n",
            "469/469 - 2s - loss: 0.3960 - auc: 0.6968 - accuracy: 0.8468\n",
            "Epoch 42/75\n",
            "469/469 - 2s - loss: 0.3961 - auc: 0.6966 - accuracy: 0.8468\n",
            "Epoch 43/75\n",
            "469/469 - 2s - loss: 0.3962 - auc: 0.6965 - accuracy: 0.8467\n",
            "Epoch 44/75\n",
            "469/469 - 2s - loss: 0.3960 - auc: 0.6967 - accuracy: 0.8468\n",
            "Epoch 45/75\n",
            "469/469 - 2s - loss: 0.3959 - auc: 0.6973 - accuracy: 0.8468\n",
            "Epoch 46/75\n",
            "469/469 - 2s - loss: 0.3960 - auc: 0.6968 - accuracy: 0.8470\n",
            "Epoch 47/75\n",
            "469/469 - 2s - loss: 0.3958 - auc: 0.6976 - accuracy: 0.8468\n",
            "Epoch 48/75\n",
            "469/469 - 2s - loss: 0.3958 - auc: 0.6976 - accuracy: 0.8469\n",
            "Epoch 49/75\n",
            "469/469 - 2s - loss: 0.3958 - auc: 0.6973 - accuracy: 0.8469\n",
            "Epoch 50/75\n",
            "469/469 - 2s - loss: 0.3959 - auc: 0.6973 - accuracy: 0.8468\n",
            "Epoch 51/75\n",
            "469/469 - 2s - loss: 0.3957 - auc: 0.6977 - accuracy: 0.8469\n",
            "Epoch 52/75\n",
            "469/469 - 2s - loss: 0.3956 - auc: 0.6979 - accuracy: 0.8468\n",
            "Epoch 53/75\n",
            "469/469 - 2s - loss: 0.3957 - auc: 0.6977 - accuracy: 0.8468\n",
            "Epoch 54/75\n",
            "469/469 - 2s - loss: 0.3957 - auc: 0.6978 - accuracy: 0.8469\n",
            "Epoch 55/75\n",
            "469/469 - 2s - loss: 0.3956 - auc: 0.6980 - accuracy: 0.8468\n",
            "Epoch 56/75\n",
            "469/469 - 2s - loss: 0.3957 - auc: 0.6978 - accuracy: 0.8468\n",
            "Epoch 57/75\n",
            "469/469 - 2s - loss: 0.3957 - auc: 0.6978 - accuracy: 0.8468\n",
            "Epoch 58/75\n",
            "469/469 - 2s - loss: 0.3953 - auc: 0.6986 - accuracy: 0.8470\n",
            "Epoch 59/75\n",
            "469/469 - 2s - loss: 0.3954 - auc: 0.6985 - accuracy: 0.8468\n",
            "Epoch 60/75\n",
            "469/469 - 2s - loss: 0.3955 - auc: 0.6982 - accuracy: 0.8468\n",
            "Epoch 61/75\n",
            "469/469 - 2s - loss: 0.3954 - auc: 0.6984 - accuracy: 0.8468\n",
            "Epoch 62/75\n",
            "469/469 - 2s - loss: 0.3954 - auc: 0.6986 - accuracy: 0.8468\n",
            "Epoch 63/75\n",
            "469/469 - 2s - loss: 0.3953 - auc: 0.6989 - accuracy: 0.8468\n",
            "Epoch 64/75\n",
            "469/469 - 2s - loss: 0.3955 - auc: 0.6984 - accuracy: 0.8468\n",
            "Epoch 65/75\n",
            "469/469 - 2s - loss: 0.3954 - auc: 0.6985 - accuracy: 0.8469\n",
            "Epoch 66/75\n",
            "469/469 - 2s - loss: 0.3953 - auc: 0.6989 - accuracy: 0.8468\n",
            "Epoch 67/75\n",
            "469/469 - 2s - loss: 0.3954 - auc: 0.6987 - accuracy: 0.8468\n",
            "Epoch 68/75\n",
            "469/469 - 2s - loss: 0.3952 - auc: 0.6991 - accuracy: 0.8468\n",
            "Epoch 69/75\n",
            "469/469 - 2s - loss: 0.3953 - auc: 0.6988 - accuracy: 0.8469\n",
            "Epoch 70/75\n",
            "469/469 - 2s - loss: 0.3951 - auc: 0.6992 - accuracy: 0.8469\n",
            "Epoch 71/75\n",
            "469/469 - 2s - loss: 0.3952 - auc: 0.6991 - accuracy: 0.8468\n",
            "Epoch 72/75\n",
            "469/469 - 2s - loss: 0.3952 - auc: 0.6990 - accuracy: 0.8469\n",
            "Epoch 73/75\n",
            "469/469 - 2s - loss: 0.3953 - auc: 0.6988 - accuracy: 0.8468\n",
            "Epoch 74/75\n",
            "469/469 - 2s - loss: 0.3953 - auc: 0.6987 - accuracy: 0.8469\n",
            "Epoch 75/75\n",
            "469/469 - 2s - loss: 0.3949 - auc: 0.7000 - accuracy: 0.8468\n",
            "7319/7319 - 6s\n",
            "7319/7319 - 6s\n",
            "Epoch 1/75\n",
            "469/469 - 2s - loss: 0.4107 - auc: 0.6810 - accuracy: 0.8427\n",
            "Epoch 2/75\n",
            "469/469 - 2s - loss: 0.4015 - auc: 0.6812 - accuracy: 0.8465\n",
            "Epoch 3/75\n",
            "469/469 - 2s - loss: 0.4003 - auc: 0.6848 - accuracy: 0.8464\n",
            "Epoch 4/75\n",
            "469/469 - 2s - loss: 0.3995 - auc: 0.6867 - accuracy: 0.8464\n",
            "Epoch 5/75\n",
            "469/469 - 2s - loss: 0.3990 - auc: 0.6883 - accuracy: 0.8466\n",
            "Epoch 6/75\n",
            "469/469 - 2s - loss: 0.3986 - auc: 0.6896 - accuracy: 0.8466\n",
            "Epoch 7/75\n",
            "469/469 - 2s - loss: 0.3984 - auc: 0.6900 - accuracy: 0.8466\n",
            "Epoch 8/75\n",
            "469/469 - 2s - loss: 0.3983 - auc: 0.6906 - accuracy: 0.8466\n",
            "Epoch 9/75\n",
            "469/469 - 2s - loss: 0.3979 - auc: 0.6917 - accuracy: 0.8466\n",
            "Epoch 10/75\n",
            "469/469 - 2s - loss: 0.3979 - auc: 0.6916 - accuracy: 0.8467\n",
            "Epoch 11/75\n",
            "469/469 - 2s - loss: 0.3977 - auc: 0.6921 - accuracy: 0.8468\n",
            "Epoch 12/75\n",
            "469/469 - 2s - loss: 0.3974 - auc: 0.6931 - accuracy: 0.8467\n",
            "Epoch 13/75\n",
            "469/469 - 2s - loss: 0.3973 - auc: 0.6934 - accuracy: 0.8468\n",
            "Epoch 14/75\n",
            "469/469 - 2s - loss: 0.3972 - auc: 0.6934 - accuracy: 0.8468\n",
            "Epoch 15/75\n",
            "469/469 - 2s - loss: 0.3972 - auc: 0.6934 - accuracy: 0.8467\n",
            "Epoch 16/75\n",
            "469/469 - 2s - loss: 0.3971 - auc: 0.6941 - accuracy: 0.8467\n",
            "Epoch 17/75\n",
            "469/469 - 2s - loss: 0.3971 - auc: 0.6936 - accuracy: 0.8468\n",
            "Epoch 18/75\n",
            "469/469 - 2s - loss: 0.3969 - auc: 0.6945 - accuracy: 0.8468\n",
            "Epoch 19/75\n",
            "469/469 - 2s - loss: 0.3969 - auc: 0.6944 - accuracy: 0.8468\n",
            "Epoch 20/75\n",
            "469/469 - 2s - loss: 0.3968 - auc: 0.6945 - accuracy: 0.8469\n",
            "Epoch 21/75\n",
            "469/469 - 2s - loss: 0.3967 - auc: 0.6949 - accuracy: 0.8467\n",
            "Epoch 22/75\n",
            "469/469 - 2s - loss: 0.3968 - auc: 0.6947 - accuracy: 0.8468\n",
            "Epoch 23/75\n",
            "469/469 - 2s - loss: 0.3965 - auc: 0.6955 - accuracy: 0.8468\n",
            "Epoch 24/75\n",
            "469/469 - 2s - loss: 0.3966 - auc: 0.6952 - accuracy: 0.8468\n",
            "Epoch 25/75\n",
            "469/469 - 2s - loss: 0.3967 - auc: 0.6950 - accuracy: 0.8468\n",
            "Epoch 26/75\n",
            "469/469 - 2s - loss: 0.3965 - auc: 0.6957 - accuracy: 0.8468\n",
            "Epoch 27/75\n",
            "469/469 - 2s - loss: 0.3964 - auc: 0.6956 - accuracy: 0.8469\n",
            "Epoch 28/75\n",
            "469/469 - 2s - loss: 0.3963 - auc: 0.6961 - accuracy: 0.8468\n",
            "Epoch 29/75\n",
            "469/469 - 2s - loss: 0.3964 - auc: 0.6960 - accuracy: 0.8468\n",
            "Epoch 30/75\n",
            "469/469 - 2s - loss: 0.3963 - auc: 0.6962 - accuracy: 0.8468\n",
            "Epoch 31/75\n",
            "469/469 - 2s - loss: 0.3963 - auc: 0.6960 - accuracy: 0.8468\n",
            "Epoch 32/75\n",
            "469/469 - 2s - loss: 0.3962 - auc: 0.6963 - accuracy: 0.8468\n",
            "Epoch 33/75\n",
            "469/469 - 2s - loss: 0.3962 - auc: 0.6965 - accuracy: 0.8468\n",
            "Epoch 34/75\n",
            "469/469 - 2s - loss: 0.3961 - auc: 0.6966 - accuracy: 0.8468\n",
            "Epoch 35/75\n",
            "469/469 - 2s - loss: 0.3962 - auc: 0.6963 - accuracy: 0.8468\n",
            "Epoch 36/75\n",
            "469/469 - 2s - loss: 0.3961 - auc: 0.6967 - accuracy: 0.8468\n",
            "Epoch 37/75\n",
            "469/469 - 2s - loss: 0.3959 - auc: 0.6973 - accuracy: 0.8468\n",
            "Epoch 38/75\n",
            "469/469 - 2s - loss: 0.3959 - auc: 0.6972 - accuracy: 0.8469\n",
            "Epoch 39/75\n",
            "469/469 - 2s - loss: 0.3961 - auc: 0.6968 - accuracy: 0.8468\n",
            "Epoch 40/75\n",
            "469/469 - 2s - loss: 0.3957 - auc: 0.6977 - accuracy: 0.8469\n",
            "Epoch 41/75\n",
            "469/469 - 2s - loss: 0.3958 - auc: 0.6976 - accuracy: 0.8469\n",
            "Epoch 42/75\n",
            "469/469 - 2s - loss: 0.3958 - auc: 0.6976 - accuracy: 0.8469\n",
            "Epoch 43/75\n",
            "469/469 - 2s - loss: 0.3958 - auc: 0.6975 - accuracy: 0.8469\n",
            "Epoch 44/75\n",
            "469/469 - 2s - loss: 0.3955 - auc: 0.6980 - accuracy: 0.8469\n",
            "Epoch 45/75\n",
            "469/469 - 2s - loss: 0.3957 - auc: 0.6978 - accuracy: 0.8467\n",
            "Epoch 46/75\n",
            "469/469 - 2s - loss: 0.3956 - auc: 0.6981 - accuracy: 0.8468\n",
            "Epoch 47/75\n",
            "469/469 - 2s - loss: 0.3956 - auc: 0.6981 - accuracy: 0.8468\n",
            "Epoch 48/75\n",
            "469/469 - 2s - loss: 0.3958 - auc: 0.6975 - accuracy: 0.8468\n",
            "Epoch 49/75\n",
            "469/469 - 2s - loss: 0.3957 - auc: 0.6979 - accuracy: 0.8468\n",
            "Epoch 50/75\n",
            "469/469 - 2s - loss: 0.3956 - auc: 0.6982 - accuracy: 0.8469\n",
            "Epoch 51/75\n",
            "469/469 - 2s - loss: 0.3955 - auc: 0.6984 - accuracy: 0.8467\n",
            "Epoch 52/75\n",
            "469/469 - 2s - loss: 0.3953 - auc: 0.6989 - accuracy: 0.8469\n",
            "Epoch 53/75\n",
            "469/469 - 2s - loss: 0.3954 - auc: 0.6987 - accuracy: 0.8468\n",
            "Epoch 54/75\n",
            "469/469 - 2s - loss: 0.3953 - auc: 0.6988 - accuracy: 0.8469\n",
            "Epoch 55/75\n",
            "469/469 - 2s - loss: 0.3955 - auc: 0.6984 - accuracy: 0.8469\n",
            "Epoch 56/75\n",
            "469/469 - 2s - loss: 0.3953 - auc: 0.6988 - accuracy: 0.8468\n",
            "Epoch 57/75\n",
            "469/469 - 2s - loss: 0.3954 - auc: 0.6985 - accuracy: 0.8468\n",
            "Epoch 58/75\n",
            "469/469 - 2s - loss: 0.3954 - auc: 0.6987 - accuracy: 0.8468\n",
            "Epoch 59/75\n",
            "469/469 - 2s - loss: 0.3953 - auc: 0.6990 - accuracy: 0.8468\n",
            "Epoch 60/75\n",
            "469/469 - 2s - loss: 0.3952 - auc: 0.6991 - accuracy: 0.8468\n",
            "Epoch 61/75\n",
            "469/469 - 2s - loss: 0.3950 - auc: 0.6996 - accuracy: 0.8469\n",
            "Epoch 62/75\n",
            "469/469 - 2s - loss: 0.3952 - auc: 0.6990 - accuracy: 0.8468\n",
            "Epoch 63/75\n",
            "469/469 - 2s - loss: 0.3952 - auc: 0.6993 - accuracy: 0.8468\n",
            "Epoch 64/75\n",
            "469/469 - 2s - loss: 0.3950 - auc: 0.6997 - accuracy: 0.8469\n",
            "Epoch 65/75\n",
            "469/469 - 2s - loss: 0.3952 - auc: 0.6992 - accuracy: 0.8468\n",
            "Epoch 66/75\n",
            "469/469 - 2s - loss: 0.3950 - auc: 0.6998 - accuracy: 0.8468\n",
            "Epoch 67/75\n",
            "469/469 - 2s - loss: 0.3952 - auc: 0.6993 - accuracy: 0.8468\n",
            "Epoch 68/75\n",
            "469/469 - 2s - loss: 0.3949 - auc: 0.7000 - accuracy: 0.8469\n",
            "Epoch 69/75\n",
            "469/469 - 2s - loss: 0.3950 - auc: 0.6998 - accuracy: 0.8468\n",
            "Epoch 70/75\n",
            "469/469 - 2s - loss: 0.3949 - auc: 0.7000 - accuracy: 0.8469\n",
            "Epoch 71/75\n",
            "469/469 - 2s - loss: 0.3948 - auc: 0.7002 - accuracy: 0.8469\n",
            "Epoch 72/75\n",
            "469/469 - 2s - loss: 0.3950 - auc: 0.6997 - accuracy: 0.8468\n",
            "Epoch 73/75\n",
            "469/469 - 2s - loss: 0.3947 - auc: 0.7004 - accuracy: 0.8469\n",
            "Epoch 74/75\n",
            "469/469 - 2s - loss: 0.3950 - auc: 0.6998 - accuracy: 0.8468\n",
            "Epoch 75/75\n",
            "469/469 - 2s - loss: 0.3950 - auc: 0.6997 - accuracy: 0.8469\n",
            "7319/7319 - 6s\n",
            "7319/7319 - 6s\n",
            "Epoch 1/75\n",
            "469/469 - 2s - loss: 0.4090 - auc: 0.6825 - accuracy: 0.8439\n",
            "Epoch 2/75\n",
            "469/469 - 2s - loss: 0.4009 - auc: 0.6829 - accuracy: 0.8462\n",
            "Epoch 3/75\n",
            "469/469 - 2s - loss: 0.3998 - auc: 0.6862 - accuracy: 0.8465\n",
            "Epoch 4/75\n",
            "469/469 - 2s - loss: 0.3990 - auc: 0.6886 - accuracy: 0.8466\n",
            "Epoch 5/75\n",
            "469/469 - 2s - loss: 0.3984 - auc: 0.6901 - accuracy: 0.8467\n",
            "Epoch 6/75\n",
            "469/469 - 2s - loss: 0.3982 - auc: 0.6906 - accuracy: 0.8467\n",
            "Epoch 7/75\n",
            "469/469 - 2s - loss: 0.3980 - auc: 0.6916 - accuracy: 0.8467\n",
            "Epoch 8/75\n",
            "469/469 - 2s - loss: 0.3978 - auc: 0.6922 - accuracy: 0.8466\n",
            "Epoch 9/75\n",
            "469/469 - 2s - loss: 0.3975 - auc: 0.6929 - accuracy: 0.8468\n",
            "Epoch 10/75\n",
            "469/469 - 2s - loss: 0.3975 - auc: 0.6931 - accuracy: 0.8467\n",
            "Epoch 11/75\n",
            "469/469 - 2s - loss: 0.3973 - auc: 0.6935 - accuracy: 0.8467\n",
            "Epoch 12/75\n",
            "469/469 - 2s - loss: 0.3972 - auc: 0.6939 - accuracy: 0.8468\n",
            "Epoch 13/75\n",
            "469/469 - 2s - loss: 0.3971 - auc: 0.6940 - accuracy: 0.8469\n",
            "Epoch 14/75\n",
            "469/469 - 2s - loss: 0.3969 - auc: 0.6945 - accuracy: 0.8468\n",
            "Epoch 15/75\n",
            "469/469 - 2s - loss: 0.3968 - auc: 0.6947 - accuracy: 0.8468\n",
            "Epoch 16/75\n",
            "469/469 - 2s - loss: 0.3968 - auc: 0.6949 - accuracy: 0.8468\n",
            "Epoch 17/75\n",
            "469/469 - 2s - loss: 0.3966 - auc: 0.6956 - accuracy: 0.8468\n",
            "Epoch 18/75\n",
            "469/469 - 2s - loss: 0.3966 - auc: 0.6954 - accuracy: 0.8468\n",
            "Epoch 19/75\n",
            "469/469 - 2s - loss: 0.3965 - auc: 0.6957 - accuracy: 0.8468\n",
            "Epoch 20/75\n",
            "469/469 - 2s - loss: 0.3963 - auc: 0.6964 - accuracy: 0.8468\n",
            "Epoch 21/75\n",
            "469/469 - 2s - loss: 0.3964 - auc: 0.6959 - accuracy: 0.8468\n",
            "Epoch 22/75\n",
            "469/469 - 2s - loss: 0.3965 - auc: 0.6958 - accuracy: 0.8468\n",
            "Epoch 23/75\n",
            "469/469 - 2s - loss: 0.3964 - auc: 0.6961 - accuracy: 0.8468\n",
            "Epoch 24/75\n",
            "469/469 - 2s - loss: 0.3962 - auc: 0.6966 - accuracy: 0.8468\n",
            "Epoch 25/75\n",
            "469/469 - 2s - loss: 0.3960 - auc: 0.6970 - accuracy: 0.8468\n",
            "Epoch 26/75\n",
            "469/469 - 2s - loss: 0.3960 - auc: 0.6971 - accuracy: 0.8468\n",
            "Epoch 27/75\n",
            "469/469 - 2s - loss: 0.3959 - auc: 0.6974 - accuracy: 0.8468\n",
            "Epoch 28/75\n",
            "469/469 - 2s - loss: 0.3958 - auc: 0.6975 - accuracy: 0.8469\n",
            "Epoch 29/75\n",
            "469/469 - 2s - loss: 0.3962 - auc: 0.6966 - accuracy: 0.8468\n",
            "Epoch 30/75\n",
            "469/469 - 2s - loss: 0.3959 - auc: 0.6976 - accuracy: 0.8468\n",
            "Epoch 31/75\n",
            "469/469 - 2s - loss: 0.3959 - auc: 0.6974 - accuracy: 0.8468\n",
            "Epoch 32/75\n",
            "469/469 - 2s - loss: 0.3959 - auc: 0.6976 - accuracy: 0.8468\n",
            "Epoch 33/75\n",
            "469/469 - 2s - loss: 0.3957 - auc: 0.6980 - accuracy: 0.8469\n",
            "Epoch 34/75\n",
            "469/469 - 2s - loss: 0.3959 - auc: 0.6974 - accuracy: 0.8468\n",
            "Epoch 35/75\n",
            "469/469 - 2s - loss: 0.3956 - auc: 0.6982 - accuracy: 0.8469\n",
            "Epoch 36/75\n",
            "469/469 - 2s - loss: 0.3955 - auc: 0.6984 - accuracy: 0.8468\n",
            "Epoch 37/75\n",
            "469/469 - 2s - loss: 0.3958 - auc: 0.6976 - accuracy: 0.8468\n",
            "Epoch 38/75\n",
            "469/469 - 2s - loss: 0.3957 - auc: 0.6979 - accuracy: 0.8469\n",
            "Epoch 39/75\n",
            "469/469 - 2s - loss: 0.3956 - auc: 0.6983 - accuracy: 0.8469\n",
            "Epoch 40/75\n",
            "469/469 - 2s - loss: 0.3956 - auc: 0.6983 - accuracy: 0.8469\n",
            "Epoch 41/75\n",
            "469/469 - 2s - loss: 0.3956 - auc: 0.6985 - accuracy: 0.8467\n",
            "Epoch 42/75\n",
            "469/469 - 2s - loss: 0.3956 - auc: 0.6984 - accuracy: 0.8468\n",
            "Epoch 43/75\n",
            "469/469 - 2s - loss: 0.3953 - auc: 0.6991 - accuracy: 0.8468\n",
            "Epoch 44/75\n",
            "469/469 - 2s - loss: 0.3954 - auc: 0.6985 - accuracy: 0.8469\n",
            "Epoch 45/75\n",
            "469/469 - 2s - loss: 0.3953 - auc: 0.6992 - accuracy: 0.8468\n",
            "Epoch 46/75\n",
            "469/469 - 2s - loss: 0.3953 - auc: 0.6991 - accuracy: 0.8469\n",
            "Epoch 47/75\n",
            "469/469 - 2s - loss: 0.3953 - auc: 0.6989 - accuracy: 0.8468\n",
            "Epoch 48/75\n",
            "469/469 - 2s - loss: 0.3953 - auc: 0.6991 - accuracy: 0.8468\n",
            "Epoch 49/75\n",
            "469/469 - 2s - loss: 0.3951 - auc: 0.6996 - accuracy: 0.8468\n",
            "Epoch 50/75\n",
            "469/469 - 2s - loss: 0.3952 - auc: 0.6994 - accuracy: 0.8469\n",
            "Epoch 51/75\n",
            "469/469 - 2s - loss: 0.3951 - auc: 0.6997 - accuracy: 0.8469\n",
            "Epoch 52/75\n",
            "469/469 - 2s - loss: 0.3951 - auc: 0.6994 - accuracy: 0.8469\n",
            "Epoch 53/75\n",
            "469/469 - 2s - loss: 0.3953 - auc: 0.6992 - accuracy: 0.8468\n",
            "Epoch 54/75\n",
            "469/469 - 2s - loss: 0.3951 - auc: 0.6995 - accuracy: 0.8468\n",
            "Epoch 55/75\n",
            "469/469 - 2s - loss: 0.3952 - auc: 0.6994 - accuracy: 0.8468\n",
            "Epoch 56/75\n",
            "469/469 - 2s - loss: 0.3950 - auc: 0.6999 - accuracy: 0.8468\n",
            "Epoch 57/75\n",
            "469/469 - 2s - loss: 0.3951 - auc: 0.6998 - accuracy: 0.8468\n",
            "Epoch 58/75\n",
            "469/469 - 2s - loss: 0.3951 - auc: 0.6996 - accuracy: 0.8469\n",
            "Epoch 59/75\n",
            "469/469 - 2s - loss: 0.3949 - auc: 0.7000 - accuracy: 0.8468\n",
            "Epoch 60/75\n",
            "469/469 - 2s - loss: 0.3950 - auc: 0.6999 - accuracy: 0.8468\n",
            "Epoch 61/75\n",
            "469/469 - 2s - loss: 0.3950 - auc: 0.7000 - accuracy: 0.8468\n",
            "Epoch 62/75\n",
            "469/469 - 2s - loss: 0.3948 - auc: 0.7007 - accuracy: 0.8469\n",
            "Epoch 63/75\n",
            "469/469 - 2s - loss: 0.3948 - auc: 0.7005 - accuracy: 0.8469\n",
            "Epoch 64/75\n",
            "469/469 - 2s - loss: 0.3949 - auc: 0.7000 - accuracy: 0.8469\n",
            "Epoch 65/75\n",
            "469/469 - 2s - loss: 0.3949 - auc: 0.7003 - accuracy: 0.8469\n",
            "Epoch 66/75\n",
            "469/469 - 2s - loss: 0.3949 - auc: 0.7003 - accuracy: 0.8469\n",
            "Epoch 67/75\n",
            "469/469 - 2s - loss: 0.3946 - auc: 0.7010 - accuracy: 0.8468\n",
            "Epoch 68/75\n",
            "469/469 - 2s - loss: 0.3946 - auc: 0.7007 - accuracy: 0.8470\n",
            "Epoch 69/75\n",
            "469/469 - 2s - loss: 0.3948 - auc: 0.7003 - accuracy: 0.8468\n",
            "Epoch 70/75\n",
            "469/469 - 2s - loss: 0.3946 - auc: 0.7010 - accuracy: 0.8468\n",
            "Epoch 71/75\n",
            "469/469 - 2s - loss: 0.3947 - auc: 0.7007 - accuracy: 0.8469\n",
            "Epoch 72/75\n",
            "469/469 - 2s - loss: 0.3946 - auc: 0.7011 - accuracy: 0.8469\n",
            "Epoch 73/75\n",
            "469/469 - 2s - loss: 0.3946 - auc: 0.7009 - accuracy: 0.8469\n",
            "Epoch 74/75\n",
            "469/469 - 2s - loss: 0.3945 - auc: 0.7012 - accuracy: 0.8469\n",
            "Epoch 75/75\n",
            "469/469 - 2s - loss: 0.3946 - auc: 0.7009 - accuracy: 0.8468\n",
            "7319/7319 - 6s\n",
            "7319/7319 - 6s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8Wb01OyY4rXz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3c492eb6-bc51-465d-ab9e-6f2e4a235ec7"
      },
      "source": [
        "#Second architecture\n",
        "cvModel2 = cross_validate(estimator=KerasClassifier(build_fn=create_model2, verbose=2, optim = 'rmsprop'), X=dfPostImpute[trainAll], y=trainLabels, scoring=scoringDict2, cv = kFold,\n",
        "                fit_params = dict(batch_size=1000,\n",
        "                                  epochs=75))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "469/469 - 2s - loss: 0.4078 - auc: 0.6857 - accuracy: 0.8426\n",
            "Epoch 2/75\n",
            "469/469 - 2s - loss: 0.3976 - auc: 0.6923 - accuracy: 0.8467\n",
            "Epoch 3/75\n",
            "469/469 - 2s - loss: 0.3968 - auc: 0.6942 - accuracy: 0.8469\n",
            "Epoch 4/75\n",
            "469/469 - 2s - loss: 0.3962 - auc: 0.6958 - accuracy: 0.8469\n",
            "Epoch 5/75\n",
            "469/469 - 2s - loss: 0.3958 - auc: 0.6968 - accuracy: 0.8469\n",
            "Epoch 6/75\n",
            "469/469 - 2s - loss: 0.3954 - auc: 0.6979 - accuracy: 0.8470\n",
            "Epoch 7/75\n",
            "469/469 - 2s - loss: 0.3951 - auc: 0.6985 - accuracy: 0.8470\n",
            "Epoch 8/75\n",
            "469/469 - 2s - loss: 0.3949 - auc: 0.6993 - accuracy: 0.8470\n",
            "Epoch 9/75\n",
            "469/469 - 2s - loss: 0.3947 - auc: 0.6997 - accuracy: 0.8470\n",
            "Epoch 10/75\n",
            "469/469 - 2s - loss: 0.3945 - auc: 0.7003 - accuracy: 0.8469\n",
            "Epoch 11/75\n",
            "469/469 - 2s - loss: 0.3943 - auc: 0.7006 - accuracy: 0.8470\n",
            "Epoch 12/75\n",
            "469/469 - 2s - loss: 0.3942 - auc: 0.7010 - accuracy: 0.8470\n",
            "Epoch 13/75\n",
            "469/469 - 2s - loss: 0.3941 - auc: 0.7014 - accuracy: 0.8470\n",
            "Epoch 14/75\n",
            "469/469 - 2s - loss: 0.3939 - auc: 0.7016 - accuracy: 0.8471\n",
            "Epoch 15/75\n",
            "469/469 - 2s - loss: 0.3938 - auc: 0.7019 - accuracy: 0.8471\n",
            "Epoch 16/75\n",
            "469/469 - 2s - loss: 0.3938 - auc: 0.7022 - accuracy: 0.8471\n",
            "Epoch 17/75\n",
            "469/469 - 2s - loss: 0.3936 - auc: 0.7025 - accuracy: 0.8471\n",
            "Epoch 18/75\n",
            "469/469 - 2s - loss: 0.3935 - auc: 0.7027 - accuracy: 0.8471\n",
            "Epoch 19/75\n",
            "469/469 - 2s - loss: 0.3934 - auc: 0.7030 - accuracy: 0.8472\n",
            "Epoch 20/75\n",
            "469/469 - 2s - loss: 0.3933 - auc: 0.7033 - accuracy: 0.8471\n",
            "Epoch 21/75\n",
            "469/469 - 2s - loss: 0.3933 - auc: 0.7034 - accuracy: 0.8472\n",
            "Epoch 22/75\n",
            "469/469 - 2s - loss: 0.3932 - auc: 0.7037 - accuracy: 0.8471\n",
            "Epoch 23/75\n",
            "469/469 - 2s - loss: 0.3931 - auc: 0.7038 - accuracy: 0.8472\n",
            "Epoch 24/75\n",
            "469/469 - 2s - loss: 0.3931 - auc: 0.7039 - accuracy: 0.8472\n",
            "Epoch 25/75\n",
            "469/469 - 2s - loss: 0.3930 - auc: 0.7042 - accuracy: 0.8471\n",
            "Epoch 26/75\n",
            "469/469 - 2s - loss: 0.3929 - auc: 0.7042 - accuracy: 0.8472\n",
            "Epoch 27/75\n",
            "469/469 - 2s - loss: 0.3928 - auc: 0.7045 - accuracy: 0.8472\n",
            "Epoch 28/75\n",
            "469/469 - 2s - loss: 0.3928 - auc: 0.7046 - accuracy: 0.8473\n",
            "Epoch 29/75\n",
            "469/469 - 2s - loss: 0.3927 - auc: 0.7049 - accuracy: 0.8473\n",
            "Epoch 30/75\n",
            "469/469 - 2s - loss: 0.3927 - auc: 0.7049 - accuracy: 0.8473\n",
            "Epoch 31/75\n",
            "469/469 - 2s - loss: 0.3926 - auc: 0.7051 - accuracy: 0.8472\n",
            "Epoch 32/75\n",
            "469/469 - 2s - loss: 0.3925 - auc: 0.7053 - accuracy: 0.8474\n",
            "Epoch 33/75\n",
            "469/469 - 2s - loss: 0.3925 - auc: 0.7054 - accuracy: 0.8472\n",
            "Epoch 34/75\n",
            "469/469 - 2s - loss: 0.3924 - auc: 0.7056 - accuracy: 0.8473\n",
            "Epoch 35/75\n",
            "469/469 - 2s - loss: 0.3924 - auc: 0.7057 - accuracy: 0.8473\n",
            "Epoch 36/75\n",
            "469/469 - 2s - loss: 0.3923 - auc: 0.7058 - accuracy: 0.8473\n",
            "Epoch 37/75\n",
            "469/469 - 2s - loss: 0.3923 - auc: 0.7059 - accuracy: 0.8474\n",
            "Epoch 38/75\n",
            "469/469 - 2s - loss: 0.3922 - auc: 0.7061 - accuracy: 0.8473\n",
            "Epoch 39/75\n",
            "469/469 - 2s - loss: 0.3922 - auc: 0.7063 - accuracy: 0.8473\n",
            "Epoch 40/75\n",
            "469/469 - 2s - loss: 0.3922 - auc: 0.7063 - accuracy: 0.8473\n",
            "Epoch 41/75\n",
            "469/469 - 2s - loss: 0.3921 - auc: 0.7064 - accuracy: 0.8473\n",
            "Epoch 42/75\n",
            "469/469 - 2s - loss: 0.3920 - auc: 0.7065 - accuracy: 0.8473\n",
            "Epoch 43/75\n",
            "469/469 - 2s - loss: 0.3920 - auc: 0.7067 - accuracy: 0.8474\n",
            "Epoch 44/75\n",
            "469/469 - 2s - loss: 0.3920 - auc: 0.7066 - accuracy: 0.8474\n",
            "Epoch 45/75\n",
            "469/469 - 2s - loss: 0.3920 - auc: 0.7067 - accuracy: 0.8473\n",
            "Epoch 46/75\n",
            "469/469 - 2s - loss: 0.3919 - auc: 0.7069 - accuracy: 0.8473\n",
            "Epoch 47/75\n",
            "469/469 - 2s - loss: 0.3918 - auc: 0.7071 - accuracy: 0.8474\n",
            "Epoch 48/75\n",
            "469/469 - 2s - loss: 0.3919 - auc: 0.7071 - accuracy: 0.8473\n",
            "Epoch 49/75\n",
            "469/469 - 2s - loss: 0.3918 - auc: 0.7072 - accuracy: 0.8474\n",
            "Epoch 50/75\n",
            "469/469 - 2s - loss: 0.3917 - auc: 0.7073 - accuracy: 0.8474\n",
            "Epoch 51/75\n",
            "469/469 - 2s - loss: 0.3917 - auc: 0.7075 - accuracy: 0.8474\n",
            "Epoch 52/75\n",
            "469/469 - 2s - loss: 0.3916 - auc: 0.7076 - accuracy: 0.8475\n",
            "Epoch 53/75\n",
            "469/469 - 2s - loss: 0.3916 - auc: 0.7076 - accuracy: 0.8474\n",
            "Epoch 54/75\n",
            "469/469 - 2s - loss: 0.3916 - auc: 0.7076 - accuracy: 0.8473\n",
            "Epoch 55/75\n",
            "469/469 - 2s - loss: 0.3915 - auc: 0.7078 - accuracy: 0.8474\n",
            "Epoch 56/75\n",
            "469/469 - 2s - loss: 0.3916 - auc: 0.7077 - accuracy: 0.8474\n",
            "Epoch 57/75\n",
            "469/469 - 2s - loss: 0.3915 - auc: 0.7079 - accuracy: 0.8473\n",
            "Epoch 58/75\n",
            "469/469 - 2s - loss: 0.3915 - auc: 0.7080 - accuracy: 0.8474\n",
            "Epoch 59/75\n",
            "469/469 - 2s - loss: 0.3914 - auc: 0.7080 - accuracy: 0.8474\n",
            "Epoch 60/75\n",
            "469/469 - 2s - loss: 0.3914 - auc: 0.7082 - accuracy: 0.8473\n",
            "Epoch 61/75\n",
            "469/469 - 2s - loss: 0.3914 - auc: 0.7083 - accuracy: 0.8474\n",
            "Epoch 62/75\n",
            "469/469 - 2s - loss: 0.3914 - auc: 0.7082 - accuracy: 0.8474\n",
            "Epoch 63/75\n",
            "469/469 - 2s - loss: 0.3913 - auc: 0.7083 - accuracy: 0.8474\n",
            "Epoch 64/75\n",
            "469/469 - 2s - loss: 0.3913 - auc: 0.7085 - accuracy: 0.8473\n",
            "Epoch 65/75\n",
            "469/469 - 2s - loss: 0.3913 - auc: 0.7085 - accuracy: 0.8473\n",
            "Epoch 66/75\n",
            "469/469 - 2s - loss: 0.3912 - auc: 0.7086 - accuracy: 0.8475\n",
            "Epoch 67/75\n",
            "469/469 - 2s - loss: 0.3912 - auc: 0.7085 - accuracy: 0.8474\n",
            "Epoch 68/75\n",
            "469/469 - 2s - loss: 0.3912 - auc: 0.7087 - accuracy: 0.8474\n",
            "Epoch 69/75\n",
            "469/469 - 2s - loss: 0.3911 - auc: 0.7088 - accuracy: 0.8473\n",
            "Epoch 70/75\n",
            "469/469 - 2s - loss: 0.3911 - auc: 0.7090 - accuracy: 0.8473\n",
            "Epoch 71/75\n",
            "469/469 - 2s - loss: 0.3911 - auc: 0.7089 - accuracy: 0.8473\n",
            "Epoch 72/75\n",
            "469/469 - 2s - loss: 0.3911 - auc: 0.7089 - accuracy: 0.8474\n",
            "Epoch 73/75\n",
            "469/469 - 2s - loss: 0.3910 - auc: 0.7091 - accuracy: 0.8474\n",
            "Epoch 74/75\n",
            "469/469 - 2s - loss: 0.3910 - auc: 0.7091 - accuracy: 0.8474\n",
            "Epoch 75/75\n",
            "469/469 - 2s - loss: 0.3910 - auc: 0.7092 - accuracy: 0.8474\n",
            "7319/7319 - 6s\n",
            "7319/7319 - 6s\n",
            "Epoch 1/75\n",
            "469/469 - 2s - loss: 0.4034 - auc: 0.6939 - accuracy: 0.8452\n",
            "Epoch 2/75\n",
            "469/469 - 2s - loss: 0.3974 - auc: 0.6926 - accuracy: 0.8467\n",
            "Epoch 3/75\n",
            "469/469 - 2s - loss: 0.3966 - auc: 0.6946 - accuracy: 0.8468\n",
            "Epoch 4/75\n",
            "469/469 - 2s - loss: 0.3961 - auc: 0.6960 - accuracy: 0.8469\n",
            "Epoch 5/75\n",
            "469/469 - 2s - loss: 0.3957 - auc: 0.6971 - accuracy: 0.8469\n",
            "Epoch 6/75\n",
            "469/469 - 2s - loss: 0.3953 - auc: 0.6980 - accuracy: 0.8470\n",
            "Epoch 7/75\n",
            "469/469 - 2s - loss: 0.3950 - auc: 0.6987 - accuracy: 0.8469\n",
            "Epoch 8/75\n",
            "469/469 - 2s - loss: 0.3948 - auc: 0.6993 - accuracy: 0.8469\n",
            "Epoch 9/75\n",
            "469/469 - 2s - loss: 0.3946 - auc: 0.6998 - accuracy: 0.8469\n",
            "Epoch 10/75\n",
            "469/469 - 2s - loss: 0.3944 - auc: 0.7003 - accuracy: 0.8469\n",
            "Epoch 11/75\n",
            "469/469 - 2s - loss: 0.3943 - auc: 0.7008 - accuracy: 0.8470\n",
            "Epoch 12/75\n",
            "469/469 - 2s - loss: 0.3941 - auc: 0.7011 - accuracy: 0.8470\n",
            "Epoch 13/75\n",
            "469/469 - 2s - loss: 0.3940 - auc: 0.7016 - accuracy: 0.8469\n",
            "Epoch 14/75\n",
            "469/469 - 2s - loss: 0.3939 - auc: 0.7018 - accuracy: 0.8469\n",
            "Epoch 15/75\n",
            "469/469 - 2s - loss: 0.3938 - auc: 0.7021 - accuracy: 0.8469\n",
            "Epoch 16/75\n",
            "469/469 - 2s - loss: 0.3937 - auc: 0.7024 - accuracy: 0.8469\n",
            "Epoch 17/75\n",
            "469/469 - 2s - loss: 0.3936 - auc: 0.7025 - accuracy: 0.8469\n",
            "Epoch 18/75\n",
            "469/469 - 2s - loss: 0.3935 - auc: 0.7029 - accuracy: 0.8471\n",
            "Epoch 19/75\n",
            "469/469 - 2s - loss: 0.3934 - auc: 0.7030 - accuracy: 0.8470\n",
            "Epoch 20/75\n",
            "469/469 - 2s - loss: 0.3933 - auc: 0.7032 - accuracy: 0.8471\n",
            "Epoch 21/75\n",
            "469/469 - 2s - loss: 0.3933 - auc: 0.7034 - accuracy: 0.8471\n",
            "Epoch 22/75\n",
            "469/469 - 2s - loss: 0.3932 - auc: 0.7036 - accuracy: 0.8471\n",
            "Epoch 23/75\n",
            "469/469 - 2s - loss: 0.3931 - auc: 0.7037 - accuracy: 0.8469\n",
            "Epoch 24/75\n",
            "469/469 - 2s - loss: 0.3931 - auc: 0.7039 - accuracy: 0.8471\n",
            "Epoch 25/75\n",
            "469/469 - 2s - loss: 0.3930 - auc: 0.7041 - accuracy: 0.8470\n",
            "Epoch 26/75\n",
            "469/469 - 2s - loss: 0.3929 - auc: 0.7042 - accuracy: 0.8470\n",
            "Epoch 27/75\n",
            "469/469 - 2s - loss: 0.3928 - auc: 0.7045 - accuracy: 0.8471\n",
            "Epoch 28/75\n",
            "469/469 - 2s - loss: 0.3928 - auc: 0.7047 - accuracy: 0.8471\n",
            "Epoch 29/75\n",
            "469/469 - 2s - loss: 0.3927 - auc: 0.7048 - accuracy: 0.8471\n",
            "Epoch 30/75\n",
            "469/469 - 2s - loss: 0.3927 - auc: 0.7049 - accuracy: 0.8471\n",
            "Epoch 31/75\n",
            "469/469 - 2s - loss: 0.3926 - auc: 0.7051 - accuracy: 0.8471\n",
            "Epoch 32/75\n",
            "469/469 - 2s - loss: 0.3926 - auc: 0.7053 - accuracy: 0.8471\n",
            "Epoch 33/75\n",
            "469/469 - 2s - loss: 0.3925 - auc: 0.7053 - accuracy: 0.8471\n",
            "Epoch 34/75\n",
            "469/469 - 2s - loss: 0.3925 - auc: 0.7054 - accuracy: 0.8470\n",
            "Epoch 35/75\n",
            "469/469 - 2s - loss: 0.3924 - auc: 0.7057 - accuracy: 0.8471\n",
            "Epoch 36/75\n",
            "469/469 - 2s - loss: 0.3924 - auc: 0.7058 - accuracy: 0.8471\n",
            "Epoch 37/75\n",
            "469/469 - 2s - loss: 0.3923 - auc: 0.7059 - accuracy: 0.8471\n",
            "Epoch 38/75\n",
            "469/469 - 2s - loss: 0.3922 - auc: 0.7061 - accuracy: 0.8471\n",
            "Epoch 39/75\n",
            "469/469 - 2s - loss: 0.3922 - auc: 0.7060 - accuracy: 0.8471\n",
            "Epoch 40/75\n",
            "469/469 - 2s - loss: 0.3922 - auc: 0.7062 - accuracy: 0.8471\n",
            "Epoch 41/75\n",
            "469/469 - 2s - loss: 0.3921 - auc: 0.7063 - accuracy: 0.8472\n",
            "Epoch 42/75\n",
            "469/469 - 2s - loss: 0.3921 - auc: 0.7064 - accuracy: 0.8471\n",
            "Epoch 43/75\n",
            "469/469 - 2s - loss: 0.3920 - auc: 0.7067 - accuracy: 0.8471\n",
            "Epoch 44/75\n",
            "469/469 - 2s - loss: 0.3920 - auc: 0.7068 - accuracy: 0.8472\n",
            "Epoch 45/75\n",
            "469/469 - 2s - loss: 0.3920 - auc: 0.7068 - accuracy: 0.8471\n",
            "Epoch 46/75\n",
            "469/469 - 2s - loss: 0.3919 - auc: 0.7070 - accuracy: 0.8472\n",
            "Epoch 47/75\n",
            "469/469 - 2s - loss: 0.3918 - auc: 0.7071 - accuracy: 0.8473\n",
            "Epoch 48/75\n",
            "469/469 - 2s - loss: 0.3918 - auc: 0.7072 - accuracy: 0.8471\n",
            "Epoch 49/75\n",
            "469/469 - 2s - loss: 0.3918 - auc: 0.7073 - accuracy: 0.8471\n",
            "Epoch 50/75\n",
            "469/469 - 2s - loss: 0.3917 - auc: 0.7073 - accuracy: 0.8472\n",
            "Epoch 51/75\n",
            "469/469 - 2s - loss: 0.3917 - auc: 0.7075 - accuracy: 0.8472\n",
            "Epoch 52/75\n",
            "469/469 - 2s - loss: 0.3916 - auc: 0.7076 - accuracy: 0.8472\n",
            "Epoch 53/75\n",
            "469/469 - 2s - loss: 0.3916 - auc: 0.7076 - accuracy: 0.8471\n",
            "Epoch 54/75\n",
            "469/469 - 2s - loss: 0.3916 - auc: 0.7078 - accuracy: 0.8472\n",
            "Epoch 55/75\n",
            "469/469 - 2s - loss: 0.3916 - auc: 0.7079 - accuracy: 0.8472\n",
            "Epoch 56/75\n",
            "469/469 - 2s - loss: 0.3915 - auc: 0.7079 - accuracy: 0.8472\n",
            "Epoch 57/75\n",
            "469/469 - 2s - loss: 0.3914 - auc: 0.7082 - accuracy: 0.8471\n",
            "Epoch 58/75\n",
            "469/469 - 2s - loss: 0.3915 - auc: 0.7081 - accuracy: 0.8473\n",
            "Epoch 59/75\n",
            "469/469 - 2s - loss: 0.3914 - auc: 0.7082 - accuracy: 0.8472\n",
            "Epoch 60/75\n",
            "469/469 - 2s - loss: 0.3914 - auc: 0.7083 - accuracy: 0.8472\n",
            "Epoch 61/75\n",
            "469/469 - 2s - loss: 0.3913 - auc: 0.7084 - accuracy: 0.8473\n",
            "Epoch 62/75\n",
            "469/469 - 2s - loss: 0.3913 - auc: 0.7086 - accuracy: 0.8472\n",
            "Epoch 63/75\n",
            "469/469 - 2s - loss: 0.3913 - auc: 0.7086 - accuracy: 0.8473\n",
            "Epoch 64/75\n",
            "469/469 - 2s - loss: 0.3913 - auc: 0.7086 - accuracy: 0.8472\n",
            "Epoch 65/75\n",
            "469/469 - 2s - loss: 0.3912 - auc: 0.7087 - accuracy: 0.8472\n",
            "Epoch 66/75\n",
            "469/469 - 2s - loss: 0.3912 - auc: 0.7088 - accuracy: 0.8472\n",
            "Epoch 67/75\n",
            "469/469 - 2s - loss: 0.3911 - auc: 0.7089 - accuracy: 0.8472\n",
            "Epoch 68/75\n",
            "469/469 - 2s - loss: 0.3911 - auc: 0.7089 - accuracy: 0.8472\n",
            "Epoch 69/75\n",
            "469/469 - 2s - loss: 0.3911 - auc: 0.7090 - accuracy: 0.8472\n",
            "Epoch 70/75\n",
            "469/469 - 2s - loss: 0.3910 - auc: 0.7093 - accuracy: 0.8473\n",
            "Epoch 71/75\n",
            "469/469 - 2s - loss: 0.3911 - auc: 0.7092 - accuracy: 0.8473\n",
            "Epoch 72/75\n",
            "469/469 - 2s - loss: 0.3910 - auc: 0.7093 - accuracy: 0.8473\n",
            "Epoch 73/75\n",
            "469/469 - 2s - loss: 0.3910 - auc: 0.7094 - accuracy: 0.8472\n",
            "Epoch 74/75\n",
            "469/469 - 2s - loss: 0.3909 - auc: 0.7094 - accuracy: 0.8473\n",
            "Epoch 75/75\n",
            "469/469 - 2s - loss: 0.3909 - auc: 0.7096 - accuracy: 0.8473\n",
            "7319/7319 - 6s\n",
            "7319/7319 - 6s\n",
            "Epoch 1/75\n",
            "469/469 - 2s - loss: 0.4068 - auc: 0.6921 - accuracy: 0.8421\n",
            "Epoch 2/75\n",
            "469/469 - 2s - loss: 0.3968 - auc: 0.6942 - accuracy: 0.8468\n",
            "Epoch 3/75\n",
            "469/469 - 2s - loss: 0.3960 - auc: 0.6963 - accuracy: 0.8468\n",
            "Epoch 4/75\n",
            "469/469 - 2s - loss: 0.3955 - auc: 0.6977 - accuracy: 0.8468\n",
            "Epoch 5/75\n",
            "469/469 - 2s - loss: 0.3951 - auc: 0.6987 - accuracy: 0.8469\n",
            "Epoch 6/75\n",
            "469/469 - 2s - loss: 0.3948 - auc: 0.6995 - accuracy: 0.8468\n",
            "Epoch 7/75\n",
            "469/469 - 2s - loss: 0.3945 - auc: 0.7004 - accuracy: 0.8469\n",
            "Epoch 8/75\n",
            "469/469 - 2s - loss: 0.3942 - auc: 0.7011 - accuracy: 0.8469\n",
            "Epoch 9/75\n",
            "469/469 - 2s - loss: 0.3941 - auc: 0.7015 - accuracy: 0.8469\n",
            "Epoch 10/75\n",
            "469/469 - 2s - loss: 0.3939 - auc: 0.7019 - accuracy: 0.8469\n",
            "Epoch 11/75\n",
            "469/469 - 2s - loss: 0.3937 - auc: 0.7025 - accuracy: 0.8470\n",
            "Epoch 12/75\n",
            "469/469 - 2s - loss: 0.3936 - auc: 0.7028 - accuracy: 0.8469\n",
            "Epoch 13/75\n",
            "469/469 - 2s - loss: 0.3934 - auc: 0.7033 - accuracy: 0.8469\n",
            "Epoch 14/75\n",
            "469/469 - 2s - loss: 0.3933 - auc: 0.7035 - accuracy: 0.8470\n",
            "Epoch 15/75\n",
            "469/469 - 2s - loss: 0.3932 - auc: 0.7039 - accuracy: 0.8469\n",
            "Epoch 16/75\n",
            "469/469 - 2s - loss: 0.3931 - auc: 0.7041 - accuracy: 0.8470\n",
            "Epoch 17/75\n",
            "469/469 - 2s - loss: 0.3930 - auc: 0.7044 - accuracy: 0.8470\n",
            "Epoch 18/75\n",
            "469/469 - 2s - loss: 0.3929 - auc: 0.7046 - accuracy: 0.8470\n",
            "Epoch 19/75\n",
            "469/469 - 2s - loss: 0.3928 - auc: 0.7049 - accuracy: 0.8470\n",
            "Epoch 20/75\n",
            "469/469 - 2s - loss: 0.3928 - auc: 0.7050 - accuracy: 0.8471\n",
            "Epoch 21/75\n",
            "469/469 - 2s - loss: 0.3927 - auc: 0.7053 - accuracy: 0.8470\n",
            "Epoch 22/75\n",
            "469/469 - 2s - loss: 0.3926 - auc: 0.7054 - accuracy: 0.8470\n",
            "Epoch 23/75\n",
            "469/469 - 2s - loss: 0.3925 - auc: 0.7057 - accuracy: 0.8470\n",
            "Epoch 24/75\n",
            "469/469 - 2s - loss: 0.3925 - auc: 0.7057 - accuracy: 0.8471\n",
            "Epoch 25/75\n",
            "469/469 - 2s - loss: 0.3924 - auc: 0.7060 - accuracy: 0.8470\n",
            "Epoch 26/75\n",
            "469/469 - 2s - loss: 0.3923 - auc: 0.7060 - accuracy: 0.8472\n",
            "Epoch 27/75\n",
            "469/469 - 2s - loss: 0.3923 - auc: 0.7062 - accuracy: 0.8470\n",
            "Epoch 28/75\n",
            "469/469 - 2s - loss: 0.3922 - auc: 0.7064 - accuracy: 0.8471\n",
            "Epoch 29/75\n",
            "469/469 - 2s - loss: 0.3921 - auc: 0.7066 - accuracy: 0.8471\n",
            "Epoch 30/75\n",
            "469/469 - 2s - loss: 0.3921 - auc: 0.7067 - accuracy: 0.8471\n",
            "Epoch 31/75\n",
            "469/469 - 2s - loss: 0.3921 - auc: 0.7068 - accuracy: 0.8471\n",
            "Epoch 32/75\n",
            "469/469 - 2s - loss: 0.3919 - auc: 0.7071 - accuracy: 0.8471\n",
            "Epoch 33/75\n",
            "469/469 - 2s - loss: 0.3919 - auc: 0.7071 - accuracy: 0.8471\n",
            "Epoch 34/75\n",
            "469/469 - 2s - loss: 0.3918 - auc: 0.7073 - accuracy: 0.8471\n",
            "Epoch 35/75\n",
            "469/469 - 2s - loss: 0.3918 - auc: 0.7074 - accuracy: 0.8471\n",
            "Epoch 36/75\n",
            "469/469 - 2s - loss: 0.3918 - auc: 0.7074 - accuracy: 0.8471\n",
            "Epoch 37/75\n",
            "469/469 - 2s - loss: 0.3917 - auc: 0.7077 - accuracy: 0.8472\n",
            "Epoch 38/75\n",
            "469/469 - 2s - loss: 0.3917 - auc: 0.7078 - accuracy: 0.8471\n",
            "Epoch 39/75\n",
            "469/469 - 2s - loss: 0.3917 - auc: 0.7078 - accuracy: 0.8472\n",
            "Epoch 40/75\n",
            "469/469 - 2s - loss: 0.3916 - auc: 0.7080 - accuracy: 0.8471\n",
            "Epoch 41/75\n",
            "469/469 - 2s - loss: 0.3915 - auc: 0.7080 - accuracy: 0.8471\n",
            "Epoch 42/75\n",
            "469/469 - 2s - loss: 0.3915 - auc: 0.7082 - accuracy: 0.8472\n",
            "Epoch 43/75\n",
            "469/469 - 2s - loss: 0.3914 - auc: 0.7084 - accuracy: 0.8471\n",
            "Epoch 44/75\n",
            "469/469 - 2s - loss: 0.3914 - auc: 0.7085 - accuracy: 0.8472\n",
            "Epoch 45/75\n",
            "469/469 - 2s - loss: 0.3914 - auc: 0.7085 - accuracy: 0.8472\n",
            "Epoch 46/75\n",
            "469/469 - 2s - loss: 0.3913 - auc: 0.7087 - accuracy: 0.8472\n",
            "Epoch 47/75\n",
            "469/469 - 2s - loss: 0.3913 - auc: 0.7088 - accuracy: 0.8472\n",
            "Epoch 48/75\n",
            "469/469 - 2s - loss: 0.3913 - auc: 0.7087 - accuracy: 0.8472\n",
            "Epoch 49/75\n",
            "469/469 - 2s - loss: 0.3912 - auc: 0.7089 - accuracy: 0.8471\n",
            "Epoch 50/75\n",
            "469/469 - 2s - loss: 0.3912 - auc: 0.7089 - accuracy: 0.8473\n",
            "Epoch 51/75\n",
            "469/469 - 2s - loss: 0.3911 - auc: 0.7092 - accuracy: 0.8473\n",
            "Epoch 52/75\n",
            "469/469 - 2s - loss: 0.3911 - auc: 0.7092 - accuracy: 0.8473\n",
            "Epoch 53/75\n",
            "469/469 - 2s - loss: 0.3911 - auc: 0.7093 - accuracy: 0.8473\n",
            "Epoch 54/75\n",
            "469/469 - 2s - loss: 0.3910 - auc: 0.7094 - accuracy: 0.8473\n",
            "Epoch 55/75\n",
            "469/469 - 2s - loss: 0.3910 - auc: 0.7094 - accuracy: 0.8472\n",
            "Epoch 56/75\n",
            "469/469 - 2s - loss: 0.3909 - auc: 0.7096 - accuracy: 0.8472\n",
            "Epoch 57/75\n",
            "469/469 - 2s - loss: 0.3909 - auc: 0.7096 - accuracy: 0.8472\n",
            "Epoch 58/75\n",
            "469/469 - 2s - loss: 0.3908 - auc: 0.7099 - accuracy: 0.8472\n",
            "Epoch 59/75\n",
            "469/469 - 2s - loss: 0.3908 - auc: 0.7099 - accuracy: 0.8473\n",
            "Epoch 60/75\n",
            "469/469 - 2s - loss: 0.3908 - auc: 0.7099 - accuracy: 0.8472\n",
            "Epoch 61/75\n",
            "469/469 - 2s - loss: 0.3908 - auc: 0.7100 - accuracy: 0.8472\n",
            "Epoch 62/75\n",
            "469/469 - 2s - loss: 0.3908 - auc: 0.7100 - accuracy: 0.8472\n",
            "Epoch 63/75\n",
            "469/469 - 2s - loss: 0.3908 - auc: 0.7101 - accuracy: 0.8472\n",
            "Epoch 64/75\n",
            "469/469 - 2s - loss: 0.3907 - auc: 0.7103 - accuracy: 0.8472\n",
            "Epoch 65/75\n",
            "469/469 - 2s - loss: 0.3906 - auc: 0.7104 - accuracy: 0.8473\n",
            "Epoch 66/75\n",
            "469/469 - 2s - loss: 0.3906 - auc: 0.7104 - accuracy: 0.8473\n",
            "Epoch 67/75\n",
            "469/469 - 2s - loss: 0.3906 - auc: 0.7105 - accuracy: 0.8473\n",
            "Epoch 68/75\n",
            "469/469 - 2s - loss: 0.3905 - auc: 0.7106 - accuracy: 0.8473\n",
            "Epoch 69/75\n",
            "469/469 - 2s - loss: 0.3906 - auc: 0.7105 - accuracy: 0.8473\n",
            "Epoch 70/75\n",
            "469/469 - 2s - loss: 0.3906 - auc: 0.7105 - accuracy: 0.8473\n",
            "Epoch 71/75\n",
            "469/469 - 2s - loss: 0.3905 - auc: 0.7107 - accuracy: 0.8473\n",
            "Epoch 72/75\n",
            "469/469 - 2s - loss: 0.3905 - auc: 0.7108 - accuracy: 0.8473\n",
            "Epoch 73/75\n",
            "469/469 - 2s - loss: 0.3904 - auc: 0.7109 - accuracy: 0.8472\n",
            "Epoch 74/75\n",
            "469/469 - 2s - loss: 0.3904 - auc: 0.7108 - accuracy: 0.8474\n",
            "Epoch 75/75\n",
            "469/469 - 2s - loss: 0.3904 - auc: 0.7111 - accuracy: 0.8473\n",
            "7319/7319 - 6s\n",
            "7319/7319 - 6s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LhpVz9vpDp0l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a1582217-4867-4495-8c5f-25df301470df"
      },
      "source": [
        "#Third architecture\n",
        "cvModel3 = cross_validate(estimator=KerasClassifier(build_fn=create_model3, verbose=2, optim = 'rmsprop'), X=dfPostImpute[trainAll], y=trainLabels, scoring=scoringDict2, cv = kFold,\n",
        "                fit_params = dict(batch_size=1000,\n",
        "                                  epochs=75))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "469/469 - 2s - loss: 0.4078 - auc: 0.6925 - accuracy: 0.8425\n",
            "Epoch 2/75\n",
            "469/469 - 2s - loss: 0.3978 - auc: 0.6911 - accuracy: 0.8467\n",
            "Epoch 3/75\n",
            "469/469 - 2s - loss: 0.3974 - auc: 0.6924 - accuracy: 0.8468\n",
            "Epoch 4/75\n",
            "469/469 - 2s - loss: 0.3969 - auc: 0.6936 - accuracy: 0.8468\n",
            "Epoch 5/75\n",
            "469/469 - 2s - loss: 0.3966 - auc: 0.6945 - accuracy: 0.8469\n",
            "Epoch 6/75\n",
            "469/469 - 2s - loss: 0.3963 - auc: 0.6954 - accuracy: 0.8468\n",
            "Epoch 7/75\n",
            "469/469 - 2s - loss: 0.3961 - auc: 0.6959 - accuracy: 0.8468\n",
            "Epoch 8/75\n",
            "469/469 - 2s - loss: 0.3959 - auc: 0.6965 - accuracy: 0.8469\n",
            "Epoch 9/75\n",
            "469/469 - 2s - loss: 0.3956 - auc: 0.6971 - accuracy: 0.8469\n",
            "Epoch 10/75\n",
            "469/469 - 2s - loss: 0.3954 - auc: 0.6977 - accuracy: 0.8469\n",
            "Epoch 11/75\n",
            "469/469 - 2s - loss: 0.3953 - auc: 0.6980 - accuracy: 0.8470\n",
            "Epoch 12/75\n",
            "469/469 - 2s - loss: 0.3951 - auc: 0.6985 - accuracy: 0.8469\n",
            "Epoch 13/75\n",
            "469/469 - 2s - loss: 0.3949 - auc: 0.6989 - accuracy: 0.8470\n",
            "Epoch 14/75\n",
            "469/469 - 2s - loss: 0.3948 - auc: 0.6995 - accuracy: 0.8470\n",
            "Epoch 15/75\n",
            "469/469 - 2s - loss: 0.3946 - auc: 0.6998 - accuracy: 0.8470\n",
            "Epoch 16/75\n",
            "469/469 - 2s - loss: 0.3945 - auc: 0.7000 - accuracy: 0.8470\n",
            "Epoch 17/75\n",
            "469/469 - 2s - loss: 0.3944 - auc: 0.7003 - accuracy: 0.8471\n",
            "Epoch 18/75\n",
            "469/469 - 2s - loss: 0.3943 - auc: 0.7007 - accuracy: 0.8470\n",
            "Epoch 19/75\n",
            "469/469 - 2s - loss: 0.3942 - auc: 0.7009 - accuracy: 0.8471\n",
            "Epoch 20/75\n",
            "469/469 - 2s - loss: 0.3941 - auc: 0.7011 - accuracy: 0.8471\n",
            "Epoch 21/75\n",
            "469/469 - 2s - loss: 0.3940 - auc: 0.7014 - accuracy: 0.8470\n",
            "Epoch 22/75\n",
            "469/469 - 2s - loss: 0.3939 - auc: 0.7016 - accuracy: 0.8470\n",
            "Epoch 23/75\n",
            "469/469 - 2s - loss: 0.3939 - auc: 0.7017 - accuracy: 0.8471\n",
            "Epoch 24/75\n",
            "469/469 - 2s - loss: 0.3938 - auc: 0.7020 - accuracy: 0.8470\n",
            "Epoch 25/75\n",
            "469/469 - 2s - loss: 0.3937 - auc: 0.7023 - accuracy: 0.8471\n",
            "Epoch 26/75\n",
            "469/469 - 2s - loss: 0.3936 - auc: 0.7024 - accuracy: 0.8471\n",
            "Epoch 27/75\n",
            "469/469 - 2s - loss: 0.3935 - auc: 0.7026 - accuracy: 0.8471\n",
            "Epoch 28/75\n",
            "469/469 - 2s - loss: 0.3935 - auc: 0.7027 - accuracy: 0.8471\n",
            "Epoch 29/75\n",
            "469/469 - 2s - loss: 0.3935 - auc: 0.7029 - accuracy: 0.8472\n",
            "Epoch 30/75\n",
            "469/469 - 2s - loss: 0.3934 - auc: 0.7031 - accuracy: 0.8471\n",
            "Epoch 31/75\n",
            "469/469 - 2s - loss: 0.3933 - auc: 0.7032 - accuracy: 0.8472\n",
            "Epoch 32/75\n",
            "469/469 - 2s - loss: 0.3933 - auc: 0.7034 - accuracy: 0.8471\n",
            "Epoch 33/75\n",
            "469/469 - 2s - loss: 0.3932 - auc: 0.7035 - accuracy: 0.8471\n",
            "Epoch 34/75\n",
            "469/469 - 2s - loss: 0.3932 - auc: 0.7036 - accuracy: 0.8471\n",
            "Epoch 35/75\n",
            "469/469 - 2s - loss: 0.3931 - auc: 0.7039 - accuracy: 0.8471\n",
            "Epoch 36/75\n",
            "469/469 - 2s - loss: 0.3931 - auc: 0.7037 - accuracy: 0.8471\n",
            "Epoch 37/75\n",
            "469/469 - 2s - loss: 0.3930 - auc: 0.7039 - accuracy: 0.8471\n",
            "Epoch 38/75\n",
            "469/469 - 2s - loss: 0.3930 - auc: 0.7041 - accuracy: 0.8471\n",
            "Epoch 39/75\n",
            "469/469 - 2s - loss: 0.3930 - auc: 0.7041 - accuracy: 0.8471\n",
            "Epoch 40/75\n",
            "469/469 - 2s - loss: 0.3929 - auc: 0.7043 - accuracy: 0.8472\n",
            "Epoch 41/75\n",
            "469/469 - 2s - loss: 0.3929 - auc: 0.7044 - accuracy: 0.8471\n",
            "Epoch 42/75\n",
            "469/469 - 2s - loss: 0.3928 - auc: 0.7046 - accuracy: 0.8471\n",
            "Epoch 43/75\n",
            "469/469 - 2s - loss: 0.3928 - auc: 0.7046 - accuracy: 0.8471\n",
            "Epoch 44/75\n",
            "469/469 - 2s - loss: 0.3928 - auc: 0.7046 - accuracy: 0.8472\n",
            "Epoch 45/75\n",
            "469/469 - 2s - loss: 0.3927 - auc: 0.7049 - accuracy: 0.8471\n",
            "Epoch 46/75\n",
            "469/469 - 2s - loss: 0.3927 - auc: 0.7049 - accuracy: 0.8472\n",
            "Epoch 47/75\n",
            "469/469 - 2s - loss: 0.3926 - auc: 0.7050 - accuracy: 0.8471\n",
            "Epoch 48/75\n",
            "469/469 - 2s - loss: 0.3926 - auc: 0.7050 - accuracy: 0.8471\n",
            "Epoch 49/75\n",
            "469/469 - 2s - loss: 0.3926 - auc: 0.7050 - accuracy: 0.8472\n",
            "Epoch 50/75\n",
            "469/469 - 2s - loss: 0.3925 - auc: 0.7053 - accuracy: 0.8472\n",
            "Epoch 51/75\n",
            "469/469 - 2s - loss: 0.3925 - auc: 0.7053 - accuracy: 0.8471\n",
            "Epoch 52/75\n",
            "469/469 - 2s - loss: 0.3925 - auc: 0.7053 - accuracy: 0.8472\n",
            "Epoch 53/75\n",
            "469/469 - 2s - loss: 0.3925 - auc: 0.7054 - accuracy: 0.8472\n",
            "Epoch 54/75\n",
            "469/469 - 2s - loss: 0.3925 - auc: 0.7054 - accuracy: 0.8471\n",
            "Epoch 55/75\n",
            "469/469 - 2s - loss: 0.3925 - auc: 0.7054 - accuracy: 0.8472\n",
            "Epoch 56/75\n",
            "469/469 - 2s - loss: 0.3924 - auc: 0.7056 - accuracy: 0.8473\n",
            "Epoch 57/75\n",
            "469/469 - 2s - loss: 0.3924 - auc: 0.7057 - accuracy: 0.8472\n",
            "Epoch 58/75\n",
            "469/469 - 2s - loss: 0.3924 - auc: 0.7057 - accuracy: 0.8473\n",
            "Epoch 59/75\n",
            "469/469 - 2s - loss: 0.3923 - auc: 0.7059 - accuracy: 0.8472\n",
            "Epoch 60/75\n",
            "469/469 - 2s - loss: 0.3923 - auc: 0.7058 - accuracy: 0.8472\n",
            "Epoch 61/75\n",
            "469/469 - 2s - loss: 0.3923 - auc: 0.7059 - accuracy: 0.8472\n",
            "Epoch 62/75\n",
            "469/469 - 2s - loss: 0.3922 - auc: 0.7061 - accuracy: 0.8472\n",
            "Epoch 63/75\n",
            "469/469 - 2s - loss: 0.3922 - auc: 0.7060 - accuracy: 0.8472\n",
            "Epoch 64/75\n",
            "469/469 - 2s - loss: 0.3922 - auc: 0.7061 - accuracy: 0.8472\n",
            "Epoch 65/75\n",
            "469/469 - 2s - loss: 0.3922 - auc: 0.7061 - accuracy: 0.8471\n",
            "Epoch 66/75\n",
            "469/469 - 2s - loss: 0.3922 - auc: 0.7061 - accuracy: 0.8472\n",
            "Epoch 67/75\n",
            "469/469 - 2s - loss: 0.3921 - auc: 0.7063 - accuracy: 0.8472\n",
            "Epoch 68/75\n",
            "469/469 - 2s - loss: 0.3921 - auc: 0.7063 - accuracy: 0.8472\n",
            "Epoch 69/75\n",
            "469/469 - 2s - loss: 0.3921 - auc: 0.7064 - accuracy: 0.8472\n",
            "Epoch 70/75\n",
            "469/469 - 2s - loss: 0.3921 - auc: 0.7062 - accuracy: 0.8472\n",
            "Epoch 71/75\n",
            "469/469 - 2s - loss: 0.3921 - auc: 0.7063 - accuracy: 0.8472\n",
            "Epoch 72/75\n",
            "469/469 - 2s - loss: 0.3920 - auc: 0.7064 - accuracy: 0.8472\n",
            "Epoch 73/75\n",
            "469/469 - 2s - loss: 0.3920 - auc: 0.7065 - accuracy: 0.8472\n",
            "Epoch 74/75\n",
            "469/469 - 2s - loss: 0.3920 - auc: 0.7066 - accuracy: 0.8473\n",
            "Epoch 75/75\n",
            "469/469 - 2s - loss: 0.3920 - auc: 0.7066 - accuracy: 0.8472\n",
            "7319/7319 - 6s\n",
            "7319/7319 - 6s\n",
            "Epoch 1/75\n",
            "469/469 - 2s - loss: 0.4114 - auc: 0.6867 - accuracy: 0.8392\n",
            "Epoch 2/75\n",
            "469/469 - 2s - loss: 0.3974 - auc: 0.6925 - accuracy: 0.8467\n",
            "Epoch 3/75\n",
            "469/469 - 2s - loss: 0.3969 - auc: 0.6939 - accuracy: 0.8468\n",
            "Epoch 4/75\n",
            "469/469 - 2s - loss: 0.3965 - auc: 0.6949 - accuracy: 0.8468\n",
            "Epoch 5/75\n",
            "469/469 - 2s - loss: 0.3961 - auc: 0.6959 - accuracy: 0.8468\n",
            "Epoch 6/75\n",
            "469/469 - 2s - loss: 0.3959 - auc: 0.6965 - accuracy: 0.8468\n",
            "Epoch 7/75\n",
            "469/469 - 2s - loss: 0.3956 - auc: 0.6972 - accuracy: 0.8468\n",
            "Epoch 8/75\n",
            "469/469 - 2s - loss: 0.3954 - auc: 0.6978 - accuracy: 0.8469\n",
            "Epoch 9/75\n",
            "469/469 - 2s - loss: 0.3952 - auc: 0.6984 - accuracy: 0.8468\n",
            "Epoch 10/75\n",
            "469/469 - 2s - loss: 0.3950 - auc: 0.6988 - accuracy: 0.8468\n",
            "Epoch 11/75\n",
            "469/469 - 2s - loss: 0.3948 - auc: 0.6995 - accuracy: 0.8469\n",
            "Epoch 12/75\n",
            "469/469 - 2s - loss: 0.3947 - auc: 0.6997 - accuracy: 0.8469\n",
            "Epoch 13/75\n",
            "469/469 - 2s - loss: 0.3945 - auc: 0.7001 - accuracy: 0.8469\n",
            "Epoch 14/75\n",
            "469/469 - 2s - loss: 0.3944 - auc: 0.7006 - accuracy: 0.8468\n",
            "Epoch 15/75\n",
            "469/469 - 2s - loss: 0.3942 - auc: 0.7009 - accuracy: 0.8469\n",
            "Epoch 16/75\n",
            "469/469 - 2s - loss: 0.3941 - auc: 0.7011 - accuracy: 0.8469\n",
            "Epoch 17/75\n",
            "469/469 - 2s - loss: 0.3940 - auc: 0.7015 - accuracy: 0.8469\n",
            "Epoch 18/75\n",
            "469/469 - 2s - loss: 0.3939 - auc: 0.7017 - accuracy: 0.8469\n",
            "Epoch 19/75\n",
            "469/469 - 2s - loss: 0.3939 - auc: 0.7019 - accuracy: 0.8469\n",
            "Epoch 20/75\n",
            "469/469 - 2s - loss: 0.3938 - auc: 0.7020 - accuracy: 0.8469\n",
            "Epoch 21/75\n",
            "469/469 - 2s - loss: 0.3937 - auc: 0.7022 - accuracy: 0.8470\n",
            "Epoch 22/75\n",
            "469/469 - 2s - loss: 0.3936 - auc: 0.7025 - accuracy: 0.8469\n",
            "Epoch 23/75\n",
            "469/469 - 2s - loss: 0.3936 - auc: 0.7024 - accuracy: 0.8469\n",
            "Epoch 24/75\n",
            "469/469 - 2s - loss: 0.3935 - auc: 0.7028 - accuracy: 0.8469\n",
            "Epoch 25/75\n",
            "469/469 - 2s - loss: 0.3934 - auc: 0.7029 - accuracy: 0.8469\n",
            "Epoch 26/75\n",
            "469/469 - 2s - loss: 0.3933 - auc: 0.7032 - accuracy: 0.8470\n",
            "Epoch 27/75\n",
            "469/469 - 2s - loss: 0.3933 - auc: 0.7032 - accuracy: 0.8469\n",
            "Epoch 28/75\n",
            "469/469 - 2s - loss: 0.3933 - auc: 0.7034 - accuracy: 0.8469\n",
            "Epoch 29/75\n",
            "469/469 - 2s - loss: 0.3932 - auc: 0.7034 - accuracy: 0.8470\n",
            "Epoch 30/75\n",
            "469/469 - 2s - loss: 0.3932 - auc: 0.7037 - accuracy: 0.8469\n",
            "Epoch 31/75\n",
            "469/469 - 2s - loss: 0.3931 - auc: 0.7038 - accuracy: 0.8470\n",
            "Epoch 32/75\n",
            "469/469 - 2s - loss: 0.3931 - auc: 0.7038 - accuracy: 0.8470\n",
            "Epoch 33/75\n",
            "469/469 - 2s - loss: 0.3930 - auc: 0.7041 - accuracy: 0.8470\n",
            "Epoch 34/75\n",
            "469/469 - 2s - loss: 0.3930 - auc: 0.7042 - accuracy: 0.8470\n",
            "Epoch 35/75\n",
            "469/469 - 2s - loss: 0.3929 - auc: 0.7043 - accuracy: 0.8470\n",
            "Epoch 36/75\n",
            "469/469 - 2s - loss: 0.3929 - auc: 0.7043 - accuracy: 0.8469\n",
            "Epoch 37/75\n",
            "469/469 - 2s - loss: 0.3929 - auc: 0.7044 - accuracy: 0.8470\n",
            "Epoch 38/75\n",
            "469/469 - 2s - loss: 0.3928 - auc: 0.7045 - accuracy: 0.8470\n",
            "Epoch 39/75\n",
            "469/469 - 2s - loss: 0.3928 - auc: 0.7047 - accuracy: 0.8470\n",
            "Epoch 40/75\n",
            "469/469 - 2s - loss: 0.3928 - auc: 0.7047 - accuracy: 0.8470\n",
            "Epoch 41/75\n",
            "469/469 - 2s - loss: 0.3927 - auc: 0.7048 - accuracy: 0.8470\n",
            "Epoch 42/75\n",
            "469/469 - 2s - loss: 0.3927 - auc: 0.7049 - accuracy: 0.8470\n",
            "Epoch 43/75\n",
            "469/469 - 2s - loss: 0.3927 - auc: 0.7049 - accuracy: 0.8471\n",
            "Epoch 44/75\n",
            "469/469 - 2s - loss: 0.3926 - auc: 0.7050 - accuracy: 0.8470\n",
            "Epoch 45/75\n",
            "469/469 - 2s - loss: 0.3926 - auc: 0.7051 - accuracy: 0.8470\n",
            "Epoch 46/75\n",
            "469/469 - 2s - loss: 0.3926 - auc: 0.7052 - accuracy: 0.8470\n",
            "Epoch 47/75\n",
            "469/469 - 2s - loss: 0.3926 - auc: 0.7052 - accuracy: 0.8471\n",
            "Epoch 48/75\n",
            "469/469 - 2s - loss: 0.3925 - auc: 0.7053 - accuracy: 0.8470\n",
            "Epoch 49/75\n",
            "469/469 - 2s - loss: 0.3925 - auc: 0.7055 - accuracy: 0.8471\n",
            "Epoch 50/75\n",
            "469/469 - 2s - loss: 0.3925 - auc: 0.7055 - accuracy: 0.8470\n",
            "Epoch 51/75\n",
            "469/469 - 2s - loss: 0.3925 - auc: 0.7054 - accuracy: 0.8470\n",
            "Epoch 52/75\n",
            "469/469 - 2s - loss: 0.3924 - auc: 0.7056 - accuracy: 0.8471\n",
            "Epoch 53/75\n",
            "469/469 - 2s - loss: 0.3924 - auc: 0.7056 - accuracy: 0.8470\n",
            "Epoch 54/75\n",
            "469/469 - 2s - loss: 0.3924 - auc: 0.7058 - accuracy: 0.8470\n",
            "Epoch 55/75\n",
            "469/469 - 2s - loss: 0.3923 - auc: 0.7058 - accuracy: 0.8470\n",
            "Epoch 56/75\n",
            "469/469 - 2s - loss: 0.3923 - auc: 0.7059 - accuracy: 0.8470\n",
            "Epoch 57/75\n",
            "469/469 - 2s - loss: 0.3923 - auc: 0.7059 - accuracy: 0.8470\n",
            "Epoch 58/75\n",
            "469/469 - 2s - loss: 0.3923 - auc: 0.7060 - accuracy: 0.8470\n",
            "Epoch 59/75\n",
            "469/469 - 2s - loss: 0.3923 - auc: 0.7059 - accuracy: 0.8471\n",
            "Epoch 60/75\n",
            "469/469 - 2s - loss: 0.3922 - auc: 0.7062 - accuracy: 0.8471\n",
            "Epoch 61/75\n",
            "469/469 - 2s - loss: 0.3922 - auc: 0.7063 - accuracy: 0.8471\n",
            "Epoch 62/75\n",
            "469/469 - 2s - loss: 0.3922 - auc: 0.7061 - accuracy: 0.8471\n",
            "Epoch 63/75\n",
            "469/469 - 2s - loss: 0.3922 - auc: 0.7063 - accuracy: 0.8470\n",
            "Epoch 64/75\n",
            "469/469 - 2s - loss: 0.3921 - auc: 0.7064 - accuracy: 0.8471\n",
            "Epoch 65/75\n",
            "469/469 - 2s - loss: 0.3921 - auc: 0.7064 - accuracy: 0.8471\n",
            "Epoch 66/75\n",
            "469/469 - 2s - loss: 0.3921 - auc: 0.7064 - accuracy: 0.8471\n",
            "Epoch 67/75\n",
            "469/469 - 2s - loss: 0.3921 - auc: 0.7065 - accuracy: 0.8472\n",
            "Epoch 68/75\n",
            "469/469 - 2s - loss: 0.3920 - auc: 0.7067 - accuracy: 0.8470\n",
            "Epoch 69/75\n",
            "469/469 - 2s - loss: 0.3921 - auc: 0.7065 - accuracy: 0.8471\n",
            "Epoch 70/75\n",
            "469/469 - 2s - loss: 0.3920 - auc: 0.7067 - accuracy: 0.8471\n",
            "Epoch 71/75\n",
            "469/469 - 2s - loss: 0.3920 - auc: 0.7067 - accuracy: 0.8470\n",
            "Epoch 72/75\n",
            "469/469 - 2s - loss: 0.3920 - auc: 0.7068 - accuracy: 0.8470\n",
            "Epoch 73/75\n",
            "469/469 - 2s - loss: 0.3919 - auc: 0.7069 - accuracy: 0.8471\n",
            "Epoch 74/75\n",
            "469/469 - 2s - loss: 0.3919 - auc: 0.7069 - accuracy: 0.8471\n",
            "Epoch 75/75\n",
            "469/469 - 2s - loss: 0.3919 - auc: 0.7069 - accuracy: 0.8470\n",
            "7319/7319 - 6s\n",
            "7319/7319 - 6s\n",
            "Epoch 1/75\n",
            "469/469 - 2s - loss: 0.4130 - auc: 0.6876 - accuracy: 0.8362\n",
            "Epoch 2/75\n",
            "469/469 - 2s - loss: 0.3972 - auc: 0.6933 - accuracy: 0.8468\n",
            "Epoch 3/75\n",
            "469/469 - 2s - loss: 0.3966 - auc: 0.6946 - accuracy: 0.8468\n",
            "Epoch 4/75\n",
            "469/469 - 2s - loss: 0.3962 - auc: 0.6960 - accuracy: 0.8467\n",
            "Epoch 5/75\n",
            "469/469 - 2s - loss: 0.3958 - auc: 0.6969 - accuracy: 0.8467\n",
            "Epoch 6/75\n",
            "469/469 - 2s - loss: 0.3955 - auc: 0.6978 - accuracy: 0.8468\n",
            "Epoch 7/75\n",
            "469/469 - 2s - loss: 0.3952 - auc: 0.6984 - accuracy: 0.8468\n",
            "Epoch 8/75\n",
            "469/469 - 2s - loss: 0.3950 - auc: 0.6991 - accuracy: 0.8469\n",
            "Epoch 9/75\n",
            "469/469 - 2s - loss: 0.3948 - auc: 0.6997 - accuracy: 0.8468\n",
            "Epoch 10/75\n",
            "469/469 - 2s - loss: 0.3946 - auc: 0.7002 - accuracy: 0.8468\n",
            "Epoch 11/75\n",
            "469/469 - 2s - loss: 0.3943 - auc: 0.7009 - accuracy: 0.8469\n",
            "Epoch 12/75\n",
            "469/469 - 2s - loss: 0.3942 - auc: 0.7011 - accuracy: 0.8470\n",
            "Epoch 13/75\n",
            "469/469 - 2s - loss: 0.3941 - auc: 0.7016 - accuracy: 0.8469\n",
            "Epoch 14/75\n",
            "469/469 - 2s - loss: 0.3939 - auc: 0.7019 - accuracy: 0.8469\n",
            "Epoch 15/75\n",
            "469/469 - 2s - loss: 0.3938 - auc: 0.7022 - accuracy: 0.8469\n",
            "Epoch 16/75\n",
            "469/469 - 2s - loss: 0.3937 - auc: 0.7024 - accuracy: 0.8469\n",
            "Epoch 17/75\n",
            "469/469 - 2s - loss: 0.3936 - auc: 0.7028 - accuracy: 0.8469\n",
            "Epoch 18/75\n",
            "469/469 - 2s - loss: 0.3935 - auc: 0.7030 - accuracy: 0.8470\n",
            "Epoch 19/75\n",
            "469/469 - 2s - loss: 0.3933 - auc: 0.7035 - accuracy: 0.8470\n",
            "Epoch 20/75\n",
            "469/469 - 2s - loss: 0.3933 - auc: 0.7036 - accuracy: 0.8469\n",
            "Epoch 21/75\n",
            "469/469 - 2s - loss: 0.3932 - auc: 0.7038 - accuracy: 0.8470\n",
            "Epoch 22/75\n",
            "469/469 - 2s - loss: 0.3931 - auc: 0.7041 - accuracy: 0.8470\n",
            "Epoch 23/75\n",
            "469/469 - 2s - loss: 0.3930 - auc: 0.7043 - accuracy: 0.8469\n",
            "Epoch 24/75\n",
            "469/469 - 2s - loss: 0.3930 - auc: 0.7044 - accuracy: 0.8470\n",
            "Epoch 25/75\n",
            "469/469 - 2s - loss: 0.3929 - auc: 0.7046 - accuracy: 0.8470\n",
            "Epoch 26/75\n",
            "469/469 - 2s - loss: 0.3929 - auc: 0.7048 - accuracy: 0.8471\n",
            "Epoch 27/75\n",
            "469/469 - 2s - loss: 0.3927 - auc: 0.7051 - accuracy: 0.8470\n",
            "Epoch 28/75\n",
            "469/469 - 2s - loss: 0.3927 - auc: 0.7052 - accuracy: 0.8470\n",
            "Epoch 29/75\n",
            "469/469 - 2s - loss: 0.3927 - auc: 0.7053 - accuracy: 0.8471\n",
            "Epoch 30/75\n",
            "469/469 - 2s - loss: 0.3926 - auc: 0.7055 - accuracy: 0.8470\n",
            "Epoch 31/75\n",
            "469/469 - 2s - loss: 0.3925 - auc: 0.7055 - accuracy: 0.8470\n",
            "Epoch 32/75\n",
            "469/469 - 2s - loss: 0.3925 - auc: 0.7058 - accuracy: 0.8469\n",
            "Epoch 33/75\n",
            "469/469 - 2s - loss: 0.3924 - auc: 0.7058 - accuracy: 0.8470\n",
            "Epoch 34/75\n",
            "469/469 - 2s - loss: 0.3924 - auc: 0.7061 - accuracy: 0.8470\n",
            "Epoch 35/75\n",
            "469/469 - 2s - loss: 0.3924 - auc: 0.7060 - accuracy: 0.8470\n",
            "Epoch 36/75\n",
            "469/469 - 2s - loss: 0.3923 - auc: 0.7063 - accuracy: 0.8471\n",
            "Epoch 37/75\n",
            "469/469 - 2s - loss: 0.3923 - auc: 0.7063 - accuracy: 0.8470\n",
            "Epoch 38/75\n",
            "469/469 - 2s - loss: 0.3922 - auc: 0.7065 - accuracy: 0.8470\n",
            "Epoch 39/75\n",
            "469/469 - 2s - loss: 0.3922 - auc: 0.7065 - accuracy: 0.8470\n",
            "Epoch 40/75\n",
            "469/469 - 2s - loss: 0.3921 - auc: 0.7066 - accuracy: 0.8471\n",
            "Epoch 41/75\n",
            "469/469 - 2s - loss: 0.3921 - auc: 0.7067 - accuracy: 0.8472\n",
            "Epoch 42/75\n",
            "469/469 - 2s - loss: 0.3920 - auc: 0.7069 - accuracy: 0.8471\n",
            "Epoch 43/75\n",
            "469/469 - 2s - loss: 0.3920 - auc: 0.7070 - accuracy: 0.8472\n",
            "Epoch 44/75\n",
            "469/469 - 2s - loss: 0.3920 - auc: 0.7070 - accuracy: 0.8470\n",
            "Epoch 45/75\n",
            "469/469 - 2s - loss: 0.3919 - auc: 0.7072 - accuracy: 0.8471\n",
            "Epoch 46/75\n",
            "469/469 - 2s - loss: 0.3919 - auc: 0.7073 - accuracy: 0.8471\n",
            "Epoch 47/75\n",
            "469/469 - 2s - loss: 0.3919 - auc: 0.7072 - accuracy: 0.8472\n",
            "Epoch 48/75\n",
            "469/469 - 2s - loss: 0.3918 - auc: 0.7075 - accuracy: 0.8472\n",
            "Epoch 49/75\n",
            "469/469 - 2s - loss: 0.3918 - auc: 0.7075 - accuracy: 0.8471\n",
            "Epoch 50/75\n",
            "469/469 - 2s - loss: 0.3918 - auc: 0.7075 - accuracy: 0.8471\n",
            "Epoch 51/75\n",
            "469/469 - 2s - loss: 0.3918 - auc: 0.7075 - accuracy: 0.8470\n",
            "Epoch 52/75\n",
            "469/469 - 2s - loss: 0.3917 - auc: 0.7078 - accuracy: 0.8471\n",
            "Epoch 53/75\n",
            "469/469 - 2s - loss: 0.3917 - auc: 0.7077 - accuracy: 0.8471\n",
            "Epoch 54/75\n",
            "469/469 - 2s - loss: 0.3917 - auc: 0.7077 - accuracy: 0.8471\n",
            "Epoch 55/75\n",
            "469/469 - 2s - loss: 0.3917 - auc: 0.7079 - accuracy: 0.8471\n",
            "Epoch 56/75\n",
            "469/469 - 2s - loss: 0.3916 - auc: 0.7080 - accuracy: 0.8471\n",
            "Epoch 57/75\n",
            "469/469 - 2s - loss: 0.3916 - auc: 0.7080 - accuracy: 0.8471\n",
            "Epoch 58/75\n",
            "469/469 - 2s - loss: 0.3916 - auc: 0.7080 - accuracy: 0.8472\n",
            "Epoch 59/75\n",
            "469/469 - 2s - loss: 0.3916 - auc: 0.7081 - accuracy: 0.8471\n",
            "Epoch 60/75\n",
            "469/469 - 2s - loss: 0.3916 - auc: 0.7082 - accuracy: 0.8471\n",
            "Epoch 61/75\n",
            "469/469 - 2s - loss: 0.3915 - auc: 0.7082 - accuracy: 0.8472\n",
            "Epoch 62/75\n",
            "469/469 - 2s - loss: 0.3915 - auc: 0.7084 - accuracy: 0.8472\n",
            "Epoch 63/75\n",
            "469/469 - 2s - loss: 0.3915 - auc: 0.7085 - accuracy: 0.8472\n",
            "Epoch 64/75\n",
            "469/469 - 2s - loss: 0.3915 - auc: 0.7083 - accuracy: 0.8472\n",
            "Epoch 65/75\n",
            "469/469 - 2s - loss: 0.3915 - auc: 0.7084 - accuracy: 0.8472\n",
            "Epoch 66/75\n",
            "469/469 - 2s - loss: 0.3914 - auc: 0.7085 - accuracy: 0.8472\n",
            "Epoch 67/75\n",
            "469/469 - 2s - loss: 0.3914 - auc: 0.7086 - accuracy: 0.8471\n",
            "Epoch 68/75\n",
            "469/469 - 2s - loss: 0.3914 - auc: 0.7087 - accuracy: 0.8471\n",
            "Epoch 69/75\n",
            "469/469 - 2s - loss: 0.3914 - auc: 0.7086 - accuracy: 0.8472\n",
            "Epoch 70/75\n",
            "469/469 - 2s - loss: 0.3914 - auc: 0.7086 - accuracy: 0.8472\n",
            "Epoch 71/75\n",
            "469/469 - 2s - loss: 0.3913 - auc: 0.7087 - accuracy: 0.8472\n",
            "Epoch 72/75\n",
            "469/469 - 2s - loss: 0.3913 - auc: 0.7087 - accuracy: 0.8472\n",
            "Epoch 73/75\n",
            "469/469 - 2s - loss: 0.3913 - auc: 0.7088 - accuracy: 0.8472\n",
            "Epoch 74/75\n",
            "469/469 - 2s - loss: 0.3913 - auc: 0.7090 - accuracy: 0.8472\n",
            "Epoch 75/75\n",
            "469/469 - 2s - loss: 0.3913 - auc: 0.7089 - accuracy: 0.8473\n",
            "7319/7319 - 6s\n",
            "7319/7319 - 6s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRABpf7p38Qh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4fe9dcd4-90aa-4121-e90a-741f51bd05c2"
      },
      "source": [
        "cvModel1['test_roc_auc'].mean(), cvModel1['test_loan_loss'].mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6990771527933791, -132348.06666666668)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qtbarn4T_VBz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a6a8dab9-5128-43e3-e2e8-72becd115e81"
      },
      "source": [
        "cvModel2['test_roc_auc'].mean(), cvModel2['test_loan_loss'].mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.695923159097911, -131294.23333333337)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cRkYUJm7JT1K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cc59cba8-063d-41ce-d80b-612b80ea8332"
      },
      "source": [
        "cvModel3['test_roc_auc'].mean(), cvModel3['test_loan_loss'].mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6973859938966679, -131773.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wlo3xTdkKycH"
      },
      "source": [
        "# NN: under sampling strategy with final architecture\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6jyoDuWGKycS",
        "colab": {}
      },
      "source": [
        "#Setup pipeline.\n",
        "stepsNN = [('under', RandomUnderSampler()), ('model', KerasClassifier(build_fn=create_model2, verbose=2))]\n",
        "pipelineNN = Pipeline(steps=stepsNN)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kVRNwic0Kycj",
        "colab": {}
      },
      "source": [
        "#Parameters for grid search.\n",
        "param_gridNN = [{'model__epochs': [75],\n",
        "              'model__batch_size': [1000],\n",
        "              'under': [None,\n",
        "                        RandomUnderSampler(random_state=rs, sampling_strategy=0.4),\n",
        "                        RandomUnderSampler(random_state=rs, sampling_strategy=0.5),\n",
        "                        RandomUnderSampler(random_state=rs, sampling_strategy=0.6),\n",
        "                        RandomUnderSampler(random_state=rs, sampling_strategy=0.7),\n",
        "                        RandomUnderSampler(random_state=rs, sampling_strategy=0.8),\n",
        "                        RandomUnderSampler(random_state=rs, sampling_strategy=0.9),\n",
        "                        RandomUnderSampler(random_state=rs, sampling_strategy=1)]}]\n"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Q7NCz3dSKydB",
        "colab": {}
      },
      "source": [
        "#Cross validation object.\n",
        "gridNNFinal = GridSearchCV(pipelineNN, param_grid=param_gridNN, scoring=scoringDict2, cv = kFold2, verbose=1,\n",
        "                                        refit='roc_auc', n_jobs=1)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RuIr5RbyKydQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "39954a1d-9eca-447f-921d-eb1cde51a6c8"
      },
      "source": [
        "#Fit cross validation object.\n",
        "gridNNFinal.fit(X=dfPostImpute[trainAll], y=trainLabels)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "469/469 - 2s - loss: 0.4057 - auc_2: 0.6746 - accuracy: 0.8434\n",
            "Epoch 2/75\n",
            "469/469 - 2s - loss: 0.3976 - auc_2: 0.6919 - accuracy: 0.8467\n",
            "Epoch 3/75\n",
            "469/469 - 2s - loss: 0.3967 - auc_2: 0.6943 - accuracy: 0.8468\n",
            "Epoch 4/75\n",
            "469/469 - 2s - loss: 0.3962 - auc_2: 0.6957 - accuracy: 0.8469\n",
            "Epoch 5/75\n",
            "469/469 - 2s - loss: 0.3958 - auc_2: 0.6967 - accuracy: 0.8469\n",
            "Epoch 6/75\n",
            "469/469 - 2s - loss: 0.3955 - auc_2: 0.6976 - accuracy: 0.8469\n",
            "Epoch 7/75\n",
            "469/469 - 2s - loss: 0.3953 - auc_2: 0.6981 - accuracy: 0.8469\n",
            "Epoch 8/75\n",
            "469/469 - 2s - loss: 0.3950 - auc_2: 0.6989 - accuracy: 0.8469\n",
            "Epoch 9/75\n",
            "469/469 - 2s - loss: 0.3948 - auc_2: 0.6994 - accuracy: 0.8468\n",
            "Epoch 10/75\n",
            "469/469 - 2s - loss: 0.3947 - auc_2: 0.6998 - accuracy: 0.8470\n",
            "Epoch 11/75\n",
            "469/469 - 2s - loss: 0.3944 - auc_2: 0.7005 - accuracy: 0.8469\n",
            "Epoch 12/75\n",
            "469/469 - 2s - loss: 0.3943 - auc_2: 0.7008 - accuracy: 0.8470\n",
            "Epoch 13/75\n",
            "469/469 - 2s - loss: 0.3942 - auc_2: 0.7012 - accuracy: 0.8470\n",
            "Epoch 14/75\n",
            "469/469 - 2s - loss: 0.3940 - auc_2: 0.7015 - accuracy: 0.8469\n",
            "Epoch 15/75\n",
            "469/469 - 2s - loss: 0.3939 - auc_2: 0.7018 - accuracy: 0.8470\n",
            "Epoch 16/75\n",
            "469/469 - 2s - loss: 0.3938 - auc_2: 0.7020 - accuracy: 0.8470\n",
            "Epoch 17/75\n",
            "469/469 - 2s - loss: 0.3937 - auc_2: 0.7024 - accuracy: 0.8470\n",
            "Epoch 18/75\n",
            "469/469 - 2s - loss: 0.3936 - auc_2: 0.7026 - accuracy: 0.8470\n",
            "Epoch 19/75\n",
            "469/469 - 2s - loss: 0.3935 - auc_2: 0.7029 - accuracy: 0.8470\n",
            "Epoch 20/75\n",
            "469/469 - 2s - loss: 0.3934 - auc_2: 0.7032 - accuracy: 0.8469\n",
            "Epoch 21/75\n",
            "469/469 - 2s - loss: 0.3933 - auc_2: 0.7033 - accuracy: 0.8470\n",
            "Epoch 22/75\n",
            "469/469 - 2s - loss: 0.3933 - auc_2: 0.7035 - accuracy: 0.8471\n",
            "Epoch 23/75\n",
            "469/469 - 2s - loss: 0.3932 - auc_2: 0.7038 - accuracy: 0.8470\n",
            "Epoch 24/75\n",
            "469/469 - 2s - loss: 0.3931 - auc_2: 0.7041 - accuracy: 0.8471\n",
            "Epoch 25/75\n",
            "469/469 - 2s - loss: 0.3930 - auc_2: 0.7042 - accuracy: 0.8471\n",
            "Epoch 26/75\n",
            "469/469 - 2s - loss: 0.3929 - auc_2: 0.7043 - accuracy: 0.8470\n",
            "Epoch 27/75\n",
            "469/469 - 2s - loss: 0.3929 - auc_2: 0.7046 - accuracy: 0.8469\n",
            "Epoch 28/75\n",
            "469/469 - 2s - loss: 0.3929 - auc_2: 0.7046 - accuracy: 0.8471\n",
            "Epoch 29/75\n",
            "469/469 - 2s - loss: 0.3927 - auc_2: 0.7050 - accuracy: 0.8470\n",
            "Epoch 30/75\n",
            "469/469 - 2s - loss: 0.3927 - auc_2: 0.7051 - accuracy: 0.8470\n",
            "Epoch 31/75\n",
            "469/469 - 2s - loss: 0.3926 - auc_2: 0.7052 - accuracy: 0.8471\n",
            "Epoch 32/75\n",
            "469/469 - 2s - loss: 0.3926 - auc_2: 0.7054 - accuracy: 0.8471\n",
            "Epoch 33/75\n",
            "469/469 - 2s - loss: 0.3925 - auc_2: 0.7056 - accuracy: 0.8470\n",
            "Epoch 34/75\n",
            "469/469 - 2s - loss: 0.3924 - auc_2: 0.7058 - accuracy: 0.8471\n",
            "Epoch 35/75\n",
            "469/469 - 2s - loss: 0.3924 - auc_2: 0.7057 - accuracy: 0.8470\n",
            "Epoch 36/75\n",
            "469/469 - 2s - loss: 0.3923 - auc_2: 0.7060 - accuracy: 0.8470\n",
            "Epoch 37/75\n",
            "469/469 - 2s - loss: 0.3923 - auc_2: 0.7061 - accuracy: 0.8471\n",
            "Epoch 38/75\n",
            "469/469 - 2s - loss: 0.3922 - auc_2: 0.7062 - accuracy: 0.8470\n",
            "Epoch 39/75\n",
            "469/469 - 2s - loss: 0.3921 - auc_2: 0.7064 - accuracy: 0.8471\n",
            "Epoch 40/75\n",
            "469/469 - 2s - loss: 0.3921 - auc_2: 0.7066 - accuracy: 0.8471\n",
            "Epoch 41/75\n",
            "469/469 - 2s - loss: 0.3920 - auc_2: 0.7067 - accuracy: 0.8470\n",
            "Epoch 42/75\n",
            "469/469 - 2s - loss: 0.3920 - auc_2: 0.7069 - accuracy: 0.8470\n",
            "Epoch 43/75\n",
            "469/469 - 2s - loss: 0.3919 - auc_2: 0.7071 - accuracy: 0.8470\n",
            "Epoch 44/75\n",
            "469/469 - 2s - loss: 0.3919 - auc_2: 0.7070 - accuracy: 0.8471\n",
            "Epoch 45/75\n",
            "469/469 - 2s - loss: 0.3919 - auc_2: 0.7071 - accuracy: 0.8472\n",
            "Epoch 46/75\n",
            "469/469 - 2s - loss: 0.3918 - auc_2: 0.7072 - accuracy: 0.8470\n",
            "Epoch 47/75\n",
            "469/469 - 2s - loss: 0.3918 - auc_2: 0.7073 - accuracy: 0.8471\n",
            "Epoch 48/75\n",
            "469/469 - 2s - loss: 0.3917 - auc_2: 0.7076 - accuracy: 0.8470\n",
            "Epoch 49/75\n",
            "469/469 - 2s - loss: 0.3917 - auc_2: 0.7076 - accuracy: 0.8471\n",
            "Epoch 50/75\n",
            "469/469 - 2s - loss: 0.3916 - auc_2: 0.7077 - accuracy: 0.8471\n",
            "Epoch 51/75\n",
            "469/469 - 2s - loss: 0.3916 - auc_2: 0.7078 - accuracy: 0.8471\n",
            "Epoch 52/75\n",
            "469/469 - 2s - loss: 0.3916 - auc_2: 0.7079 - accuracy: 0.8471\n",
            "Epoch 53/75\n",
            "469/469 - 2s - loss: 0.3915 - auc_2: 0.7080 - accuracy: 0.8471\n",
            "Epoch 54/75\n",
            "469/469 - 2s - loss: 0.3915 - auc_2: 0.7082 - accuracy: 0.8471\n",
            "Epoch 55/75\n",
            "469/469 - 2s - loss: 0.3914 - auc_2: 0.7082 - accuracy: 0.8471\n",
            "Epoch 56/75\n",
            "469/469 - 2s - loss: 0.3914 - auc_2: 0.7083 - accuracy: 0.8471\n",
            "Epoch 57/75\n",
            "469/469 - 2s - loss: 0.3914 - auc_2: 0.7084 - accuracy: 0.8470\n",
            "Epoch 58/75\n",
            "469/469 - 2s - loss: 0.3913 - auc_2: 0.7085 - accuracy: 0.8470\n",
            "Epoch 59/75\n",
            "469/469 - 2s - loss: 0.3913 - auc_2: 0.7086 - accuracy: 0.8472\n",
            "Epoch 60/75\n",
            "469/469 - 2s - loss: 0.3913 - auc_2: 0.7086 - accuracy: 0.8472\n",
            "Epoch 61/75\n",
            "469/469 - 2s - loss: 0.3913 - auc_2: 0.7087 - accuracy: 0.8471\n",
            "Epoch 62/75\n",
            "469/469 - 2s - loss: 0.3912 - auc_2: 0.7089 - accuracy: 0.8471\n",
            "Epoch 63/75\n",
            "469/469 - 2s - loss: 0.3912 - auc_2: 0.7089 - accuracy: 0.8471\n",
            "Epoch 64/75\n",
            "469/469 - 2s - loss: 0.3911 - auc_2: 0.7091 - accuracy: 0.8472\n",
            "Epoch 65/75\n",
            "469/469 - 2s - loss: 0.3911 - auc_2: 0.7091 - accuracy: 0.8471\n",
            "Epoch 66/75\n",
            "469/469 - 2s - loss: 0.3911 - auc_2: 0.7091 - accuracy: 0.8472\n",
            "Epoch 67/75\n",
            "469/469 - 2s - loss: 0.3911 - auc_2: 0.7091 - accuracy: 0.8471\n",
            "Epoch 68/75\n",
            "469/469 - 2s - loss: 0.3910 - auc_2: 0.7093 - accuracy: 0.8472\n",
            "Epoch 69/75\n",
            "469/469 - 2s - loss: 0.3910 - auc_2: 0.7093 - accuracy: 0.8472\n",
            "Epoch 70/75\n",
            "469/469 - 2s - loss: 0.3910 - auc_2: 0.7094 - accuracy: 0.8471\n",
            "Epoch 71/75\n",
            "469/469 - 2s - loss: 0.3909 - auc_2: 0.7096 - accuracy: 0.8471\n",
            "Epoch 72/75\n",
            "469/469 - 2s - loss: 0.3909 - auc_2: 0.7096 - accuracy: 0.8472\n",
            "Epoch 73/75\n",
            "469/469 - 2s - loss: 0.3909 - auc_2: 0.7096 - accuracy: 0.8472\n",
            "Epoch 74/75\n",
            "469/469 - 2s - loss: 0.3909 - auc_2: 0.7097 - accuracy: 0.8473\n",
            "Epoch 75/75\n",
            "469/469 - 2s - loss: 0.3908 - auc_2: 0.7098 - accuracy: 0.8472\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py:241: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "235/235 - 0s\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py:264: Sequential.predict_proba (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use `model.predict()` instead.\n",
            "235/235 - 0s\n",
            "Epoch 1/75\n",
            "469/469 - 2s - loss: 0.4053 - auc_2: 0.6932 - accuracy: 0.8433\n",
            "Epoch 2/75\n",
            "469/469 - 2s - loss: 0.3970 - auc_2: 0.6936 - accuracy: 0.8468\n",
            "Epoch 3/75\n",
            "469/469 - 2s - loss: 0.3963 - auc_2: 0.6957 - accuracy: 0.8469\n",
            "Epoch 4/75\n",
            "469/469 - 2s - loss: 0.3958 - auc_2: 0.6969 - accuracy: 0.8469\n",
            "Epoch 5/75\n",
            "469/469 - 2s - loss: 0.3953 - auc_2: 0.6981 - accuracy: 0.8469\n",
            "Epoch 6/75\n",
            "469/469 - 2s - loss: 0.3950 - auc_2: 0.6991 - accuracy: 0.8469\n",
            "Epoch 7/75\n",
            "469/469 - 2s - loss: 0.3947 - auc_2: 0.6997 - accuracy: 0.8469\n",
            "Epoch 8/75\n",
            "469/469 - 2s - loss: 0.3945 - auc_2: 0.7004 - accuracy: 0.8470\n",
            "Epoch 9/75\n",
            "469/469 - 2s - loss: 0.3943 - auc_2: 0.7009 - accuracy: 0.8469\n",
            "Epoch 10/75\n",
            "469/469 - 2s - loss: 0.3940 - auc_2: 0.7015 - accuracy: 0.8470\n",
            "Epoch 11/75\n",
            "469/469 - 2s - loss: 0.3939 - auc_2: 0.7021 - accuracy: 0.8469\n",
            "Epoch 12/75\n",
            "469/469 - 2s - loss: 0.3938 - auc_2: 0.7023 - accuracy: 0.8470\n",
            "Epoch 13/75\n",
            "469/469 - 2s - loss: 0.3936 - auc_2: 0.7027 - accuracy: 0.8470\n",
            "Epoch 14/75\n",
            "469/469 - 2s - loss: 0.3935 - auc_2: 0.7031 - accuracy: 0.8470\n",
            "Epoch 15/75\n",
            "469/469 - 2s - loss: 0.3934 - auc_2: 0.7032 - accuracy: 0.8470\n",
            "Epoch 16/75\n",
            "469/469 - 2s - loss: 0.3932 - auc_2: 0.7038 - accuracy: 0.8470\n",
            "Epoch 17/75\n",
            "469/469 - 2s - loss: 0.3931 - auc_2: 0.7039 - accuracy: 0.8470\n",
            "Epoch 18/75\n",
            "469/469 - 2s - loss: 0.3931 - auc_2: 0.7041 - accuracy: 0.8470\n",
            "Epoch 19/75\n",
            "469/469 - 2s - loss: 0.3930 - auc_2: 0.7042 - accuracy: 0.8470\n",
            "Epoch 20/75\n",
            "469/469 - 2s - loss: 0.3929 - auc_2: 0.7046 - accuracy: 0.8470\n",
            "Epoch 21/75\n",
            "469/469 - 2s - loss: 0.3928 - auc_2: 0.7049 - accuracy: 0.8470\n",
            "Epoch 22/75\n",
            "469/469 - 2s - loss: 0.3927 - auc_2: 0.7050 - accuracy: 0.8471\n",
            "Epoch 23/75\n",
            "469/469 - 2s - loss: 0.3926 - auc_2: 0.7052 - accuracy: 0.8471\n",
            "Epoch 24/75\n",
            "469/469 - 2s - loss: 0.3926 - auc_2: 0.7053 - accuracy: 0.8470\n",
            "Epoch 25/75\n",
            "469/469 - 2s - loss: 0.3925 - auc_2: 0.7056 - accuracy: 0.8471\n",
            "Epoch 26/75\n",
            "469/469 - 2s - loss: 0.3924 - auc_2: 0.7056 - accuracy: 0.8471\n",
            "Epoch 27/75\n",
            "469/469 - 2s - loss: 0.3924 - auc_2: 0.7058 - accuracy: 0.8471\n",
            "Epoch 28/75\n",
            "469/469 - 2s - loss: 0.3923 - auc_2: 0.7060 - accuracy: 0.8472\n",
            "Epoch 29/75\n",
            "469/469 - 2s - loss: 0.3922 - auc_2: 0.7063 - accuracy: 0.8471\n",
            "Epoch 30/75\n",
            "469/469 - 2s - loss: 0.3922 - auc_2: 0.7063 - accuracy: 0.8472\n",
            "Epoch 31/75\n",
            "469/469 - 2s - loss: 0.3922 - auc_2: 0.7064 - accuracy: 0.8471\n",
            "Epoch 32/75\n",
            "469/469 - 2s - loss: 0.3921 - auc_2: 0.7065 - accuracy: 0.8472\n",
            "Epoch 33/75\n",
            "469/469 - 2s - loss: 0.3920 - auc_2: 0.7067 - accuracy: 0.8472\n",
            "Epoch 34/75\n",
            "469/469 - 2s - loss: 0.3920 - auc_2: 0.7068 - accuracy: 0.8471\n",
            "Epoch 35/75\n",
            "469/469 - 2s - loss: 0.3919 - auc_2: 0.7069 - accuracy: 0.8472\n",
            "Epoch 36/75\n",
            "469/469 - 2s - loss: 0.3919 - auc_2: 0.7071 - accuracy: 0.8471\n",
            "Epoch 37/75\n",
            "469/469 - 2s - loss: 0.3918 - auc_2: 0.7072 - accuracy: 0.8472\n",
            "Epoch 38/75\n",
            "469/469 - 2s - loss: 0.3918 - auc_2: 0.7072 - accuracy: 0.8472\n",
            "Epoch 39/75\n",
            "469/469 - 2s - loss: 0.3918 - auc_2: 0.7074 - accuracy: 0.8472\n",
            "Epoch 40/75\n",
            "469/469 - 2s - loss: 0.3917 - auc_2: 0.7074 - accuracy: 0.8472\n",
            "Epoch 41/75\n",
            "469/469 - 2s - loss: 0.3917 - auc_2: 0.7075 - accuracy: 0.8471\n",
            "Epoch 42/75\n",
            "469/469 - 2s - loss: 0.3916 - auc_2: 0.7077 - accuracy: 0.8472\n",
            "Epoch 43/75\n",
            "469/469 - 2s - loss: 0.3916 - auc_2: 0.7078 - accuracy: 0.8472\n",
            "Epoch 44/75\n",
            "469/469 - 2s - loss: 0.3916 - auc_2: 0.7078 - accuracy: 0.8472\n",
            "Epoch 45/75\n",
            "469/469 - 2s - loss: 0.3916 - auc_2: 0.7079 - accuracy: 0.8471\n",
            "Epoch 46/75\n",
            "469/469 - 2s - loss: 0.3915 - auc_2: 0.7080 - accuracy: 0.8472\n",
            "Epoch 47/75\n",
            "469/469 - 2s - loss: 0.3914 - auc_2: 0.7082 - accuracy: 0.8472\n",
            "Epoch 48/75\n",
            "469/469 - 2s - loss: 0.3914 - auc_2: 0.7083 - accuracy: 0.8473\n",
            "Epoch 49/75\n",
            "469/469 - 2s - loss: 0.3914 - auc_2: 0.7083 - accuracy: 0.8472\n",
            "Epoch 50/75\n",
            "469/469 - 2s - loss: 0.3914 - auc_2: 0.7082 - accuracy: 0.8473\n",
            "Epoch 51/75\n",
            "469/469 - 2s - loss: 0.3913 - auc_2: 0.7084 - accuracy: 0.8473\n",
            "Epoch 52/75\n",
            "469/469 - 2s - loss: 0.3912 - auc_2: 0.7086 - accuracy: 0.8473\n",
            "Epoch 53/75\n",
            "469/469 - 2s - loss: 0.3912 - auc_2: 0.7086 - accuracy: 0.8473\n",
            "Epoch 54/75\n",
            "469/469 - 2s - loss: 0.3911 - auc_2: 0.7089 - accuracy: 0.8472\n",
            "Epoch 55/75\n",
            "469/469 - 2s - loss: 0.3912 - auc_2: 0.7087 - accuracy: 0.8473\n",
            "Epoch 56/75\n",
            "469/469 - 2s - loss: 0.3912 - auc_2: 0.7089 - accuracy: 0.8473\n",
            "Epoch 57/75\n",
            "469/469 - 2s - loss: 0.3911 - auc_2: 0.7089 - accuracy: 0.8473\n",
            "Epoch 58/75\n",
            "469/469 - 2s - loss: 0.3911 - auc_2: 0.7090 - accuracy: 0.8472\n",
            "Epoch 59/75\n",
            "469/469 - 2s - loss: 0.3911 - auc_2: 0.7090 - accuracy: 0.8473\n",
            "Epoch 60/75\n",
            "469/469 - 2s - loss: 0.3910 - auc_2: 0.7091 - accuracy: 0.8473\n",
            "Epoch 61/75\n",
            "469/469 - 2s - loss: 0.3910 - auc_2: 0.7093 - accuracy: 0.8473\n",
            "Epoch 62/75\n",
            "469/469 - 2s - loss: 0.3910 - auc_2: 0.7093 - accuracy: 0.8472\n",
            "Epoch 63/75\n",
            "469/469 - 2s - loss: 0.3909 - auc_2: 0.7094 - accuracy: 0.8472\n",
            "Epoch 64/75\n",
            "469/469 - 2s - loss: 0.3909 - auc_2: 0.7095 - accuracy: 0.8474\n",
            "Epoch 65/75\n",
            "469/469 - 2s - loss: 0.3909 - auc_2: 0.7095 - accuracy: 0.8473\n",
            "Epoch 66/75\n",
            "469/469 - 2s - loss: 0.3909 - auc_2: 0.7096 - accuracy: 0.8472\n",
            "Epoch 67/75\n",
            "469/469 - 2s - loss: 0.3908 - auc_2: 0.7098 - accuracy: 0.8473\n",
            "Epoch 68/75\n",
            "469/469 - 2s - loss: 0.3908 - auc_2: 0.7098 - accuracy: 0.8473\n",
            "Epoch 69/75\n",
            "469/469 - 2s - loss: 0.3908 - auc_2: 0.7098 - accuracy: 0.8473\n",
            "Epoch 70/75\n",
            "469/469 - 2s - loss: 0.3907 - auc_2: 0.7100 - accuracy: 0.8473\n",
            "Epoch 71/75\n",
            "469/469 - 2s - loss: 0.3907 - auc_2: 0.7098 - accuracy: 0.8473\n",
            "Epoch 72/75\n",
            "469/469 - 2s - loss: 0.3907 - auc_2: 0.7100 - accuracy: 0.8472\n",
            "Epoch 73/75\n",
            "469/469 - 2s - loss: 0.3906 - auc_2: 0.7101 - accuracy: 0.8473\n",
            "Epoch 74/75\n",
            "469/469 - 2s - loss: 0.3906 - auc_2: 0.7102 - accuracy: 0.8473\n",
            "Epoch 75/75\n",
            "469/469 - 2s - loss: 0.3906 - auc_2: 0.7102 - accuracy: 0.8473\n",
            "235/235 - 0s\n",
            "235/235 - 0s\n",
            "Epoch 1/75\n",
            "469/469 - 2s - loss: 0.4067 - auc_2: 0.6921 - accuracy: 0.8423\n",
            "Epoch 2/75\n",
            "469/469 - 2s - loss: 0.3977 - auc_2: 0.6919 - accuracy: 0.8466\n",
            "Epoch 3/75\n",
            "469/469 - 2s - loss: 0.3969 - auc_2: 0.6940 - accuracy: 0.8467\n",
            "Epoch 4/75\n",
            "469/469 - 2s - loss: 0.3963 - auc_2: 0.6954 - accuracy: 0.8468\n",
            "Epoch 5/75\n",
            "469/469 - 2s - loss: 0.3959 - auc_2: 0.6965 - accuracy: 0.8468\n",
            "Epoch 6/75\n",
            "469/469 - 2s - loss: 0.3955 - auc_2: 0.6976 - accuracy: 0.8468\n",
            "Epoch 7/75\n",
            "469/469 - 2s - loss: 0.3953 - auc_2: 0.6981 - accuracy: 0.8468\n",
            "Epoch 8/75\n",
            "469/469 - 2s - loss: 0.3950 - auc_2: 0.6988 - accuracy: 0.8469\n",
            "Epoch 9/75\n",
            "469/469 - 2s - loss: 0.3948 - auc_2: 0.6994 - accuracy: 0.8468\n",
            "Epoch 10/75\n",
            "469/469 - 2s - loss: 0.3946 - auc_2: 0.6999 - accuracy: 0.8469\n",
            "Epoch 11/75\n",
            "469/469 - 2s - loss: 0.3944 - auc_2: 0.7003 - accuracy: 0.8469\n",
            "Epoch 12/75\n",
            "469/469 - 2s - loss: 0.3943 - auc_2: 0.7007 - accuracy: 0.8468\n",
            "Epoch 13/75\n",
            "469/469 - 2s - loss: 0.3941 - auc_2: 0.7012 - accuracy: 0.8469\n",
            "Epoch 14/75\n",
            "469/469 - 2s - loss: 0.3940 - auc_2: 0.7015 - accuracy: 0.8469\n",
            "Epoch 15/75\n",
            "469/469 - 2s - loss: 0.3939 - auc_2: 0.7018 - accuracy: 0.8470\n",
            "Epoch 16/75\n",
            "469/469 - 2s - loss: 0.3937 - auc_2: 0.7021 - accuracy: 0.8470\n",
            "Epoch 17/75\n",
            "469/469 - 2s - loss: 0.3936 - auc_2: 0.7024 - accuracy: 0.8470\n",
            "Epoch 18/75\n",
            "469/469 - 2s - loss: 0.3935 - auc_2: 0.7027 - accuracy: 0.8470\n",
            "Epoch 19/75\n",
            "469/469 - 2s - loss: 0.3934 - auc_2: 0.7030 - accuracy: 0.8470\n",
            "Epoch 20/75\n",
            "469/469 - 2s - loss: 0.3933 - auc_2: 0.7032 - accuracy: 0.8471\n",
            "Epoch 21/75\n",
            "469/469 - 2s - loss: 0.3933 - auc_2: 0.7033 - accuracy: 0.8471\n",
            "Epoch 22/75\n",
            "469/469 - 2s - loss: 0.3932 - auc_2: 0.7036 - accuracy: 0.8471\n",
            "Epoch 23/75\n",
            "469/469 - 2s - loss: 0.3931 - auc_2: 0.7037 - accuracy: 0.8470\n",
            "Epoch 24/75\n",
            "469/469 - 2s - loss: 0.3930 - auc_2: 0.7039 - accuracy: 0.8471\n",
            "Epoch 25/75\n",
            "469/469 - 2s - loss: 0.3929 - auc_2: 0.7041 - accuracy: 0.8471\n",
            "Epoch 26/75\n",
            "469/469 - 2s - loss: 0.3929 - auc_2: 0.7043 - accuracy: 0.8470\n",
            "Epoch 27/75\n",
            "469/469 - 2s - loss: 0.3928 - auc_2: 0.7044 - accuracy: 0.8472\n",
            "Epoch 28/75\n",
            "469/469 - 2s - loss: 0.3928 - auc_2: 0.7046 - accuracy: 0.8471\n",
            "Epoch 29/75\n",
            "469/469 - 2s - loss: 0.3927 - auc_2: 0.7047 - accuracy: 0.8472\n",
            "Epoch 30/75\n",
            "469/469 - 2s - loss: 0.3926 - auc_2: 0.7050 - accuracy: 0.8471\n",
            "Epoch 31/75\n",
            "469/469 - 2s - loss: 0.3926 - auc_2: 0.7051 - accuracy: 0.8472\n",
            "Epoch 32/75\n",
            "469/469 - 2s - loss: 0.3925 - auc_2: 0.7052 - accuracy: 0.8472\n",
            "Epoch 33/75\n",
            "469/469 - 2s - loss: 0.3925 - auc_2: 0.7053 - accuracy: 0.8471\n",
            "Epoch 34/75\n",
            "469/469 - 2s - loss: 0.3924 - auc_2: 0.7056 - accuracy: 0.8472\n",
            "Epoch 35/75\n",
            "469/469 - 2s - loss: 0.3924 - auc_2: 0.7056 - accuracy: 0.8472\n",
            "Epoch 36/75\n",
            "469/469 - 2s - loss: 0.3923 - auc_2: 0.7057 - accuracy: 0.8472\n",
            "Epoch 37/75\n",
            "469/469 - 2s - loss: 0.3922 - auc_2: 0.7060 - accuracy: 0.8471\n",
            "Epoch 38/75\n",
            "469/469 - 2s - loss: 0.3922 - auc_2: 0.7059 - accuracy: 0.8472\n",
            "Epoch 39/75\n",
            "469/469 - 2s - loss: 0.3922 - auc_2: 0.7061 - accuracy: 0.8472\n",
            "Epoch 40/75\n",
            "469/469 - 2s - loss: 0.3921 - auc_2: 0.7062 - accuracy: 0.8472\n",
            "Epoch 41/75\n",
            "469/469 - 2s - loss: 0.3921 - auc_2: 0.7063 - accuracy: 0.8473\n",
            "Epoch 42/75\n",
            "469/469 - 2s - loss: 0.3920 - auc_2: 0.7065 - accuracy: 0.8472\n",
            "Epoch 43/75\n",
            "469/469 - 2s - loss: 0.3920 - auc_2: 0.7066 - accuracy: 0.8473\n",
            "Epoch 44/75\n",
            "469/469 - 2s - loss: 0.3920 - auc_2: 0.7067 - accuracy: 0.8473\n",
            "Epoch 45/75\n",
            "469/469 - 2s - loss: 0.3919 - auc_2: 0.7069 - accuracy: 0.8472\n",
            "Epoch 46/75\n",
            "469/469 - 2s - loss: 0.3919 - auc_2: 0.7069 - accuracy: 0.8473\n",
            "Epoch 47/75\n",
            "469/469 - 2s - loss: 0.3919 - auc_2: 0.7070 - accuracy: 0.8472\n",
            "Epoch 48/75\n",
            "469/469 - 2s - loss: 0.3918 - auc_2: 0.7071 - accuracy: 0.8472\n",
            "Epoch 49/75\n",
            "469/469 - 2s - loss: 0.3917 - auc_2: 0.7073 - accuracy: 0.8472\n",
            "Epoch 50/75\n",
            "469/469 - 2s - loss: 0.3917 - auc_2: 0.7074 - accuracy: 0.8472\n",
            "Epoch 51/75\n",
            "469/469 - 2s - loss: 0.3917 - auc_2: 0.7074 - accuracy: 0.8472\n",
            "Epoch 52/75\n",
            "469/469 - 2s - loss: 0.3917 - auc_2: 0.7075 - accuracy: 0.8472\n",
            "Epoch 53/75\n",
            "469/469 - 2s - loss: 0.3916 - auc_2: 0.7077 - accuracy: 0.8472\n",
            "Epoch 54/75\n",
            "469/469 - 2s - loss: 0.3916 - auc_2: 0.7077 - accuracy: 0.8472\n",
            "Epoch 55/75\n",
            "469/469 - 2s - loss: 0.3916 - auc_2: 0.7076 - accuracy: 0.8472\n",
            "Epoch 56/75\n",
            "469/469 - 2s - loss: 0.3915 - auc_2: 0.7079 - accuracy: 0.8473\n",
            "Epoch 57/75\n",
            "469/469 - 2s - loss: 0.3915 - auc_2: 0.7079 - accuracy: 0.8472\n",
            "Epoch 58/75\n",
            "469/469 - 2s - loss: 0.3915 - auc_2: 0.7080 - accuracy: 0.8473\n",
            "Epoch 59/75\n",
            "469/469 - 2s - loss: 0.3914 - auc_2: 0.7081 - accuracy: 0.8473\n",
            "Epoch 60/75\n",
            "469/469 - 2s - loss: 0.3914 - auc_2: 0.7082 - accuracy: 0.8473\n",
            "Epoch 61/75\n",
            "469/469 - 2s - loss: 0.3914 - auc_2: 0.7083 - accuracy: 0.8472\n",
            "Epoch 62/75\n",
            "469/469 - 2s - loss: 0.3913 - auc_2: 0.7083 - accuracy: 0.8472\n",
            "Epoch 63/75\n",
            "469/469 - 2s - loss: 0.3913 - auc_2: 0.7084 - accuracy: 0.8472\n",
            "Epoch 64/75\n",
            "469/469 - 2s - loss: 0.3913 - auc_2: 0.7086 - accuracy: 0.8473\n",
            "Epoch 65/75\n",
            "469/469 - 2s - loss: 0.3913 - auc_2: 0.7084 - accuracy: 0.8473\n",
            "Epoch 66/75\n",
            "469/469 - 2s - loss: 0.3912 - auc_2: 0.7086 - accuracy: 0.8473\n",
            "Epoch 67/75\n",
            "469/469 - 2s - loss: 0.3912 - auc_2: 0.7086 - accuracy: 0.8473\n",
            "Epoch 68/75\n",
            "469/469 - 2s - loss: 0.3912 - auc_2: 0.7087 - accuracy: 0.8473\n",
            "Epoch 69/75\n",
            "469/469 - 2s - loss: 0.3911 - auc_2: 0.7089 - accuracy: 0.8472\n",
            "Epoch 70/75\n",
            "469/469 - 2s - loss: 0.3911 - auc_2: 0.7089 - accuracy: 0.8473\n",
            "Epoch 71/75\n",
            "469/469 - 2s - loss: 0.3911 - auc_2: 0.7089 - accuracy: 0.8473\n",
            "Epoch 72/75\n",
            "469/469 - 2s - loss: 0.3910 - auc_2: 0.7092 - accuracy: 0.8472\n",
            "Epoch 73/75\n",
            "469/469 - 2s - loss: 0.3911 - auc_2: 0.7090 - accuracy: 0.8473\n",
            "Epoch 74/75\n",
            "469/469 - 2s - loss: 0.3910 - auc_2: 0.7092 - accuracy: 0.8473\n",
            "Epoch 75/75\n",
            "469/469 - 2s - loss: 0.3910 - auc_2: 0.7092 - accuracy: 0.8473\n",
            "235/235 - 0s\n",
            "235/235 - 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "252/252 - 1s - loss: 0.5572 - auc_2: 0.7217 - accuracy: 0.7178\n",
            "Epoch 2/75\n",
            "252/252 - 1s - loss: 0.5512 - auc_2: 0.6901 - accuracy: 0.7222\n",
            "Epoch 3/75\n",
            "252/252 - 1s - loss: 0.5502 - auc_2: 0.6919 - accuracy: 0.7226\n",
            "Epoch 4/75\n",
            "252/252 - 1s - loss: 0.5495 - auc_2: 0.6931 - accuracy: 0.7234\n",
            "Epoch 5/75\n",
            "252/252 - 1s - loss: 0.5489 - auc_2: 0.6942 - accuracy: 0.7237\n",
            "Epoch 6/75\n",
            "252/252 - 1s - loss: 0.5484 - auc_2: 0.6950 - accuracy: 0.7240\n",
            "Epoch 7/75\n",
            "252/252 - 1s - loss: 0.5480 - auc_2: 0.6957 - accuracy: 0.7240\n",
            "Epoch 8/75\n",
            "252/252 - 1s - loss: 0.5476 - auc_2: 0.6964 - accuracy: 0.7242\n",
            "Epoch 9/75\n",
            "252/252 - 1s - loss: 0.5472 - auc_2: 0.6971 - accuracy: 0.7249\n",
            "Epoch 10/75\n",
            "252/252 - 1s - loss: 0.5468 - auc_2: 0.6977 - accuracy: 0.7245\n",
            "Epoch 11/75\n",
            "252/252 - 1s - loss: 0.5465 - auc_2: 0.6983 - accuracy: 0.7248\n",
            "Epoch 12/75\n",
            "252/252 - 1s - loss: 0.5463 - auc_2: 0.6987 - accuracy: 0.7248\n",
            "Epoch 13/75\n",
            "252/252 - 1s - loss: 0.5460 - auc_2: 0.6993 - accuracy: 0.7249\n",
            "Epoch 14/75\n",
            "252/252 - 1s - loss: 0.5457 - auc_2: 0.6997 - accuracy: 0.7257\n",
            "Epoch 15/75\n",
            "252/252 - 1s - loss: 0.5455 - auc_2: 0.7000 - accuracy: 0.7251\n",
            "Epoch 16/75\n",
            "252/252 - 1s - loss: 0.5453 - auc_2: 0.7003 - accuracy: 0.7253\n",
            "Epoch 17/75\n",
            "252/252 - 1s - loss: 0.5451 - auc_2: 0.7008 - accuracy: 0.7254\n",
            "Epoch 18/75\n",
            "252/252 - 1s - loss: 0.5449 - auc_2: 0.7010 - accuracy: 0.7256\n",
            "Epoch 19/75\n",
            "252/252 - 1s - loss: 0.5448 - auc_2: 0.7014 - accuracy: 0.7257\n",
            "Epoch 20/75\n",
            "252/252 - 1s - loss: 0.5446 - auc_2: 0.7017 - accuracy: 0.7253\n",
            "Epoch 21/75\n",
            "252/252 - 1s - loss: 0.5445 - auc_2: 0.7017 - accuracy: 0.7255\n",
            "Epoch 22/75\n",
            "252/252 - 1s - loss: 0.5443 - auc_2: 0.7022 - accuracy: 0.7257\n",
            "Epoch 23/75\n",
            "252/252 - 1s - loss: 0.5442 - auc_2: 0.7023 - accuracy: 0.7262\n",
            "Epoch 24/75\n",
            "252/252 - 1s - loss: 0.5440 - auc_2: 0.7027 - accuracy: 0.7257\n",
            "Epoch 25/75\n",
            "252/252 - 1s - loss: 0.5438 - auc_2: 0.7030 - accuracy: 0.7260\n",
            "Epoch 26/75\n",
            "252/252 - 1s - loss: 0.5438 - auc_2: 0.7030 - accuracy: 0.7260\n",
            "Epoch 27/75\n",
            "252/252 - 1s - loss: 0.5437 - auc_2: 0.7032 - accuracy: 0.7263\n",
            "Epoch 28/75\n",
            "252/252 - 1s - loss: 0.5435 - auc_2: 0.7035 - accuracy: 0.7263\n",
            "Epoch 29/75\n",
            "252/252 - 1s - loss: 0.5434 - auc_2: 0.7037 - accuracy: 0.7262\n",
            "Epoch 30/75\n",
            "252/252 - 1s - loss: 0.5433 - auc_2: 0.7039 - accuracy: 0.7263\n",
            "Epoch 31/75\n",
            "252/252 - 1s - loss: 0.5432 - auc_2: 0.7041 - accuracy: 0.7264\n",
            "Epoch 32/75\n",
            "252/252 - 1s - loss: 0.5431 - auc_2: 0.7044 - accuracy: 0.7264\n",
            "Epoch 33/75\n",
            "252/252 - 1s - loss: 0.5430 - auc_2: 0.7045 - accuracy: 0.7266\n",
            "Epoch 34/75\n",
            "252/252 - 1s - loss: 0.5429 - auc_2: 0.7047 - accuracy: 0.7265\n",
            "Epoch 35/75\n",
            "252/252 - 1s - loss: 0.5427 - auc_2: 0.7049 - accuracy: 0.7267\n",
            "Epoch 36/75\n",
            "252/252 - 1s - loss: 0.5427 - auc_2: 0.7050 - accuracy: 0.7267\n",
            "Epoch 37/75\n",
            "252/252 - 1s - loss: 0.5425 - auc_2: 0.7052 - accuracy: 0.7271\n",
            "Epoch 38/75\n",
            "252/252 - 1s - loss: 0.5425 - auc_2: 0.7054 - accuracy: 0.7270\n",
            "Epoch 39/75\n",
            "252/252 - 1s - loss: 0.5424 - auc_2: 0.7055 - accuracy: 0.7266\n",
            "Epoch 40/75\n",
            "252/252 - 1s - loss: 0.5423 - auc_2: 0.7057 - accuracy: 0.7266\n",
            "Epoch 41/75\n",
            "252/252 - 1s - loss: 0.5422 - auc_2: 0.7058 - accuracy: 0.7268\n",
            "Epoch 42/75\n",
            "252/252 - 1s - loss: 0.5421 - auc_2: 0.7060 - accuracy: 0.7270\n",
            "Epoch 43/75\n",
            "252/252 - 1s - loss: 0.5420 - auc_2: 0.7061 - accuracy: 0.7273\n",
            "Epoch 44/75\n",
            "252/252 - 1s - loss: 0.5420 - auc_2: 0.7063 - accuracy: 0.7273\n",
            "Epoch 45/75\n",
            "252/252 - 1s - loss: 0.5419 - auc_2: 0.7064 - accuracy: 0.7272\n",
            "Epoch 46/75\n",
            "252/252 - 1s - loss: 0.5418 - auc_2: 0.7065 - accuracy: 0.7272\n",
            "Epoch 47/75\n",
            "252/252 - 1s - loss: 0.5418 - auc_2: 0.7065 - accuracy: 0.7278\n",
            "Epoch 48/75\n",
            "252/252 - 1s - loss: 0.5417 - auc_2: 0.7067 - accuracy: 0.7274\n",
            "Epoch 49/75\n",
            "252/252 - 1s - loss: 0.5416 - auc_2: 0.7069 - accuracy: 0.7272\n",
            "Epoch 50/75\n",
            "252/252 - 1s - loss: 0.5416 - auc_2: 0.7069 - accuracy: 0.7272\n",
            "Epoch 51/75\n",
            "252/252 - 1s - loss: 0.5414 - auc_2: 0.7072 - accuracy: 0.7275\n",
            "Epoch 52/75\n",
            "252/252 - 1s - loss: 0.5414 - auc_2: 0.7071 - accuracy: 0.7275\n",
            "Epoch 53/75\n",
            "252/252 - 1s - loss: 0.5414 - auc_2: 0.7072 - accuracy: 0.7278\n",
            "Epoch 54/75\n",
            "252/252 - 1s - loss: 0.5413 - auc_2: 0.7075 - accuracy: 0.7280\n",
            "Epoch 55/75\n",
            "252/252 - 1s - loss: 0.5412 - auc_2: 0.7075 - accuracy: 0.7280\n",
            "Epoch 56/75\n",
            "252/252 - 1s - loss: 0.5412 - auc_2: 0.7075 - accuracy: 0.7278\n",
            "Epoch 57/75\n",
            "252/252 - 1s - loss: 0.5410 - auc_2: 0.7079 - accuracy: 0.7276\n",
            "Epoch 58/75\n",
            "252/252 - 1s - loss: 0.5411 - auc_2: 0.7077 - accuracy: 0.7277\n",
            "Epoch 59/75\n",
            "252/252 - 1s - loss: 0.5410 - auc_2: 0.7079 - accuracy: 0.7279\n",
            "Epoch 60/75\n",
            "252/252 - 1s - loss: 0.5409 - auc_2: 0.7080 - accuracy: 0.7281\n",
            "Epoch 61/75\n",
            "252/252 - 1s - loss: 0.5409 - auc_2: 0.7081 - accuracy: 0.7279\n",
            "Epoch 62/75\n",
            "252/252 - 1s - loss: 0.5408 - auc_2: 0.7082 - accuracy: 0.7279\n",
            "Epoch 63/75\n",
            "252/252 - 1s - loss: 0.5407 - auc_2: 0.7083 - accuracy: 0.7280\n",
            "Epoch 64/75\n",
            "252/252 - 1s - loss: 0.5407 - auc_2: 0.7084 - accuracy: 0.7284\n",
            "Epoch 65/75\n",
            "252/252 - 1s - loss: 0.5406 - auc_2: 0.7085 - accuracy: 0.7284\n",
            "Epoch 66/75\n",
            "252/252 - 1s - loss: 0.5406 - auc_2: 0.7086 - accuracy: 0.7284\n",
            "Epoch 67/75\n",
            "252/252 - 1s - loss: 0.5405 - auc_2: 0.7087 - accuracy: 0.7282\n",
            "Epoch 68/75\n",
            "252/252 - 1s - loss: 0.5405 - auc_2: 0.7088 - accuracy: 0.7282\n",
            "Epoch 69/75\n",
            "252/252 - 1s - loss: 0.5404 - auc_2: 0.7087 - accuracy: 0.7283\n",
            "Epoch 70/75\n",
            "252/252 - 1s - loss: 0.5403 - auc_2: 0.7090 - accuracy: 0.7285\n",
            "Epoch 71/75\n",
            "252/252 - 1s - loss: 0.5403 - auc_2: 0.7091 - accuracy: 0.7285\n",
            "Epoch 72/75\n",
            "252/252 - 1s - loss: 0.5402 - auc_2: 0.7092 - accuracy: 0.7288\n",
            "Epoch 73/75\n",
            "252/252 - 1s - loss: 0.5402 - auc_2: 0.7091 - accuracy: 0.7280\n",
            "Epoch 74/75\n",
            "252/252 - 1s - loss: 0.5401 - auc_2: 0.7093 - accuracy: 0.7289\n",
            "Epoch 75/75\n",
            "252/252 - 1s - loss: 0.5401 - auc_2: 0.7093 - accuracy: 0.7285\n",
            "235/235 - 0s\n",
            "235/235 - 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "252/252 - 1s - loss: 0.5576 - auc_2: 0.6945 - accuracy: 0.7166\n",
            "Epoch 2/75\n",
            "252/252 - 1s - loss: 0.5497 - auc_2: 0.6931 - accuracy: 0.7230\n",
            "Epoch 3/75\n",
            "252/252 - 1s - loss: 0.5488 - auc_2: 0.6947 - accuracy: 0.7239\n",
            "Epoch 4/75\n",
            "252/252 - 1s - loss: 0.5481 - auc_2: 0.6960 - accuracy: 0.7237\n",
            "Epoch 5/75\n",
            "252/252 - 1s - loss: 0.5475 - auc_2: 0.6969 - accuracy: 0.7238\n",
            "Epoch 6/75\n",
            "252/252 - 1s - loss: 0.5470 - auc_2: 0.6977 - accuracy: 0.7243\n",
            "Epoch 7/75\n",
            "252/252 - 1s - loss: 0.5465 - auc_2: 0.6986 - accuracy: 0.7243\n",
            "Epoch 8/75\n",
            "252/252 - 1s - loss: 0.5463 - auc_2: 0.6990 - accuracy: 0.7246\n",
            "Epoch 9/75\n",
            "252/252 - 1s - loss: 0.5459 - auc_2: 0.6997 - accuracy: 0.7245\n",
            "Epoch 10/75\n",
            "252/252 - 1s - loss: 0.5455 - auc_2: 0.7003 - accuracy: 0.7247\n",
            "Epoch 11/75\n",
            "252/252 - 1s - loss: 0.5453 - auc_2: 0.7007 - accuracy: 0.7250\n",
            "Epoch 12/75\n",
            "252/252 - 1s - loss: 0.5450 - auc_2: 0.7012 - accuracy: 0.7252\n",
            "Epoch 13/75\n",
            "252/252 - 1s - loss: 0.5449 - auc_2: 0.7015 - accuracy: 0.7252\n",
            "Epoch 14/75\n",
            "252/252 - 1s - loss: 0.5446 - auc_2: 0.7020 - accuracy: 0.7248\n",
            "Epoch 15/75\n",
            "252/252 - 1s - loss: 0.5443 - auc_2: 0.7023 - accuracy: 0.7254\n",
            "Epoch 16/75\n",
            "252/252 - 1s - loss: 0.5442 - auc_2: 0.7026 - accuracy: 0.7252\n",
            "Epoch 17/75\n",
            "252/252 - 1s - loss: 0.5440 - auc_2: 0.7029 - accuracy: 0.7258\n",
            "Epoch 18/75\n",
            "252/252 - 1s - loss: 0.5439 - auc_2: 0.7032 - accuracy: 0.7258\n",
            "Epoch 19/75\n",
            "252/252 - 1s - loss: 0.5436 - auc_2: 0.7035 - accuracy: 0.7258\n",
            "Epoch 20/75\n",
            "252/252 - 1s - loss: 0.5435 - auc_2: 0.7038 - accuracy: 0.7261\n",
            "Epoch 21/75\n",
            "252/252 - 1s - loss: 0.5433 - auc_2: 0.7040 - accuracy: 0.7259\n",
            "Epoch 22/75\n",
            "252/252 - 1s - loss: 0.5432 - auc_2: 0.7043 - accuracy: 0.7263\n",
            "Epoch 23/75\n",
            "252/252 - 1s - loss: 0.5431 - auc_2: 0.7044 - accuracy: 0.7262\n",
            "Epoch 24/75\n",
            "252/252 - 1s - loss: 0.5429 - auc_2: 0.7048 - accuracy: 0.7267\n",
            "Epoch 25/75\n",
            "252/252 - 1s - loss: 0.5428 - auc_2: 0.7050 - accuracy: 0.7269\n",
            "Epoch 26/75\n",
            "252/252 - 1s - loss: 0.5427 - auc_2: 0.7050 - accuracy: 0.7266\n",
            "Epoch 27/75\n",
            "252/252 - 1s - loss: 0.5426 - auc_2: 0.7053 - accuracy: 0.7269\n",
            "Epoch 28/75\n",
            "252/252 - 1s - loss: 0.5425 - auc_2: 0.7054 - accuracy: 0.7272\n",
            "Epoch 29/75\n",
            "252/252 - 1s - loss: 0.5424 - auc_2: 0.7057 - accuracy: 0.7266\n",
            "Epoch 30/75\n",
            "252/252 - 1s - loss: 0.5423 - auc_2: 0.7057 - accuracy: 0.7269\n",
            "Epoch 31/75\n",
            "252/252 - 1s - loss: 0.5422 - auc_2: 0.7059 - accuracy: 0.7273\n",
            "Epoch 32/75\n",
            "252/252 - 1s - loss: 0.5420 - auc_2: 0.7063 - accuracy: 0.7269\n",
            "Epoch 33/75\n",
            "252/252 - 1s - loss: 0.5419 - auc_2: 0.7064 - accuracy: 0.7274\n",
            "Epoch 34/75\n",
            "252/252 - 1s - loss: 0.5419 - auc_2: 0.7065 - accuracy: 0.7273\n",
            "Epoch 35/75\n",
            "252/252 - 1s - loss: 0.5418 - auc_2: 0.7065 - accuracy: 0.7277\n",
            "Epoch 36/75\n",
            "252/252 - 1s - loss: 0.5416 - auc_2: 0.7070 - accuracy: 0.7275\n",
            "Epoch 37/75\n",
            "252/252 - 1s - loss: 0.5416 - auc_2: 0.7070 - accuracy: 0.7277\n",
            "Epoch 38/75\n",
            "252/252 - 1s - loss: 0.5415 - auc_2: 0.7072 - accuracy: 0.7277\n",
            "Epoch 39/75\n",
            "252/252 - 1s - loss: 0.5414 - auc_2: 0.7072 - accuracy: 0.7278\n",
            "Epoch 40/75\n",
            "252/252 - 1s - loss: 0.5413 - auc_2: 0.7074 - accuracy: 0.7276\n",
            "Epoch 41/75\n",
            "252/252 - 1s - loss: 0.5413 - auc_2: 0.7076 - accuracy: 0.7278\n",
            "Epoch 42/75\n",
            "252/252 - 1s - loss: 0.5411 - auc_2: 0.7077 - accuracy: 0.7278\n",
            "Epoch 43/75\n",
            "252/252 - 1s - loss: 0.5411 - auc_2: 0.7079 - accuracy: 0.7281\n",
            "Epoch 44/75\n",
            "252/252 - 1s - loss: 0.5411 - auc_2: 0.7080 - accuracy: 0.7281\n",
            "Epoch 45/75\n",
            "252/252 - 1s - loss: 0.5409 - auc_2: 0.7081 - accuracy: 0.7284\n",
            "Epoch 46/75\n",
            "252/252 - 1s - loss: 0.5409 - auc_2: 0.7081 - accuracy: 0.7281\n",
            "Epoch 47/75\n",
            "252/252 - 1s - loss: 0.5408 - auc_2: 0.7084 - accuracy: 0.7283\n",
            "Epoch 48/75\n",
            "252/252 - 1s - loss: 0.5407 - auc_2: 0.7086 - accuracy: 0.7284\n",
            "Epoch 49/75\n",
            "252/252 - 1s - loss: 0.5406 - auc_2: 0.7086 - accuracy: 0.7286\n",
            "Epoch 50/75\n",
            "252/252 - 1s - loss: 0.5406 - auc_2: 0.7087 - accuracy: 0.7287\n",
            "Epoch 51/75\n",
            "252/252 - 1s - loss: 0.5405 - auc_2: 0.7088 - accuracy: 0.7285\n",
            "Epoch 52/75\n",
            "252/252 - 1s - loss: 0.5404 - auc_2: 0.7089 - accuracy: 0.7286\n",
            "Epoch 53/75\n",
            "252/252 - 1s - loss: 0.5403 - auc_2: 0.7091 - accuracy: 0.7288\n",
            "Epoch 54/75\n",
            "252/252 - 1s - loss: 0.5404 - auc_2: 0.7091 - accuracy: 0.7284\n",
            "Epoch 55/75\n",
            "252/252 - 1s - loss: 0.5402 - auc_2: 0.7094 - accuracy: 0.7284\n",
            "Epoch 56/75\n",
            "252/252 - 1s - loss: 0.5402 - auc_2: 0.7094 - accuracy: 0.7286\n",
            "Epoch 57/75\n",
            "252/252 - 1s - loss: 0.5401 - auc_2: 0.7096 - accuracy: 0.7288\n",
            "Epoch 58/75\n",
            "252/252 - 1s - loss: 0.5400 - auc_2: 0.7097 - accuracy: 0.7289\n",
            "Epoch 59/75\n",
            "252/252 - 1s - loss: 0.5400 - auc_2: 0.7097 - accuracy: 0.7291\n",
            "Epoch 60/75\n",
            "252/252 - 1s - loss: 0.5399 - auc_2: 0.7100 - accuracy: 0.7287\n",
            "Epoch 61/75\n",
            "252/252 - 1s - loss: 0.5398 - auc_2: 0.7100 - accuracy: 0.7288\n",
            "Epoch 62/75\n",
            "252/252 - 1s - loss: 0.5398 - auc_2: 0.7100 - accuracy: 0.7289\n",
            "Epoch 63/75\n",
            "252/252 - 1s - loss: 0.5398 - auc_2: 0.7101 - accuracy: 0.7293\n",
            "Epoch 64/75\n",
            "252/252 - 1s - loss: 0.5396 - auc_2: 0.7102 - accuracy: 0.7293\n",
            "Epoch 65/75\n",
            "252/252 - 1s - loss: 0.5397 - auc_2: 0.7103 - accuracy: 0.7290\n",
            "Epoch 66/75\n",
            "252/252 - 1s - loss: 0.5396 - auc_2: 0.7104 - accuracy: 0.7298\n",
            "Epoch 67/75\n",
            "252/252 - 1s - loss: 0.5395 - auc_2: 0.7105 - accuracy: 0.7294\n",
            "Epoch 68/75\n",
            "252/252 - 1s - loss: 0.5395 - auc_2: 0.7104 - accuracy: 0.7292\n",
            "Epoch 69/75\n",
            "252/252 - 1s - loss: 0.5394 - auc_2: 0.7107 - accuracy: 0.7292\n",
            "Epoch 70/75\n",
            "252/252 - 1s - loss: 0.5394 - auc_2: 0.7107 - accuracy: 0.7290\n",
            "Epoch 71/75\n",
            "252/252 - 1s - loss: 0.5392 - auc_2: 0.7110 - accuracy: 0.7293\n",
            "Epoch 72/75\n",
            "252/252 - 1s - loss: 0.5393 - auc_2: 0.7109 - accuracy: 0.7296\n",
            "Epoch 73/75\n",
            "252/252 - 1s - loss: 0.5392 - auc_2: 0.7110 - accuracy: 0.7295\n",
            "Epoch 74/75\n",
            "252/252 - 1s - loss: 0.5392 - auc_2: 0.7110 - accuracy: 0.7292\n",
            "Epoch 75/75\n",
            "252/252 - 1s - loss: 0.5392 - auc_2: 0.7110 - accuracy: 0.7295\n",
            "235/235 - 0s\n",
            "235/235 - 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "252/252 - 1s - loss: 0.5635 - auc_2: 0.6906 - accuracy: 0.7122\n",
            "Epoch 2/75\n",
            "252/252 - 1s - loss: 0.5503 - auc_2: 0.6921 - accuracy: 0.7229\n",
            "Epoch 3/75\n",
            "252/252 - 1s - loss: 0.5493 - auc_2: 0.6939 - accuracy: 0.7233\n",
            "Epoch 4/75\n",
            "252/252 - 1s - loss: 0.5485 - auc_2: 0.6953 - accuracy: 0.7237\n",
            "Epoch 5/75\n",
            "252/252 - 1s - loss: 0.5480 - auc_2: 0.6962 - accuracy: 0.7240\n",
            "Epoch 6/75\n",
            "252/252 - 1s - loss: 0.5475 - auc_2: 0.6970 - accuracy: 0.7241\n",
            "Epoch 7/75\n",
            "252/252 - 1s - loss: 0.5471 - auc_2: 0.6976 - accuracy: 0.7245\n",
            "Epoch 8/75\n",
            "252/252 - 1s - loss: 0.5467 - auc_2: 0.6983 - accuracy: 0.7247\n",
            "Epoch 9/75\n",
            "252/252 - 1s - loss: 0.5464 - auc_2: 0.6989 - accuracy: 0.7253\n",
            "Epoch 10/75\n",
            "252/252 - 1s - loss: 0.5462 - auc_2: 0.6992 - accuracy: 0.7254\n",
            "Epoch 11/75\n",
            "252/252 - 1s - loss: 0.5460 - auc_2: 0.6996 - accuracy: 0.7256\n",
            "Epoch 12/75\n",
            "252/252 - 1s - loss: 0.5457 - auc_2: 0.7000 - accuracy: 0.7251\n",
            "Epoch 13/75\n",
            "252/252 - 1s - loss: 0.5455 - auc_2: 0.7003 - accuracy: 0.7260\n",
            "Epoch 14/75\n",
            "252/252 - 1s - loss: 0.5454 - auc_2: 0.7006 - accuracy: 0.7258\n",
            "Epoch 15/75\n",
            "252/252 - 1s - loss: 0.5452 - auc_2: 0.7009 - accuracy: 0.7256\n",
            "Epoch 16/75\n",
            "252/252 - 1s - loss: 0.5450 - auc_2: 0.7011 - accuracy: 0.7262\n",
            "Epoch 17/75\n",
            "252/252 - 1s - loss: 0.5449 - auc_2: 0.7015 - accuracy: 0.7258\n",
            "Epoch 18/75\n",
            "252/252 - 1s - loss: 0.5447 - auc_2: 0.7018 - accuracy: 0.7261\n",
            "Epoch 19/75\n",
            "252/252 - 1s - loss: 0.5445 - auc_2: 0.7020 - accuracy: 0.7264\n",
            "Epoch 20/75\n",
            "252/252 - 1s - loss: 0.5445 - auc_2: 0.7023 - accuracy: 0.7259\n",
            "Epoch 21/75\n",
            "252/252 - 1s - loss: 0.5442 - auc_2: 0.7025 - accuracy: 0.7265\n",
            "Epoch 22/75\n",
            "252/252 - 1s - loss: 0.5442 - auc_2: 0.7027 - accuracy: 0.7266\n",
            "Epoch 23/75\n",
            "252/252 - 1s - loss: 0.5440 - auc_2: 0.7030 - accuracy: 0.7265\n",
            "Epoch 24/75\n",
            "252/252 - 1s - loss: 0.5438 - auc_2: 0.7033 - accuracy: 0.7266\n",
            "Epoch 25/75\n",
            "252/252 - 1s - loss: 0.5438 - auc_2: 0.7034 - accuracy: 0.7266\n",
            "Epoch 26/75\n",
            "252/252 - 1s - loss: 0.5436 - auc_2: 0.7037 - accuracy: 0.7270\n",
            "Epoch 27/75\n",
            "252/252 - 1s - loss: 0.5435 - auc_2: 0.7038 - accuracy: 0.7267\n",
            "Epoch 28/75\n",
            "252/252 - 1s - loss: 0.5434 - auc_2: 0.7041 - accuracy: 0.7272\n",
            "Epoch 29/75\n",
            "252/252 - 1s - loss: 0.5433 - auc_2: 0.7042 - accuracy: 0.7268\n",
            "Epoch 30/75\n",
            "252/252 - 1s - loss: 0.5432 - auc_2: 0.7044 - accuracy: 0.7270\n",
            "Epoch 31/75\n",
            "252/252 - 1s - loss: 0.5430 - auc_2: 0.7046 - accuracy: 0.7271\n",
            "Epoch 32/75\n",
            "252/252 - 1s - loss: 0.5429 - auc_2: 0.7048 - accuracy: 0.7268\n",
            "Epoch 33/75\n",
            "252/252 - 1s - loss: 0.5430 - auc_2: 0.7048 - accuracy: 0.7272\n",
            "Epoch 34/75\n",
            "252/252 - 1s - loss: 0.5428 - auc_2: 0.7051 - accuracy: 0.7273\n",
            "Epoch 35/75\n",
            "252/252 - 1s - loss: 0.5427 - auc_2: 0.7053 - accuracy: 0.7269\n",
            "Epoch 36/75\n",
            "252/252 - 1s - loss: 0.5426 - auc_2: 0.7053 - accuracy: 0.7274\n",
            "Epoch 37/75\n",
            "252/252 - 1s - loss: 0.5425 - auc_2: 0.7055 - accuracy: 0.7274\n",
            "Epoch 38/75\n",
            "252/252 - 1s - loss: 0.5424 - auc_2: 0.7057 - accuracy: 0.7275\n",
            "Epoch 39/75\n",
            "252/252 - 1s - loss: 0.5423 - auc_2: 0.7059 - accuracy: 0.7276\n",
            "Epoch 40/75\n",
            "252/252 - 1s - loss: 0.5422 - auc_2: 0.7061 - accuracy: 0.7277\n",
            "Epoch 41/75\n",
            "252/252 - 1s - loss: 0.5422 - auc_2: 0.7061 - accuracy: 0.7277\n",
            "Epoch 42/75\n",
            "252/252 - 1s - loss: 0.5420 - auc_2: 0.7064 - accuracy: 0.7272\n",
            "Epoch 43/75\n",
            "252/252 - 1s - loss: 0.5420 - auc_2: 0.7064 - accuracy: 0.7280\n",
            "Epoch 44/75\n",
            "252/252 - 1s - loss: 0.5419 - auc_2: 0.7066 - accuracy: 0.7279\n",
            "Epoch 45/75\n",
            "252/252 - 1s - loss: 0.5418 - auc_2: 0.7068 - accuracy: 0.7278\n",
            "Epoch 46/75\n",
            "252/252 - 1s - loss: 0.5418 - auc_2: 0.7069 - accuracy: 0.7277\n",
            "Epoch 47/75\n",
            "252/252 - 1s - loss: 0.5417 - auc_2: 0.7069 - accuracy: 0.7278\n",
            "Epoch 48/75\n",
            "252/252 - 1s - loss: 0.5416 - auc_2: 0.7071 - accuracy: 0.7281\n",
            "Epoch 49/75\n",
            "252/252 - 1s - loss: 0.5415 - auc_2: 0.7073 - accuracy: 0.7276\n",
            "Epoch 50/75\n",
            "252/252 - 1s - loss: 0.5414 - auc_2: 0.7075 - accuracy: 0.7280\n",
            "Epoch 51/75\n",
            "252/252 - 1s - loss: 0.5414 - auc_2: 0.7075 - accuracy: 0.7280\n",
            "Epoch 52/75\n",
            "252/252 - 1s - loss: 0.5413 - auc_2: 0.7077 - accuracy: 0.7283\n",
            "Epoch 53/75\n",
            "252/252 - 1s - loss: 0.5413 - auc_2: 0.7077 - accuracy: 0.7281\n",
            "Epoch 54/75\n",
            "252/252 - 1s - loss: 0.5411 - auc_2: 0.7079 - accuracy: 0.7280\n",
            "Epoch 55/75\n",
            "252/252 - 1s - loss: 0.5411 - auc_2: 0.7079 - accuracy: 0.7280\n",
            "Epoch 56/75\n",
            "252/252 - 1s - loss: 0.5411 - auc_2: 0.7080 - accuracy: 0.7280\n",
            "Epoch 57/75\n",
            "252/252 - 1s - loss: 0.5410 - auc_2: 0.7081 - accuracy: 0.7281\n",
            "Epoch 58/75\n",
            "252/252 - 1s - loss: 0.5410 - auc_2: 0.7082 - accuracy: 0.7284\n",
            "Epoch 59/75\n",
            "252/252 - 1s - loss: 0.5408 - auc_2: 0.7085 - accuracy: 0.7285\n",
            "Epoch 60/75\n",
            "252/252 - 1s - loss: 0.5408 - auc_2: 0.7085 - accuracy: 0.7286\n",
            "Epoch 61/75\n",
            "252/252 - 1s - loss: 0.5408 - auc_2: 0.7085 - accuracy: 0.7285\n",
            "Epoch 62/75\n",
            "252/252 - 1s - loss: 0.5407 - auc_2: 0.7085 - accuracy: 0.7282\n",
            "Epoch 63/75\n",
            "252/252 - 1s - loss: 0.5407 - auc_2: 0.7087 - accuracy: 0.7284\n",
            "Epoch 64/75\n",
            "252/252 - 1s - loss: 0.5406 - auc_2: 0.7089 - accuracy: 0.7285\n",
            "Epoch 65/75\n",
            "252/252 - 1s - loss: 0.5405 - auc_2: 0.7090 - accuracy: 0.7284\n",
            "Epoch 66/75\n",
            "252/252 - 1s - loss: 0.5405 - auc_2: 0.7090 - accuracy: 0.7287\n",
            "Epoch 67/75\n",
            "252/252 - 1s - loss: 0.5404 - auc_2: 0.7091 - accuracy: 0.7287\n",
            "Epoch 68/75\n",
            "252/252 - 1s - loss: 0.5404 - auc_2: 0.7091 - accuracy: 0.7283\n",
            "Epoch 69/75\n",
            "252/252 - 1s - loss: 0.5403 - auc_2: 0.7094 - accuracy: 0.7286\n",
            "Epoch 70/75\n",
            "252/252 - 1s - loss: 0.5403 - auc_2: 0.7095 - accuracy: 0.7284\n",
            "Epoch 71/75\n",
            "252/252 - 1s - loss: 0.5403 - auc_2: 0.7094 - accuracy: 0.7286\n",
            "Epoch 72/75\n",
            "252/252 - 1s - loss: 0.5402 - auc_2: 0.7096 - accuracy: 0.7284\n",
            "Epoch 73/75\n",
            "252/252 - 1s - loss: 0.5401 - auc_2: 0.7097 - accuracy: 0.7285\n",
            "Epoch 74/75\n",
            "252/252 - 1s - loss: 0.5402 - auc_2: 0.7096 - accuracy: 0.7285\n",
            "Epoch 75/75\n",
            "252/252 - 1s - loss: 0.5400 - auc_2: 0.7099 - accuracy: 0.7289\n",
            "235/235 - 0s\n",
            "235/235 - 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "216/216 - 1s - loss: 0.5933 - auc_2: 0.6962 - accuracy: 0.6805\n",
            "Epoch 2/75\n",
            "216/216 - 1s - loss: 0.5851 - auc_2: 0.6906 - accuracy: 0.6875\n",
            "Epoch 3/75\n",
            "216/216 - 1s - loss: 0.5840 - auc_2: 0.6924 - accuracy: 0.6878\n",
            "Epoch 4/75\n",
            "216/216 - 1s - loss: 0.5830 - auc_2: 0.6940 - accuracy: 0.6890\n",
            "Epoch 5/75\n",
            "216/216 - 1s - loss: 0.5823 - auc_2: 0.6951 - accuracy: 0.6894\n",
            "Epoch 6/75\n",
            "216/216 - 1s - loss: 0.5817 - auc_2: 0.6960 - accuracy: 0.6896\n",
            "Epoch 7/75\n",
            "216/216 - 1s - loss: 0.5811 - auc_2: 0.6969 - accuracy: 0.6900\n",
            "Epoch 8/75\n",
            "216/216 - 1s - loss: 0.5808 - auc_2: 0.6974 - accuracy: 0.6904\n",
            "Epoch 9/75\n",
            "216/216 - 1s - loss: 0.5803 - auc_2: 0.6982 - accuracy: 0.6909\n",
            "Epoch 10/75\n",
            "216/216 - 1s - loss: 0.5800 - auc_2: 0.6987 - accuracy: 0.6911\n",
            "Epoch 11/75\n",
            "216/216 - 1s - loss: 0.5797 - auc_2: 0.6990 - accuracy: 0.6914\n",
            "Epoch 12/75\n",
            "216/216 - 1s - loss: 0.5794 - auc_2: 0.6995 - accuracy: 0.6919\n",
            "Epoch 13/75\n",
            "216/216 - 1s - loss: 0.5793 - auc_2: 0.6997 - accuracy: 0.6920\n",
            "Epoch 14/75\n",
            "216/216 - 1s - loss: 0.5790 - auc_2: 0.7002 - accuracy: 0.6924\n",
            "Epoch 15/75\n",
            "216/216 - 1s - loss: 0.5788 - auc_2: 0.7006 - accuracy: 0.6923\n",
            "Epoch 16/75\n",
            "216/216 - 1s - loss: 0.5786 - auc_2: 0.7007 - accuracy: 0.6923\n",
            "Epoch 17/75\n",
            "216/216 - 1s - loss: 0.5784 - auc_2: 0.7011 - accuracy: 0.6924\n",
            "Epoch 18/75\n",
            "216/216 - 1s - loss: 0.5782 - auc_2: 0.7014 - accuracy: 0.6925\n",
            "Epoch 19/75\n",
            "216/216 - 1s - loss: 0.5781 - auc_2: 0.7016 - accuracy: 0.6928\n",
            "Epoch 20/75\n",
            "216/216 - 1s - loss: 0.5780 - auc_2: 0.7018 - accuracy: 0.6926\n",
            "Epoch 21/75\n",
            "216/216 - 1s - loss: 0.5777 - auc_2: 0.7022 - accuracy: 0.6930\n",
            "Epoch 22/75\n",
            "216/216 - 1s - loss: 0.5776 - auc_2: 0.7024 - accuracy: 0.6927\n",
            "Epoch 23/75\n",
            "216/216 - 1s - loss: 0.5774 - auc_2: 0.7027 - accuracy: 0.6933\n",
            "Epoch 24/75\n",
            "216/216 - 1s - loss: 0.5773 - auc_2: 0.7028 - accuracy: 0.6925\n",
            "Epoch 25/75\n",
            "216/216 - 1s - loss: 0.5771 - auc_2: 0.7032 - accuracy: 0.6935\n",
            "Epoch 26/75\n",
            "216/216 - 1s - loss: 0.5771 - auc_2: 0.7033 - accuracy: 0.6934\n",
            "Epoch 27/75\n",
            "216/216 - 1s - loss: 0.5767 - auc_2: 0.7037 - accuracy: 0.6938\n",
            "Epoch 28/75\n",
            "216/216 - 1s - loss: 0.5768 - auc_2: 0.7037 - accuracy: 0.6937\n",
            "Epoch 29/75\n",
            "216/216 - 1s - loss: 0.5765 - auc_2: 0.7041 - accuracy: 0.6937\n",
            "Epoch 30/75\n",
            "216/216 - 1s - loss: 0.5765 - auc_2: 0.7042 - accuracy: 0.6939\n",
            "Epoch 31/75\n",
            "216/216 - 1s - loss: 0.5764 - auc_2: 0.7044 - accuracy: 0.6944\n",
            "Epoch 32/75\n",
            "216/216 - 1s - loss: 0.5762 - auc_2: 0.7046 - accuracy: 0.6941\n",
            "Epoch 33/75\n",
            "216/216 - 1s - loss: 0.5761 - auc_2: 0.7047 - accuracy: 0.6939\n",
            "Epoch 34/75\n",
            "216/216 - 1s - loss: 0.5760 - auc_2: 0.7050 - accuracy: 0.6942\n",
            "Epoch 35/75\n",
            "216/216 - 1s - loss: 0.5759 - auc_2: 0.7051 - accuracy: 0.6944\n",
            "Epoch 36/75\n",
            "216/216 - 1s - loss: 0.5759 - auc_2: 0.7052 - accuracy: 0.6944\n",
            "Epoch 37/75\n",
            "216/216 - 1s - loss: 0.5757 - auc_2: 0.7055 - accuracy: 0.6945\n",
            "Epoch 38/75\n",
            "216/216 - 1s - loss: 0.5756 - auc_2: 0.7056 - accuracy: 0.6945\n",
            "Epoch 39/75\n",
            "216/216 - 1s - loss: 0.5755 - auc_2: 0.7059 - accuracy: 0.6948\n",
            "Epoch 40/75\n",
            "216/216 - 1s - loss: 0.5754 - auc_2: 0.7060 - accuracy: 0.6948\n",
            "Epoch 41/75\n",
            "216/216 - 1s - loss: 0.5753 - auc_2: 0.7061 - accuracy: 0.6949\n",
            "Epoch 42/75\n",
            "216/216 - 1s - loss: 0.5752 - auc_2: 0.7062 - accuracy: 0.6947\n",
            "Epoch 43/75\n",
            "216/216 - 1s - loss: 0.5751 - auc_2: 0.7063 - accuracy: 0.6952\n",
            "Epoch 44/75\n",
            "216/216 - 1s - loss: 0.5750 - auc_2: 0.7067 - accuracy: 0.6951\n",
            "Epoch 45/75\n",
            "216/216 - 1s - loss: 0.5749 - auc_2: 0.7068 - accuracy: 0.6953\n",
            "Epoch 46/75\n",
            "216/216 - 1s - loss: 0.5750 - auc_2: 0.7066 - accuracy: 0.6949\n",
            "Epoch 47/75\n",
            "216/216 - 1s - loss: 0.5748 - auc_2: 0.7069 - accuracy: 0.6952\n",
            "Epoch 48/75\n",
            "216/216 - 1s - loss: 0.5747 - auc_2: 0.7071 - accuracy: 0.6955\n",
            "Epoch 49/75\n",
            "216/216 - 1s - loss: 0.5745 - auc_2: 0.7074 - accuracy: 0.6953\n",
            "Epoch 50/75\n",
            "216/216 - 1s - loss: 0.5745 - auc_2: 0.7074 - accuracy: 0.6953\n",
            "Epoch 51/75\n",
            "216/216 - 1s - loss: 0.5744 - auc_2: 0.7075 - accuracy: 0.6953\n",
            "Epoch 52/75\n",
            "216/216 - 1s - loss: 0.5744 - auc_2: 0.7076 - accuracy: 0.6959\n",
            "Epoch 53/75\n",
            "216/216 - 1s - loss: 0.5743 - auc_2: 0.7078 - accuracy: 0.6962\n",
            "Epoch 54/75\n",
            "216/216 - 1s - loss: 0.5741 - auc_2: 0.7080 - accuracy: 0.6961\n",
            "Epoch 55/75\n",
            "216/216 - 1s - loss: 0.5741 - auc_2: 0.7080 - accuracy: 0.6959\n",
            "Epoch 56/75\n",
            "216/216 - 1s - loss: 0.5741 - auc_2: 0.7081 - accuracy: 0.6957\n",
            "Epoch 57/75\n",
            "216/216 - 1s - loss: 0.5740 - auc_2: 0.7081 - accuracy: 0.6961\n",
            "Epoch 58/75\n",
            "216/216 - 1s - loss: 0.5739 - auc_2: 0.7084 - accuracy: 0.6960\n",
            "Epoch 59/75\n",
            "216/216 - 1s - loss: 0.5738 - auc_2: 0.7085 - accuracy: 0.6961\n",
            "Epoch 60/75\n",
            "216/216 - 1s - loss: 0.5738 - auc_2: 0.7086 - accuracy: 0.6964\n",
            "Epoch 61/75\n",
            "216/216 - 1s - loss: 0.5737 - auc_2: 0.7085 - accuracy: 0.6966\n",
            "Epoch 62/75\n",
            "216/216 - 1s - loss: 0.5736 - auc_2: 0.7088 - accuracy: 0.6965\n",
            "Epoch 63/75\n",
            "216/216 - 1s - loss: 0.5736 - auc_2: 0.7087 - accuracy: 0.6962\n",
            "Epoch 64/75\n",
            "216/216 - 1s - loss: 0.5735 - auc_2: 0.7090 - accuracy: 0.6968\n",
            "Epoch 65/75\n",
            "216/216 - 1s - loss: 0.5734 - auc_2: 0.7091 - accuracy: 0.6963\n",
            "Epoch 66/75\n",
            "216/216 - 1s - loss: 0.5734 - auc_2: 0.7092 - accuracy: 0.6970\n",
            "Epoch 67/75\n",
            "216/216 - 1s - loss: 0.5733 - auc_2: 0.7092 - accuracy: 0.6967\n",
            "Epoch 68/75\n",
            "216/216 - 1s - loss: 0.5733 - auc_2: 0.7093 - accuracy: 0.6969\n",
            "Epoch 69/75\n",
            "216/216 - 1s - loss: 0.5732 - auc_2: 0.7095 - accuracy: 0.6969\n",
            "Epoch 70/75\n",
            "216/216 - 1s - loss: 0.5732 - auc_2: 0.7095 - accuracy: 0.6967\n",
            "Epoch 71/75\n",
            "216/216 - 1s - loss: 0.5731 - auc_2: 0.7095 - accuracy: 0.6970\n",
            "Epoch 72/75\n",
            "216/216 - 1s - loss: 0.5730 - auc_2: 0.7097 - accuracy: 0.6970\n",
            "Epoch 73/75\n",
            "216/216 - 1s - loss: 0.5730 - auc_2: 0.7097 - accuracy: 0.6970\n",
            "Epoch 74/75\n",
            "216/216 - 1s - loss: 0.5730 - auc_2: 0.7097 - accuracy: 0.6973\n",
            "Epoch 75/75\n",
            "216/216 - 1s - loss: 0.5728 - auc_2: 0.7100 - accuracy: 0.6976\n",
            "235/235 - 0s\n",
            "235/235 - 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "216/216 - 1s - loss: 0.5940 - auc_2: 0.6934 - accuracy: 0.6796\n",
            "Epoch 2/75\n",
            "216/216 - 1s - loss: 0.5840 - auc_2: 0.6924 - accuracy: 0.6891\n",
            "Epoch 3/75\n",
            "216/216 - 1s - loss: 0.5828 - auc_2: 0.6943 - accuracy: 0.6897\n",
            "Epoch 4/75\n",
            "216/216 - 1s - loss: 0.5819 - auc_2: 0.6958 - accuracy: 0.6897\n",
            "Epoch 5/75\n",
            "216/216 - 1s - loss: 0.5812 - auc_2: 0.6969 - accuracy: 0.6904\n",
            "Epoch 6/75\n",
            "216/216 - 1s - loss: 0.5806 - auc_2: 0.6978 - accuracy: 0.6912\n",
            "Epoch 7/75\n",
            "216/216 - 1s - loss: 0.5802 - auc_2: 0.6985 - accuracy: 0.6912\n",
            "Epoch 8/75\n",
            "216/216 - 1s - loss: 0.5797 - auc_2: 0.6993 - accuracy: 0.6913\n",
            "Epoch 9/75\n",
            "216/216 - 1s - loss: 0.5793 - auc_2: 0.6999 - accuracy: 0.6918\n",
            "Epoch 10/75\n",
            "216/216 - 1s - loss: 0.5789 - auc_2: 0.7006 - accuracy: 0.6921\n",
            "Epoch 11/75\n",
            "216/216 - 1s - loss: 0.5787 - auc_2: 0.7009 - accuracy: 0.6921\n",
            "Epoch 12/75\n",
            "216/216 - 1s - loss: 0.5784 - auc_2: 0.7014 - accuracy: 0.6926\n",
            "Epoch 13/75\n",
            "216/216 - 1s - loss: 0.5781 - auc_2: 0.7019 - accuracy: 0.6933\n",
            "Epoch 14/75\n",
            "216/216 - 1s - loss: 0.5779 - auc_2: 0.7023 - accuracy: 0.6935\n",
            "Epoch 15/75\n",
            "216/216 - 1s - loss: 0.5777 - auc_2: 0.7026 - accuracy: 0.6933\n",
            "Epoch 16/75\n",
            "216/216 - 1s - loss: 0.5774 - auc_2: 0.7030 - accuracy: 0.6939\n",
            "Epoch 17/75\n",
            "216/216 - 1s - loss: 0.5773 - auc_2: 0.7031 - accuracy: 0.6930\n",
            "Epoch 18/75\n",
            "216/216 - 1s - loss: 0.5770 - auc_2: 0.7036 - accuracy: 0.6939\n",
            "Epoch 19/75\n",
            "216/216 - 1s - loss: 0.5769 - auc_2: 0.7037 - accuracy: 0.6935\n",
            "Epoch 20/75\n",
            "216/216 - 1s - loss: 0.5767 - auc_2: 0.7040 - accuracy: 0.6946\n",
            "Epoch 21/75\n",
            "216/216 - 1s - loss: 0.5765 - auc_2: 0.7044 - accuracy: 0.6941\n",
            "Epoch 22/75\n",
            "216/216 - 1s - loss: 0.5764 - auc_2: 0.7045 - accuracy: 0.6947\n",
            "Epoch 23/75\n",
            "216/216 - 1s - loss: 0.5762 - auc_2: 0.7048 - accuracy: 0.6948\n",
            "Epoch 24/75\n",
            "216/216 - 1s - loss: 0.5761 - auc_2: 0.7050 - accuracy: 0.6944\n",
            "Epoch 25/75\n",
            "216/216 - 1s - loss: 0.5760 - auc_2: 0.7052 - accuracy: 0.6953\n",
            "Epoch 26/75\n",
            "216/216 - 1s - loss: 0.5758 - auc_2: 0.7054 - accuracy: 0.6950\n",
            "Epoch 27/75\n",
            "216/216 - 1s - loss: 0.5757 - auc_2: 0.7055 - accuracy: 0.6954\n",
            "Epoch 28/75\n",
            "216/216 - 1s - loss: 0.5755 - auc_2: 0.7057 - accuracy: 0.6957\n",
            "Epoch 29/75\n",
            "216/216 - 1s - loss: 0.5754 - auc_2: 0.7060 - accuracy: 0.6954\n",
            "Epoch 30/75\n",
            "216/216 - 1s - loss: 0.5753 - auc_2: 0.7061 - accuracy: 0.6948\n",
            "Epoch 31/75\n",
            "216/216 - 1s - loss: 0.5752 - auc_2: 0.7065 - accuracy: 0.6954\n",
            "Epoch 32/75\n",
            "216/216 - 1s - loss: 0.5751 - auc_2: 0.7065 - accuracy: 0.6961\n",
            "Epoch 33/75\n",
            "216/216 - 1s - loss: 0.5750 - auc_2: 0.7067 - accuracy: 0.6953\n",
            "Epoch 34/75\n",
            "216/216 - 1s - loss: 0.5749 - auc_2: 0.7068 - accuracy: 0.6956\n",
            "Epoch 35/75\n",
            "216/216 - 1s - loss: 0.5748 - auc_2: 0.7069 - accuracy: 0.6957\n",
            "Epoch 36/75\n",
            "216/216 - 1s - loss: 0.5747 - auc_2: 0.7070 - accuracy: 0.6959\n",
            "Epoch 37/75\n",
            "216/216 - 1s - loss: 0.5745 - auc_2: 0.7075 - accuracy: 0.6963\n",
            "Epoch 38/75\n",
            "216/216 - 1s - loss: 0.5743 - auc_2: 0.7076 - accuracy: 0.6958\n",
            "Epoch 39/75\n",
            "216/216 - 1s - loss: 0.5744 - auc_2: 0.7076 - accuracy: 0.6964\n",
            "Epoch 40/75\n",
            "216/216 - 1s - loss: 0.5741 - auc_2: 0.7079 - accuracy: 0.6958\n",
            "Epoch 41/75\n",
            "216/216 - 1s - loss: 0.5741 - auc_2: 0.7079 - accuracy: 0.6962\n",
            "Epoch 42/75\n",
            "216/216 - 1s - loss: 0.5740 - auc_2: 0.7081 - accuracy: 0.6961\n",
            "Epoch 43/75\n",
            "216/216 - 1s - loss: 0.5740 - auc_2: 0.7081 - accuracy: 0.6962\n",
            "Epoch 44/75\n",
            "216/216 - 1s - loss: 0.5739 - auc_2: 0.7083 - accuracy: 0.6962\n",
            "Epoch 45/75\n",
            "216/216 - 1s - loss: 0.5739 - auc_2: 0.7084 - accuracy: 0.6967\n",
            "Epoch 46/75\n",
            "216/216 - 1s - loss: 0.5737 - auc_2: 0.7086 - accuracy: 0.6972\n",
            "Epoch 47/75\n",
            "216/216 - 1s - loss: 0.5736 - auc_2: 0.7087 - accuracy: 0.6972\n",
            "Epoch 48/75\n",
            "216/216 - 1s - loss: 0.5736 - auc_2: 0.7088 - accuracy: 0.6973\n",
            "Epoch 49/75\n",
            "216/216 - 1s - loss: 0.5735 - auc_2: 0.7089 - accuracy: 0.6966\n",
            "Epoch 50/75\n",
            "216/216 - 1s - loss: 0.5733 - auc_2: 0.7092 - accuracy: 0.6971\n",
            "Epoch 51/75\n",
            "216/216 - 1s - loss: 0.5734 - auc_2: 0.7090 - accuracy: 0.6968\n",
            "Epoch 52/75\n",
            "216/216 - 1s - loss: 0.5732 - auc_2: 0.7094 - accuracy: 0.6973\n",
            "Epoch 53/75\n",
            "216/216 - 1s - loss: 0.5732 - auc_2: 0.7094 - accuracy: 0.6973\n",
            "Epoch 54/75\n",
            "216/216 - 1s - loss: 0.5730 - auc_2: 0.7096 - accuracy: 0.6971\n",
            "Epoch 55/75\n",
            "216/216 - 1s - loss: 0.5730 - auc_2: 0.7097 - accuracy: 0.6973\n",
            "Epoch 56/75\n",
            "216/216 - 1s - loss: 0.5729 - auc_2: 0.7098 - accuracy: 0.6969\n",
            "Epoch 57/75\n",
            "216/216 - 1s - loss: 0.5728 - auc_2: 0.7098 - accuracy: 0.6973\n",
            "Epoch 58/75\n",
            "216/216 - 1s - loss: 0.5727 - auc_2: 0.7101 - accuracy: 0.6970\n",
            "Epoch 59/75\n",
            "216/216 - 1s - loss: 0.5727 - auc_2: 0.7100 - accuracy: 0.6978\n",
            "Epoch 60/75\n",
            "216/216 - 1s - loss: 0.5726 - auc_2: 0.7101 - accuracy: 0.6975\n",
            "Epoch 61/75\n",
            "216/216 - 1s - loss: 0.5726 - auc_2: 0.7103 - accuracy: 0.6982\n",
            "Epoch 62/75\n",
            "216/216 - 1s - loss: 0.5725 - auc_2: 0.7103 - accuracy: 0.6978\n",
            "Epoch 63/75\n",
            "216/216 - 1s - loss: 0.5725 - auc_2: 0.7104 - accuracy: 0.6984\n",
            "Epoch 64/75\n",
            "216/216 - 1s - loss: 0.5725 - auc_2: 0.7104 - accuracy: 0.6981\n",
            "Epoch 65/75\n",
            "216/216 - 1s - loss: 0.5723 - auc_2: 0.7106 - accuracy: 0.6981\n",
            "Epoch 66/75\n",
            "216/216 - 1s - loss: 0.5723 - auc_2: 0.7107 - accuracy: 0.6978\n",
            "Epoch 67/75\n",
            "216/216 - 1s - loss: 0.5722 - auc_2: 0.7109 - accuracy: 0.6975\n",
            "Epoch 68/75\n",
            "216/216 - 1s - loss: 0.5722 - auc_2: 0.7107 - accuracy: 0.6974\n",
            "Epoch 69/75\n",
            "216/216 - 1s - loss: 0.5720 - auc_2: 0.7110 - accuracy: 0.6981\n",
            "Epoch 70/75\n",
            "216/216 - 1s - loss: 0.5720 - auc_2: 0.7111 - accuracy: 0.6978\n",
            "Epoch 71/75\n",
            "216/216 - 1s - loss: 0.5720 - auc_2: 0.7111 - accuracy: 0.6982\n",
            "Epoch 72/75\n",
            "216/216 - 1s - loss: 0.5719 - auc_2: 0.7113 - accuracy: 0.6980\n",
            "Epoch 73/75\n",
            "216/216 - 1s - loss: 0.5719 - auc_2: 0.7113 - accuracy: 0.6979\n",
            "Epoch 74/75\n",
            "216/216 - 1s - loss: 0.5718 - auc_2: 0.7114 - accuracy: 0.6981\n",
            "Epoch 75/75\n",
            "216/216 - 1s - loss: 0.5717 - auc_2: 0.7116 - accuracy: 0.6988\n",
            "235/235 - 0s\n",
            "235/235 - 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "216/216 - 1s - loss: 0.5921 - auc_2: 0.6956 - accuracy: 0.6810\n",
            "Epoch 2/75\n",
            "216/216 - 1s - loss: 0.5851 - auc_2: 0.6909 - accuracy: 0.6873\n",
            "Epoch 3/75\n",
            "216/216 - 1s - loss: 0.5838 - auc_2: 0.6929 - accuracy: 0.6883\n",
            "Epoch 4/75\n",
            "216/216 - 1s - loss: 0.5828 - auc_2: 0.6944 - accuracy: 0.6890\n",
            "Epoch 5/75\n",
            "216/216 - 1s - loss: 0.5821 - auc_2: 0.6956 - accuracy: 0.6893\n",
            "Epoch 6/75\n",
            "216/216 - 1s - loss: 0.5816 - auc_2: 0.6964 - accuracy: 0.6902\n",
            "Epoch 7/75\n",
            "216/216 - 1s - loss: 0.5811 - auc_2: 0.6972 - accuracy: 0.6901\n",
            "Epoch 8/75\n",
            "216/216 - 1s - loss: 0.5807 - auc_2: 0.6978 - accuracy: 0.6905\n",
            "Epoch 9/75\n",
            "216/216 - 1s - loss: 0.5803 - auc_2: 0.6984 - accuracy: 0.6906\n",
            "Epoch 10/75\n",
            "216/216 - 1s - loss: 0.5800 - auc_2: 0.6989 - accuracy: 0.6917\n",
            "Epoch 11/75\n",
            "216/216 - 1s - loss: 0.5796 - auc_2: 0.6995 - accuracy: 0.6912\n",
            "Epoch 12/75\n",
            "216/216 - 1s - loss: 0.5793 - auc_2: 0.7000 - accuracy: 0.6915\n",
            "Epoch 13/75\n",
            "216/216 - 1s - loss: 0.5791 - auc_2: 0.7003 - accuracy: 0.6918\n",
            "Epoch 14/75\n",
            "216/216 - 1s - loss: 0.5790 - auc_2: 0.7004 - accuracy: 0.6916\n",
            "Epoch 15/75\n",
            "216/216 - 1s - loss: 0.5786 - auc_2: 0.7011 - accuracy: 0.6917\n",
            "Epoch 16/75\n",
            "216/216 - 1s - loss: 0.5786 - auc_2: 0.7011 - accuracy: 0.6920\n",
            "Epoch 17/75\n",
            "216/216 - 1s - loss: 0.5784 - auc_2: 0.7014 - accuracy: 0.6923\n",
            "Epoch 18/75\n",
            "216/216 - 1s - loss: 0.5782 - auc_2: 0.7017 - accuracy: 0.6926\n",
            "Epoch 19/75\n",
            "216/216 - 1s - loss: 0.5780 - auc_2: 0.7020 - accuracy: 0.6929\n",
            "Epoch 20/75\n",
            "216/216 - 1s - loss: 0.5779 - auc_2: 0.7021 - accuracy: 0.6924\n",
            "Epoch 21/75\n",
            "216/216 - 1s - loss: 0.5776 - auc_2: 0.7026 - accuracy: 0.6931\n",
            "Epoch 22/75\n",
            "216/216 - 1s - loss: 0.5777 - auc_2: 0.7026 - accuracy: 0.6935\n",
            "Epoch 23/75\n",
            "216/216 - 1s - loss: 0.5774 - auc_2: 0.7029 - accuracy: 0.6929\n",
            "Epoch 24/75\n",
            "216/216 - 1s - loss: 0.5773 - auc_2: 0.7031 - accuracy: 0.6930\n",
            "Epoch 25/75\n",
            "216/216 - 1s - loss: 0.5772 - auc_2: 0.7034 - accuracy: 0.6935\n",
            "Epoch 26/75\n",
            "216/216 - 1s - loss: 0.5771 - auc_2: 0.7036 - accuracy: 0.6933\n",
            "Epoch 27/75\n",
            "216/216 - 1s - loss: 0.5769 - auc_2: 0.7038 - accuracy: 0.6937\n",
            "Epoch 28/75\n",
            "216/216 - 1s - loss: 0.5768 - auc_2: 0.7039 - accuracy: 0.6935\n",
            "Epoch 29/75\n",
            "216/216 - 1s - loss: 0.5767 - auc_2: 0.7040 - accuracy: 0.6935\n",
            "Epoch 30/75\n",
            "216/216 - 1s - loss: 0.5766 - auc_2: 0.7042 - accuracy: 0.6939\n",
            "Epoch 31/75\n",
            "216/216 - 1s - loss: 0.5765 - auc_2: 0.7045 - accuracy: 0.6942\n",
            "Epoch 32/75\n",
            "216/216 - 1s - loss: 0.5763 - auc_2: 0.7048 - accuracy: 0.6940\n",
            "Epoch 33/75\n",
            "216/216 - 1s - loss: 0.5763 - auc_2: 0.7049 - accuracy: 0.6943\n",
            "Epoch 34/75\n",
            "216/216 - 1s - loss: 0.5762 - auc_2: 0.7049 - accuracy: 0.6944\n",
            "Epoch 35/75\n",
            "216/216 - 1s - loss: 0.5760 - auc_2: 0.7052 - accuracy: 0.6942\n",
            "Epoch 36/75\n",
            "216/216 - 1s - loss: 0.5759 - auc_2: 0.7054 - accuracy: 0.6944\n",
            "Epoch 37/75\n",
            "216/216 - 1s - loss: 0.5759 - auc_2: 0.7055 - accuracy: 0.6947\n",
            "Epoch 38/75\n",
            "216/216 - 1s - loss: 0.5757 - auc_2: 0.7057 - accuracy: 0.6946\n",
            "Epoch 39/75\n",
            "216/216 - 1s - loss: 0.5756 - auc_2: 0.7058 - accuracy: 0.6943\n",
            "Epoch 40/75\n",
            "216/216 - 1s - loss: 0.5757 - auc_2: 0.7058 - accuracy: 0.6945\n",
            "Epoch 41/75\n",
            "216/216 - 1s - loss: 0.5755 - auc_2: 0.7060 - accuracy: 0.6950\n",
            "Epoch 42/75\n",
            "216/216 - 1s - loss: 0.5754 - auc_2: 0.7061 - accuracy: 0.6944\n",
            "Epoch 43/75\n",
            "216/216 - 1s - loss: 0.5753 - auc_2: 0.7064 - accuracy: 0.6952\n",
            "Epoch 44/75\n",
            "216/216 - 1s - loss: 0.5752 - auc_2: 0.7065 - accuracy: 0.6952\n",
            "Epoch 45/75\n",
            "216/216 - 1s - loss: 0.5752 - auc_2: 0.7066 - accuracy: 0.6954\n",
            "Epoch 46/75\n",
            "216/216 - 1s - loss: 0.5750 - auc_2: 0.7068 - accuracy: 0.6954\n",
            "Epoch 47/75\n",
            "216/216 - 1s - loss: 0.5750 - auc_2: 0.7069 - accuracy: 0.6955\n",
            "Epoch 48/75\n",
            "216/216 - 1s - loss: 0.5749 - auc_2: 0.7069 - accuracy: 0.6954\n",
            "Epoch 49/75\n",
            "216/216 - 1s - loss: 0.5748 - auc_2: 0.7072 - accuracy: 0.6957\n",
            "Epoch 50/75\n",
            "216/216 - 1s - loss: 0.5747 - auc_2: 0.7072 - accuracy: 0.6955\n",
            "Epoch 51/75\n",
            "216/216 - 1s - loss: 0.5747 - auc_2: 0.7073 - accuracy: 0.6958\n",
            "Epoch 52/75\n",
            "216/216 - 1s - loss: 0.5745 - auc_2: 0.7075 - accuracy: 0.6955\n",
            "Epoch 53/75\n",
            "216/216 - 1s - loss: 0.5745 - auc_2: 0.7076 - accuracy: 0.6957\n",
            "Epoch 54/75\n",
            "216/216 - 1s - loss: 0.5745 - auc_2: 0.7075 - accuracy: 0.6958\n",
            "Epoch 55/75\n",
            "216/216 - 1s - loss: 0.5744 - auc_2: 0.7077 - accuracy: 0.6956\n",
            "Epoch 56/75\n",
            "216/216 - 1s - loss: 0.5743 - auc_2: 0.7079 - accuracy: 0.6959\n",
            "Epoch 57/75\n",
            "216/216 - 1s - loss: 0.5743 - auc_2: 0.7078 - accuracy: 0.6959\n",
            "Epoch 58/75\n",
            "216/216 - 1s - loss: 0.5742 - auc_2: 0.7080 - accuracy: 0.6959\n",
            "Epoch 59/75\n",
            "216/216 - 1s - loss: 0.5741 - auc_2: 0.7081 - accuracy: 0.6962\n",
            "Epoch 60/75\n",
            "216/216 - 1s - loss: 0.5741 - auc_2: 0.7081 - accuracy: 0.6958\n",
            "Epoch 61/75\n",
            "216/216 - 1s - loss: 0.5739 - auc_2: 0.7085 - accuracy: 0.6966\n",
            "Epoch 62/75\n",
            "216/216 - 1s - loss: 0.5739 - auc_2: 0.7084 - accuracy: 0.6966\n",
            "Epoch 63/75\n",
            "216/216 - 1s - loss: 0.5739 - auc_2: 0.7086 - accuracy: 0.6968\n",
            "Epoch 64/75\n",
            "216/216 - 1s - loss: 0.5737 - auc_2: 0.7088 - accuracy: 0.6963\n",
            "Epoch 65/75\n",
            "216/216 - 1s - loss: 0.5736 - auc_2: 0.7089 - accuracy: 0.6967\n",
            "Epoch 66/75\n",
            "216/216 - 1s - loss: 0.5737 - auc_2: 0.7088 - accuracy: 0.6963\n",
            "Epoch 67/75\n",
            "216/216 - 1s - loss: 0.5736 - auc_2: 0.7089 - accuracy: 0.6962\n",
            "Epoch 68/75\n",
            "216/216 - 1s - loss: 0.5736 - auc_2: 0.7090 - accuracy: 0.6966\n",
            "Epoch 69/75\n",
            "216/216 - 1s - loss: 0.5734 - auc_2: 0.7092 - accuracy: 0.6968\n",
            "Epoch 70/75\n",
            "216/216 - 1s - loss: 0.5734 - auc_2: 0.7092 - accuracy: 0.6969\n",
            "Epoch 71/75\n",
            "216/216 - 1s - loss: 0.5734 - auc_2: 0.7092 - accuracy: 0.6966\n",
            "Epoch 72/75\n",
            "216/216 - 1s - loss: 0.5733 - auc_2: 0.7094 - accuracy: 0.6968\n",
            "Epoch 73/75\n",
            "216/216 - 1s - loss: 0.5732 - auc_2: 0.7095 - accuracy: 0.6964\n",
            "Epoch 74/75\n",
            "216/216 - 1s - loss: 0.5731 - auc_2: 0.7096 - accuracy: 0.6972\n",
            "Epoch 75/75\n",
            "216/216 - 1s - loss: 0.5731 - auc_2: 0.7098 - accuracy: 0.6974\n",
            "235/235 - 0s\n",
            "235/235 - 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "192/192 - 1s - loss: 0.6142 - auc_2: 0.6968 - accuracy: 0.6577\n",
            "Epoch 2/75\n",
            "192/192 - 1s - loss: 0.6077 - auc_2: 0.6897 - accuracy: 0.6627\n",
            "Epoch 3/75\n",
            "192/192 - 1s - loss: 0.6065 - auc_2: 0.6915 - accuracy: 0.6640\n",
            "Epoch 4/75\n",
            "192/192 - 1s - loss: 0.6056 - auc_2: 0.6929 - accuracy: 0.6654\n",
            "Epoch 5/75\n",
            "192/192 - 1s - loss: 0.6049 - auc_2: 0.6941 - accuracy: 0.6652\n",
            "Epoch 6/75\n",
            "192/192 - 1s - loss: 0.6043 - auc_2: 0.6947 - accuracy: 0.6660\n",
            "Epoch 7/75\n",
            "192/192 - 1s - loss: 0.6038 - auc_2: 0.6956 - accuracy: 0.6667\n",
            "Epoch 8/75\n",
            "192/192 - 1s - loss: 0.6033 - auc_2: 0.6963 - accuracy: 0.6667\n",
            "Epoch 9/75\n",
            "192/192 - 1s - loss: 0.6029 - auc_2: 0.6969 - accuracy: 0.6679\n",
            "Epoch 10/75\n",
            "192/192 - 1s - loss: 0.6025 - auc_2: 0.6976 - accuracy: 0.6682\n",
            "Epoch 11/75\n",
            "192/192 - 1s - loss: 0.6022 - auc_2: 0.6981 - accuracy: 0.6680\n",
            "Epoch 12/75\n",
            "192/192 - 1s - loss: 0.6018 - auc_2: 0.6985 - accuracy: 0.6686\n",
            "Epoch 13/75\n",
            "192/192 - 1s - loss: 0.6014 - auc_2: 0.6991 - accuracy: 0.6694\n",
            "Epoch 14/75\n",
            "192/192 - 1s - loss: 0.6012 - auc_2: 0.6996 - accuracy: 0.6690\n",
            "Epoch 15/75\n",
            "192/192 - 1s - loss: 0.6010 - auc_2: 0.6999 - accuracy: 0.6695\n",
            "Epoch 16/75\n",
            "192/192 - 1s - loss: 0.6007 - auc_2: 0.7002 - accuracy: 0.6695\n",
            "Epoch 17/75\n",
            "192/192 - 1s - loss: 0.6005 - auc_2: 0.7005 - accuracy: 0.6692\n",
            "Epoch 18/75\n",
            "192/192 - 1s - loss: 0.6003 - auc_2: 0.7008 - accuracy: 0.6695\n",
            "Epoch 19/75\n",
            "192/192 - 1s - loss: 0.6001 - auc_2: 0.7012 - accuracy: 0.6696\n",
            "Epoch 20/75\n",
            "192/192 - 1s - loss: 0.5999 - auc_2: 0.7015 - accuracy: 0.6705\n",
            "Epoch 21/75\n",
            "192/192 - 1s - loss: 0.5997 - auc_2: 0.7018 - accuracy: 0.6705\n",
            "Epoch 22/75\n",
            "192/192 - 1s - loss: 0.5995 - auc_2: 0.7021 - accuracy: 0.6708\n",
            "Epoch 23/75\n",
            "192/192 - 1s - loss: 0.5995 - auc_2: 0.7022 - accuracy: 0.6707\n",
            "Epoch 24/75\n",
            "192/192 - 1s - loss: 0.5992 - auc_2: 0.7026 - accuracy: 0.6713\n",
            "Epoch 25/75\n",
            "192/192 - 1s - loss: 0.5991 - auc_2: 0.7027 - accuracy: 0.6707\n",
            "Epoch 26/75\n",
            "192/192 - 1s - loss: 0.5989 - auc_2: 0.7031 - accuracy: 0.6717\n",
            "Epoch 27/75\n",
            "192/192 - 1s - loss: 0.5988 - auc_2: 0.7033 - accuracy: 0.6709\n",
            "Epoch 28/75\n",
            "192/192 - 1s - loss: 0.5986 - auc_2: 0.7035 - accuracy: 0.6719\n",
            "Epoch 29/75\n",
            "192/192 - 1s - loss: 0.5985 - auc_2: 0.7036 - accuracy: 0.6716\n",
            "Epoch 30/75\n",
            "192/192 - 1s - loss: 0.5984 - auc_2: 0.7039 - accuracy: 0.6719\n",
            "Epoch 31/75\n",
            "192/192 - 1s - loss: 0.5982 - auc_2: 0.7041 - accuracy: 0.6715\n",
            "Epoch 32/75\n",
            "192/192 - 1s - loss: 0.5981 - auc_2: 0.7044 - accuracy: 0.6723\n",
            "Epoch 33/75\n",
            "192/192 - 1s - loss: 0.5979 - auc_2: 0.7045 - accuracy: 0.6718\n",
            "Epoch 34/75\n",
            "192/192 - 1s - loss: 0.5979 - auc_2: 0.7046 - accuracy: 0.6722\n",
            "Epoch 35/75\n",
            "192/192 - 1s - loss: 0.5977 - auc_2: 0.7050 - accuracy: 0.6725\n",
            "Epoch 36/75\n",
            "192/192 - 1s - loss: 0.5977 - auc_2: 0.7050 - accuracy: 0.6726\n",
            "Epoch 37/75\n",
            "192/192 - 1s - loss: 0.5975 - auc_2: 0.7052 - accuracy: 0.6724\n",
            "Epoch 38/75\n",
            "192/192 - 1s - loss: 0.5974 - auc_2: 0.7054 - accuracy: 0.6727\n",
            "Epoch 39/75\n",
            "192/192 - 1s - loss: 0.5973 - auc_2: 0.7054 - accuracy: 0.6728\n",
            "Epoch 40/75\n",
            "192/192 - 1s - loss: 0.5973 - auc_2: 0.7057 - accuracy: 0.6728\n",
            "Epoch 41/75\n",
            "192/192 - 1s - loss: 0.5971 - auc_2: 0.7059 - accuracy: 0.6731\n",
            "Epoch 42/75\n",
            "192/192 - 1s - loss: 0.5971 - auc_2: 0.7058 - accuracy: 0.6726\n",
            "Epoch 43/75\n",
            "192/192 - 1s - loss: 0.5969 - auc_2: 0.7062 - accuracy: 0.6728\n",
            "Epoch 44/75\n",
            "192/192 - 1s - loss: 0.5969 - auc_2: 0.7062 - accuracy: 0.6734\n",
            "Epoch 45/75\n",
            "192/192 - 1s - loss: 0.5967 - auc_2: 0.7064 - accuracy: 0.6733\n",
            "Epoch 46/75\n",
            "192/192 - 1s - loss: 0.5967 - auc_2: 0.7065 - accuracy: 0.6735\n",
            "Epoch 47/75\n",
            "192/192 - 1s - loss: 0.5966 - auc_2: 0.7065 - accuracy: 0.6735\n",
            "Epoch 48/75\n",
            "192/192 - 1s - loss: 0.5965 - auc_2: 0.7067 - accuracy: 0.6735\n",
            "Epoch 49/75\n",
            "192/192 - 1s - loss: 0.5964 - auc_2: 0.7069 - accuracy: 0.6735\n",
            "Epoch 50/75\n",
            "192/192 - 1s - loss: 0.5964 - auc_2: 0.7070 - accuracy: 0.6735\n",
            "Epoch 51/75\n",
            "192/192 - 1s - loss: 0.5962 - auc_2: 0.7072 - accuracy: 0.6736\n",
            "Epoch 52/75\n",
            "192/192 - 1s - loss: 0.5962 - auc_2: 0.7072 - accuracy: 0.6741\n",
            "Epoch 53/75\n",
            "192/192 - 1s - loss: 0.5962 - auc_2: 0.7072 - accuracy: 0.6736\n",
            "Epoch 54/75\n",
            "192/192 - 1s - loss: 0.5961 - auc_2: 0.7075 - accuracy: 0.6737\n",
            "Epoch 55/75\n",
            "192/192 - 1s - loss: 0.5960 - auc_2: 0.7075 - accuracy: 0.6741\n",
            "Epoch 56/75\n",
            "192/192 - 1s - loss: 0.5959 - auc_2: 0.7076 - accuracy: 0.6739\n",
            "Epoch 57/75\n",
            "192/192 - 1s - loss: 0.5958 - auc_2: 0.7079 - accuracy: 0.6736\n",
            "Epoch 58/75\n",
            "192/192 - 1s - loss: 0.5958 - auc_2: 0.7079 - accuracy: 0.6740\n",
            "Epoch 59/75\n",
            "192/192 - 1s - loss: 0.5957 - auc_2: 0.7080 - accuracy: 0.6741\n",
            "Epoch 60/75\n",
            "192/192 - 1s - loss: 0.5957 - auc_2: 0.7080 - accuracy: 0.6745\n",
            "Epoch 61/75\n",
            "192/192 - 1s - loss: 0.5956 - auc_2: 0.7082 - accuracy: 0.6740\n",
            "Epoch 62/75\n",
            "192/192 - 1s - loss: 0.5955 - auc_2: 0.7082 - accuracy: 0.6743\n",
            "Epoch 63/75\n",
            "192/192 - 1s - loss: 0.5954 - auc_2: 0.7085 - accuracy: 0.6744\n",
            "Epoch 64/75\n",
            "192/192 - 1s - loss: 0.5954 - auc_2: 0.7084 - accuracy: 0.6748\n",
            "Epoch 65/75\n",
            "192/192 - 1s - loss: 0.5953 - auc_2: 0.7085 - accuracy: 0.6744\n",
            "Epoch 66/75\n",
            "192/192 - 1s - loss: 0.5952 - auc_2: 0.7086 - accuracy: 0.6747\n",
            "Epoch 67/75\n",
            "192/192 - 1s - loss: 0.5951 - auc_2: 0.7088 - accuracy: 0.6746\n",
            "Epoch 68/75\n",
            "192/192 - 1s - loss: 0.5952 - auc_2: 0.7088 - accuracy: 0.6746\n",
            "Epoch 69/75\n",
            "192/192 - 1s - loss: 0.5950 - auc_2: 0.7090 - accuracy: 0.6751\n",
            "Epoch 70/75\n",
            "192/192 - 1s - loss: 0.5949 - auc_2: 0.7091 - accuracy: 0.6751\n",
            "Epoch 71/75\n",
            "192/192 - 1s - loss: 0.5949 - auc_2: 0.7091 - accuracy: 0.6753\n",
            "Epoch 72/75\n",
            "192/192 - 1s - loss: 0.5949 - auc_2: 0.7093 - accuracy: 0.6756\n",
            "Epoch 73/75\n",
            "192/192 - 1s - loss: 0.5948 - auc_2: 0.7094 - accuracy: 0.6758\n",
            "Epoch 74/75\n",
            "192/192 - 1s - loss: 0.5947 - auc_2: 0.7094 - accuracy: 0.6752\n",
            "Epoch 75/75\n",
            "192/192 - 1s - loss: 0.5947 - auc_2: 0.7095 - accuracy: 0.6756\n",
            "235/235 - 0s\n",
            "235/235 - 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "192/192 - 1s - loss: 0.6139 - auc_2: 0.6945 - accuracy: 0.6564\n",
            "Epoch 2/75\n",
            "192/192 - 1s - loss: 0.6058 - auc_2: 0.6929 - accuracy: 0.6652\n",
            "Epoch 3/75\n",
            "192/192 - 1s - loss: 0.6048 - auc_2: 0.6945 - accuracy: 0.6664\n",
            "Epoch 4/75\n",
            "192/192 - 1s - loss: 0.6040 - auc_2: 0.6955 - accuracy: 0.6671\n",
            "Epoch 5/75\n",
            "192/192 - 1s - loss: 0.6034 - auc_2: 0.6965 - accuracy: 0.6675\n",
            "Epoch 6/75\n",
            "192/192 - 1s - loss: 0.6028 - auc_2: 0.6974 - accuracy: 0.6681\n",
            "Epoch 7/75\n",
            "192/192 - 1s - loss: 0.6024 - auc_2: 0.6979 - accuracy: 0.6683\n",
            "Epoch 8/75\n",
            "192/192 - 1s - loss: 0.6020 - auc_2: 0.6986 - accuracy: 0.6691\n",
            "Epoch 9/75\n",
            "192/192 - 1s - loss: 0.6016 - auc_2: 0.6993 - accuracy: 0.6691\n",
            "Epoch 10/75\n",
            "192/192 - 1s - loss: 0.6013 - auc_2: 0.6997 - accuracy: 0.6696\n",
            "Epoch 11/75\n",
            "192/192 - 1s - loss: 0.6009 - auc_2: 0.7003 - accuracy: 0.6704\n",
            "Epoch 12/75\n",
            "192/192 - 1s - loss: 0.6006 - auc_2: 0.7007 - accuracy: 0.6703\n",
            "Epoch 13/75\n",
            "192/192 - 1s - loss: 0.6003 - auc_2: 0.7012 - accuracy: 0.6705\n",
            "Epoch 14/75\n",
            "192/192 - 1s - loss: 0.6000 - auc_2: 0.7017 - accuracy: 0.6709\n",
            "Epoch 15/75\n",
            "192/192 - 1s - loss: 0.5997 - auc_2: 0.7021 - accuracy: 0.6710\n",
            "Epoch 16/75\n",
            "192/192 - 1s - loss: 0.5995 - auc_2: 0.7024 - accuracy: 0.6708\n",
            "Epoch 17/75\n",
            "192/192 - 1s - loss: 0.5993 - auc_2: 0.7027 - accuracy: 0.6719\n",
            "Epoch 18/75\n",
            "192/192 - 1s - loss: 0.5990 - auc_2: 0.7032 - accuracy: 0.6720\n",
            "Epoch 19/75\n",
            "192/192 - 1s - loss: 0.5988 - auc_2: 0.7035 - accuracy: 0.6715\n",
            "Epoch 20/75\n",
            "192/192 - 1s - loss: 0.5986 - auc_2: 0.7038 - accuracy: 0.6724\n",
            "Epoch 21/75\n",
            "192/192 - 1s - loss: 0.5985 - auc_2: 0.7039 - accuracy: 0.6717\n",
            "Epoch 22/75\n",
            "192/192 - 1s - loss: 0.5982 - auc_2: 0.7044 - accuracy: 0.6724\n",
            "Epoch 23/75\n",
            "192/192 - 1s - loss: 0.5982 - auc_2: 0.7043 - accuracy: 0.6726\n",
            "Epoch 24/75\n",
            "192/192 - 1s - loss: 0.5980 - auc_2: 0.7047 - accuracy: 0.6727\n",
            "Epoch 25/75\n",
            "192/192 - 1s - loss: 0.5978 - auc_2: 0.7050 - accuracy: 0.6727\n",
            "Epoch 26/75\n",
            "192/192 - 1s - loss: 0.5977 - auc_2: 0.7050 - accuracy: 0.6727\n",
            "Epoch 27/75\n",
            "192/192 - 1s - loss: 0.5976 - auc_2: 0.7052 - accuracy: 0.6730\n",
            "Epoch 28/75\n",
            "192/192 - 1s - loss: 0.5974 - auc_2: 0.7056 - accuracy: 0.6732\n",
            "Epoch 29/75\n",
            "192/192 - 1s - loss: 0.5971 - auc_2: 0.7059 - accuracy: 0.6737\n",
            "Epoch 30/75\n",
            "192/192 - 1s - loss: 0.5971 - auc_2: 0.7060 - accuracy: 0.6730\n",
            "Epoch 31/75\n",
            "192/192 - 1s - loss: 0.5971 - auc_2: 0.7061 - accuracy: 0.6739\n",
            "Epoch 32/75\n",
            "192/192 - 1s - loss: 0.5969 - auc_2: 0.7063 - accuracy: 0.6736\n",
            "Epoch 33/75\n",
            "192/192 - 1s - loss: 0.5968 - auc_2: 0.7064 - accuracy: 0.6741\n",
            "Epoch 34/75\n",
            "192/192 - 1s - loss: 0.5967 - auc_2: 0.7066 - accuracy: 0.6742\n",
            "Epoch 35/75\n",
            "192/192 - 1s - loss: 0.5966 - auc_2: 0.7067 - accuracy: 0.6739\n",
            "Epoch 36/75\n",
            "192/192 - 1s - loss: 0.5964 - auc_2: 0.7070 - accuracy: 0.6743\n",
            "Epoch 37/75\n",
            "192/192 - 1s - loss: 0.5963 - auc_2: 0.7071 - accuracy: 0.6745\n",
            "Epoch 38/75\n",
            "192/192 - 1s - loss: 0.5962 - auc_2: 0.7073 - accuracy: 0.6742\n",
            "Epoch 39/75\n",
            "192/192 - 1s - loss: 0.5962 - auc_2: 0.7073 - accuracy: 0.6742\n",
            "Epoch 40/75\n",
            "192/192 - 1s - loss: 0.5960 - auc_2: 0.7076 - accuracy: 0.6746\n",
            "Epoch 41/75\n",
            "192/192 - 1s - loss: 0.5960 - auc_2: 0.7076 - accuracy: 0.6745\n",
            "Epoch 42/75\n",
            "192/192 - 1s - loss: 0.5959 - auc_2: 0.7077 - accuracy: 0.6744\n",
            "Epoch 43/75\n",
            "192/192 - 1s - loss: 0.5958 - auc_2: 0.7079 - accuracy: 0.6749\n",
            "Epoch 44/75\n",
            "192/192 - 1s - loss: 0.5957 - auc_2: 0.7081 - accuracy: 0.6748\n",
            "Epoch 45/75\n",
            "192/192 - 1s - loss: 0.5956 - auc_2: 0.7082 - accuracy: 0.6749\n",
            "Epoch 46/75\n",
            "192/192 - 1s - loss: 0.5954 - auc_2: 0.7084 - accuracy: 0.6752\n",
            "Epoch 47/75\n",
            "192/192 - 1s - loss: 0.5954 - auc_2: 0.7085 - accuracy: 0.6746\n",
            "Epoch 48/75\n",
            "192/192 - 1s - loss: 0.5953 - auc_2: 0.7086 - accuracy: 0.6752\n",
            "Epoch 49/75\n",
            "192/192 - 1s - loss: 0.5952 - auc_2: 0.7088 - accuracy: 0.6753\n",
            "Epoch 50/75\n",
            "192/192 - 1s - loss: 0.5952 - auc_2: 0.7088 - accuracy: 0.6750\n",
            "Epoch 51/75\n",
            "192/192 - 1s - loss: 0.5950 - auc_2: 0.7090 - accuracy: 0.6750\n",
            "Epoch 52/75\n",
            "192/192 - 1s - loss: 0.5950 - auc_2: 0.7090 - accuracy: 0.6754\n",
            "Epoch 53/75\n",
            "192/192 - 1s - loss: 0.5950 - auc_2: 0.7092 - accuracy: 0.6750\n",
            "Epoch 54/75\n",
            "192/192 - 1s - loss: 0.5947 - auc_2: 0.7095 - accuracy: 0.6754\n",
            "Epoch 55/75\n",
            "192/192 - 1s - loss: 0.5947 - auc_2: 0.7096 - accuracy: 0.6757\n",
            "Epoch 56/75\n",
            "192/192 - 1s - loss: 0.5946 - auc_2: 0.7096 - accuracy: 0.6756\n",
            "Epoch 57/75\n",
            "192/192 - 1s - loss: 0.5945 - auc_2: 0.7098 - accuracy: 0.6756\n",
            "Epoch 58/75\n",
            "192/192 - 1s - loss: 0.5945 - auc_2: 0.7098 - accuracy: 0.6755\n",
            "Epoch 59/75\n",
            "192/192 - 1s - loss: 0.5943 - auc_2: 0.7100 - accuracy: 0.6758\n",
            "Epoch 60/75\n",
            "192/192 - 1s - loss: 0.5943 - auc_2: 0.7101 - accuracy: 0.6757\n",
            "Epoch 61/75\n",
            "192/192 - 1s - loss: 0.5942 - auc_2: 0.7102 - accuracy: 0.6754\n",
            "Epoch 62/75\n",
            "192/192 - 1s - loss: 0.5941 - auc_2: 0.7104 - accuracy: 0.6761\n",
            "Epoch 63/75\n",
            "192/192 - 1s - loss: 0.5941 - auc_2: 0.7104 - accuracy: 0.6757\n",
            "Epoch 64/75\n",
            "192/192 - 1s - loss: 0.5940 - auc_2: 0.7106 - accuracy: 0.6763\n",
            "Epoch 65/75\n",
            "192/192 - 1s - loss: 0.5939 - auc_2: 0.7107 - accuracy: 0.6766\n",
            "Epoch 66/75\n",
            "192/192 - 1s - loss: 0.5939 - auc_2: 0.7106 - accuracy: 0.6766\n",
            "Epoch 67/75\n",
            "192/192 - 1s - loss: 0.5938 - auc_2: 0.7107 - accuracy: 0.6764\n",
            "Epoch 68/75\n",
            "192/192 - 1s - loss: 0.5937 - auc_2: 0.7109 - accuracy: 0.6763\n",
            "Epoch 69/75\n",
            "192/192 - 1s - loss: 0.5937 - auc_2: 0.7110 - accuracy: 0.6765\n",
            "Epoch 70/75\n",
            "192/192 - 1s - loss: 0.5936 - auc_2: 0.7111 - accuracy: 0.6764\n",
            "Epoch 71/75\n",
            "192/192 - 1s - loss: 0.5935 - auc_2: 0.7113 - accuracy: 0.6762\n",
            "Epoch 72/75\n",
            "192/192 - 1s - loss: 0.5934 - auc_2: 0.7113 - accuracy: 0.6764\n",
            "Epoch 73/75\n",
            "192/192 - 1s - loss: 0.5934 - auc_2: 0.7114 - accuracy: 0.6766\n",
            "Epoch 74/75\n",
            "192/192 - 1s - loss: 0.5933 - auc_2: 0.7115 - accuracy: 0.6768\n",
            "Epoch 75/75\n",
            "192/192 - 1s - loss: 0.5932 - auc_2: 0.7116 - accuracy: 0.6769\n",
            "235/235 - 0s\n",
            "235/235 - 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "192/192 - 1s - loss: 0.6134 - auc_2: 0.6961 - accuracy: 0.6585\n",
            "Epoch 2/75\n",
            "192/192 - 1s - loss: 0.6068 - auc_2: 0.6914 - accuracy: 0.6644\n",
            "Epoch 3/75\n",
            "192/192 - 1s - loss: 0.6058 - auc_2: 0.6929 - accuracy: 0.6651\n",
            "Epoch 4/75\n",
            "192/192 - 1s - loss: 0.6052 - auc_2: 0.6939 - accuracy: 0.6661\n",
            "Epoch 5/75\n",
            "192/192 - 1s - loss: 0.6046 - auc_2: 0.6947 - accuracy: 0.6663\n",
            "Epoch 6/75\n",
            "192/192 - 1s - loss: 0.6041 - auc_2: 0.6955 - accuracy: 0.6666\n",
            "Epoch 7/75\n",
            "192/192 - 1s - loss: 0.6036 - auc_2: 0.6962 - accuracy: 0.6677\n",
            "Epoch 8/75\n",
            "192/192 - 1s - loss: 0.6032 - auc_2: 0.6968 - accuracy: 0.6675\n",
            "Epoch 9/75\n",
            "192/192 - 1s - loss: 0.6028 - auc_2: 0.6975 - accuracy: 0.6680\n",
            "Epoch 10/75\n",
            "192/192 - 1s - loss: 0.6024 - auc_2: 0.6979 - accuracy: 0.6680\n",
            "Epoch 11/75\n",
            "192/192 - 1s - loss: 0.6021 - auc_2: 0.6986 - accuracy: 0.6691\n",
            "Epoch 12/75\n",
            "192/192 - 1s - loss: 0.6017 - auc_2: 0.6991 - accuracy: 0.6686\n",
            "Epoch 13/75\n",
            "192/192 - 1s - loss: 0.6014 - auc_2: 0.6996 - accuracy: 0.6690\n",
            "Epoch 14/75\n",
            "192/192 - 1s - loss: 0.6011 - auc_2: 0.7000 - accuracy: 0.6695\n",
            "Epoch 15/75\n",
            "192/192 - 1s - loss: 0.6009 - auc_2: 0.7003 - accuracy: 0.6696\n",
            "Epoch 16/75\n",
            "192/192 - 1s - loss: 0.6006 - auc_2: 0.7007 - accuracy: 0.6700\n",
            "Epoch 17/75\n",
            "192/192 - 1s - loss: 0.6003 - auc_2: 0.7012 - accuracy: 0.6701\n",
            "Epoch 18/75\n",
            "192/192 - 1s - loss: 0.6000 - auc_2: 0.7016 - accuracy: 0.6707\n",
            "Epoch 19/75\n",
            "192/192 - 1s - loss: 0.5998 - auc_2: 0.7019 - accuracy: 0.6707\n",
            "Epoch 20/75\n",
            "192/192 - 1s - loss: 0.5997 - auc_2: 0.7020 - accuracy: 0.6700\n",
            "Epoch 21/75\n",
            "192/192 - 1s - loss: 0.5994 - auc_2: 0.7025 - accuracy: 0.6710\n",
            "Epoch 22/75\n",
            "192/192 - 1s - loss: 0.5993 - auc_2: 0.7025 - accuracy: 0.6710\n",
            "Epoch 23/75\n",
            "192/192 - 1s - loss: 0.5991 - auc_2: 0.7029 - accuracy: 0.6712\n",
            "Epoch 24/75\n",
            "192/192 - 1s - loss: 0.5990 - auc_2: 0.7030 - accuracy: 0.6709\n",
            "Epoch 25/75\n",
            "192/192 - 1s - loss: 0.5988 - auc_2: 0.7035 - accuracy: 0.6716\n",
            "Epoch 26/75\n",
            "192/192 - 1s - loss: 0.5987 - auc_2: 0.7035 - accuracy: 0.6712\n",
            "Epoch 27/75\n",
            "192/192 - 1s - loss: 0.5984 - auc_2: 0.7039 - accuracy: 0.6718\n",
            "Epoch 28/75\n",
            "192/192 - 1s - loss: 0.5983 - auc_2: 0.7041 - accuracy: 0.6715\n",
            "Epoch 29/75\n",
            "192/192 - 1s - loss: 0.5983 - auc_2: 0.7042 - accuracy: 0.6717\n",
            "Epoch 30/75\n",
            "192/192 - 1s - loss: 0.5981 - auc_2: 0.7045 - accuracy: 0.6723\n",
            "Epoch 31/75\n",
            "192/192 - 1s - loss: 0.5980 - auc_2: 0.7046 - accuracy: 0.6723\n",
            "Epoch 32/75\n",
            "192/192 - 1s - loss: 0.5978 - auc_2: 0.7047 - accuracy: 0.6720\n",
            "Epoch 33/75\n",
            "192/192 - 1s - loss: 0.5977 - auc_2: 0.7050 - accuracy: 0.6721\n",
            "Epoch 34/75\n",
            "192/192 - 1s - loss: 0.5976 - auc_2: 0.7052 - accuracy: 0.6725\n",
            "Epoch 35/75\n",
            "192/192 - 1s - loss: 0.5975 - auc_2: 0.7054 - accuracy: 0.6728\n",
            "Epoch 36/75\n",
            "192/192 - 1s - loss: 0.5973 - auc_2: 0.7056 - accuracy: 0.6729\n",
            "Epoch 37/75\n",
            "192/192 - 1s - loss: 0.5972 - auc_2: 0.7057 - accuracy: 0.6724\n",
            "Epoch 38/75\n",
            "192/192 - 1s - loss: 0.5971 - auc_2: 0.7059 - accuracy: 0.6729\n",
            "Epoch 39/75\n",
            "192/192 - 1s - loss: 0.5971 - auc_2: 0.7059 - accuracy: 0.6729\n",
            "Epoch 40/75\n",
            "192/192 - 1s - loss: 0.5970 - auc_2: 0.7060 - accuracy: 0.6730\n",
            "Epoch 41/75\n",
            "192/192 - 1s - loss: 0.5969 - auc_2: 0.7062 - accuracy: 0.6738\n",
            "Epoch 42/75\n",
            "192/192 - 1s - loss: 0.5968 - auc_2: 0.7064 - accuracy: 0.6734\n",
            "Epoch 43/75\n",
            "192/192 - 1s - loss: 0.5967 - auc_2: 0.7064 - accuracy: 0.6729\n",
            "Epoch 44/75\n",
            "192/192 - 1s - loss: 0.5966 - auc_2: 0.7066 - accuracy: 0.6733\n",
            "Epoch 45/75\n",
            "192/192 - 1s - loss: 0.5964 - auc_2: 0.7069 - accuracy: 0.6736\n",
            "Epoch 46/75\n",
            "192/192 - 1s - loss: 0.5964 - auc_2: 0.7069 - accuracy: 0.6730\n",
            "Epoch 47/75\n",
            "192/192 - 1s - loss: 0.5963 - auc_2: 0.7071 - accuracy: 0.6733\n",
            "Epoch 48/75\n",
            "192/192 - 1s - loss: 0.5962 - auc_2: 0.7072 - accuracy: 0.6738\n",
            "Epoch 49/75\n",
            "192/192 - 1s - loss: 0.5962 - auc_2: 0.7072 - accuracy: 0.6739\n",
            "Epoch 50/75\n",
            "192/192 - 1s - loss: 0.5961 - auc_2: 0.7075 - accuracy: 0.6738\n",
            "Epoch 51/75\n",
            "192/192 - 1s - loss: 0.5960 - auc_2: 0.7075 - accuracy: 0.6741\n",
            "Epoch 52/75\n",
            "192/192 - 1s - loss: 0.5959 - auc_2: 0.7078 - accuracy: 0.6747\n",
            "Epoch 53/75\n",
            "192/192 - 1s - loss: 0.5958 - auc_2: 0.7079 - accuracy: 0.6743\n",
            "Epoch 54/75\n",
            "192/192 - 1s - loss: 0.5958 - auc_2: 0.7079 - accuracy: 0.6744\n",
            "Epoch 55/75\n",
            "192/192 - 1s - loss: 0.5958 - auc_2: 0.7079 - accuracy: 0.6747\n",
            "Epoch 56/75\n",
            "192/192 - 1s - loss: 0.5956 - auc_2: 0.7082 - accuracy: 0.6744\n",
            "Epoch 57/75\n",
            "192/192 - 1s - loss: 0.5954 - auc_2: 0.7084 - accuracy: 0.6747\n",
            "Epoch 58/75\n",
            "192/192 - 1s - loss: 0.5954 - auc_2: 0.7084 - accuracy: 0.6749\n",
            "Epoch 59/75\n",
            "192/192 - 1s - loss: 0.5953 - auc_2: 0.7085 - accuracy: 0.6750\n",
            "Epoch 60/75\n",
            "192/192 - 1s - loss: 0.5953 - auc_2: 0.7086 - accuracy: 0.6747\n",
            "Epoch 61/75\n",
            "192/192 - 1s - loss: 0.5952 - auc_2: 0.7086 - accuracy: 0.6749\n",
            "Epoch 62/75\n",
            "192/192 - 1s - loss: 0.5952 - auc_2: 0.7087 - accuracy: 0.6752\n",
            "Epoch 63/75\n",
            "192/192 - 1s - loss: 0.5951 - auc_2: 0.7089 - accuracy: 0.6752\n",
            "Epoch 64/75\n",
            "192/192 - 1s - loss: 0.5950 - auc_2: 0.7090 - accuracy: 0.6748\n",
            "Epoch 65/75\n",
            "192/192 - 1s - loss: 0.5949 - auc_2: 0.7092 - accuracy: 0.6752\n",
            "Epoch 66/75\n",
            "192/192 - 1s - loss: 0.5949 - auc_2: 0.7091 - accuracy: 0.6749\n",
            "Epoch 67/75\n",
            "192/192 - 1s - loss: 0.5948 - auc_2: 0.7092 - accuracy: 0.6756\n",
            "Epoch 68/75\n",
            "192/192 - 1s - loss: 0.5948 - auc_2: 0.7093 - accuracy: 0.6746\n",
            "Epoch 69/75\n",
            "192/192 - 1s - loss: 0.5947 - auc_2: 0.7095 - accuracy: 0.6756\n",
            "Epoch 70/75\n",
            "192/192 - 1s - loss: 0.5946 - auc_2: 0.7096 - accuracy: 0.6756\n",
            "Epoch 71/75\n",
            "192/192 - 1s - loss: 0.5945 - auc_2: 0.7097 - accuracy: 0.6757\n",
            "Epoch 72/75\n",
            "192/192 - 1s - loss: 0.5945 - auc_2: 0.7098 - accuracy: 0.6752\n",
            "Epoch 73/75\n",
            "192/192 - 1s - loss: 0.5944 - auc_2: 0.7099 - accuracy: 0.6757\n",
            "Epoch 74/75\n",
            "192/192 - 1s - loss: 0.5943 - auc_2: 0.7100 - accuracy: 0.6756\n",
            "Epoch 75/75\n",
            "192/192 - 1s - loss: 0.5943 - auc_2: 0.7100 - accuracy: 0.6759\n",
            "235/235 - 0s\n",
            "235/235 - 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "175/175 - 1s - loss: 0.6315 - auc_2: 0.6939 - accuracy: 0.6374\n",
            "Epoch 2/75\n",
            "175/175 - 1s - loss: 0.6214 - auc_2: 0.6901 - accuracy: 0.6484\n",
            "Epoch 3/75\n",
            "175/175 - 1s - loss: 0.6203 - auc_2: 0.6917 - accuracy: 0.6493\n",
            "Epoch 4/75\n",
            "175/175 - 1s - loss: 0.6195 - auc_2: 0.6929 - accuracy: 0.6506\n",
            "Epoch 5/75\n",
            "175/175 - 1s - loss: 0.6188 - auc_2: 0.6940 - accuracy: 0.6511\n",
            "Epoch 6/75\n",
            "175/175 - 1s - loss: 0.6182 - auc_2: 0.6947 - accuracy: 0.6519\n",
            "Epoch 7/75\n",
            "175/175 - 1s - loss: 0.6176 - auc_2: 0.6956 - accuracy: 0.6524\n",
            "Epoch 8/75\n",
            "175/175 - 1s - loss: 0.6170 - auc_2: 0.6965 - accuracy: 0.6531\n",
            "Epoch 9/75\n",
            "175/175 - 1s - loss: 0.6167 - auc_2: 0.6969 - accuracy: 0.6527\n",
            "Epoch 10/75\n",
            "175/175 - 1s - loss: 0.6162 - auc_2: 0.6977 - accuracy: 0.6539\n",
            "Epoch 11/75\n",
            "175/175 - 1s - loss: 0.6158 - auc_2: 0.6983 - accuracy: 0.6549\n",
            "Epoch 12/75\n",
            "175/175 - 1s - loss: 0.6156 - auc_2: 0.6986 - accuracy: 0.6548\n",
            "Epoch 13/75\n",
            "175/175 - 1s - loss: 0.6153 - auc_2: 0.6991 - accuracy: 0.6553\n",
            "Epoch 14/75\n",
            "175/175 - 1s - loss: 0.6149 - auc_2: 0.6997 - accuracy: 0.6559\n",
            "Epoch 15/75\n",
            "175/175 - 1s - loss: 0.6147 - auc_2: 0.6999 - accuracy: 0.6563\n",
            "Epoch 16/75\n",
            "175/175 - 1s - loss: 0.6144 - auc_2: 0.7004 - accuracy: 0.6564\n",
            "Epoch 17/75\n",
            "175/175 - 1s - loss: 0.6141 - auc_2: 0.7007 - accuracy: 0.6558\n",
            "Epoch 18/75\n",
            "175/175 - 1s - loss: 0.6140 - auc_2: 0.7009 - accuracy: 0.6565\n",
            "Epoch 19/75\n",
            "175/175 - 1s - loss: 0.6138 - auc_2: 0.7014 - accuracy: 0.6568\n",
            "Epoch 20/75\n",
            "175/175 - 1s - loss: 0.6135 - auc_2: 0.7016 - accuracy: 0.6576\n",
            "Epoch 21/75\n",
            "175/175 - 1s - loss: 0.6134 - auc_2: 0.7018 - accuracy: 0.6569\n",
            "Epoch 22/75\n",
            "175/175 - 1s - loss: 0.6133 - auc_2: 0.7020 - accuracy: 0.6569\n",
            "Epoch 23/75\n",
            "175/175 - 1s - loss: 0.6132 - auc_2: 0.7021 - accuracy: 0.6568\n",
            "Epoch 24/75\n",
            "175/175 - 1s - loss: 0.6128 - auc_2: 0.7027 - accuracy: 0.6581\n",
            "Epoch 25/75\n",
            "175/175 - 1s - loss: 0.6127 - auc_2: 0.7028 - accuracy: 0.6573\n",
            "Epoch 26/75\n",
            "175/175 - 1s - loss: 0.6126 - auc_2: 0.7030 - accuracy: 0.6577\n",
            "Epoch 27/75\n",
            "175/175 - 1s - loss: 0.6125 - auc_2: 0.7031 - accuracy: 0.6573\n",
            "Epoch 28/75\n",
            "175/175 - 1s - loss: 0.6123 - auc_2: 0.7034 - accuracy: 0.6575\n",
            "Epoch 29/75\n",
            "175/175 - 1s - loss: 0.6123 - auc_2: 0.7035 - accuracy: 0.6578\n",
            "Epoch 30/75\n",
            "175/175 - 1s - loss: 0.6120 - auc_2: 0.7039 - accuracy: 0.6579\n",
            "Epoch 31/75\n",
            "175/175 - 1s - loss: 0.6119 - auc_2: 0.7040 - accuracy: 0.6589\n",
            "Epoch 32/75\n",
            "175/175 - 1s - loss: 0.6118 - auc_2: 0.7042 - accuracy: 0.6582\n",
            "Epoch 33/75\n",
            "175/175 - 1s - loss: 0.6117 - auc_2: 0.7043 - accuracy: 0.6581\n",
            "Epoch 34/75\n",
            "175/175 - 1s - loss: 0.6115 - auc_2: 0.7045 - accuracy: 0.6582\n",
            "Epoch 35/75\n",
            "175/175 - 1s - loss: 0.6113 - auc_2: 0.7048 - accuracy: 0.6588\n",
            "Epoch 36/75\n",
            "175/175 - 1s - loss: 0.6113 - auc_2: 0.7048 - accuracy: 0.6581\n",
            "Epoch 37/75\n",
            "175/175 - 1s - loss: 0.6112 - auc_2: 0.7051 - accuracy: 0.6589\n",
            "Epoch 38/75\n",
            "175/175 - 1s - loss: 0.6112 - auc_2: 0.7050 - accuracy: 0.6587\n",
            "Epoch 39/75\n",
            "175/175 - 1s - loss: 0.6110 - auc_2: 0.7053 - accuracy: 0.6591\n",
            "Epoch 40/75\n",
            "175/175 - 1s - loss: 0.6109 - auc_2: 0.7054 - accuracy: 0.6585\n",
            "Epoch 41/75\n",
            "175/175 - 1s - loss: 0.6108 - auc_2: 0.7057 - accuracy: 0.6590\n",
            "Epoch 42/75\n",
            "175/175 - 1s - loss: 0.6106 - auc_2: 0.7059 - accuracy: 0.6590\n",
            "Epoch 43/75\n",
            "175/175 - 1s - loss: 0.6105 - auc_2: 0.7059 - accuracy: 0.6589\n",
            "Epoch 44/75\n",
            "175/175 - 1s - loss: 0.6105 - auc_2: 0.7060 - accuracy: 0.6589\n",
            "Epoch 45/75\n",
            "175/175 - 1s - loss: 0.6104 - auc_2: 0.7061 - accuracy: 0.6593\n",
            "Epoch 46/75\n",
            "175/175 - 1s - loss: 0.6103 - auc_2: 0.7063 - accuracy: 0.6597\n",
            "Epoch 47/75\n",
            "175/175 - 1s - loss: 0.6102 - auc_2: 0.7064 - accuracy: 0.6597\n",
            "Epoch 48/75\n",
            "175/175 - 1s - loss: 0.6100 - auc_2: 0.7067 - accuracy: 0.6605\n",
            "Epoch 49/75\n",
            "175/175 - 1s - loss: 0.6100 - auc_2: 0.7068 - accuracy: 0.6594\n",
            "Epoch 50/75\n",
            "175/175 - 1s - loss: 0.6099 - auc_2: 0.7070 - accuracy: 0.6597\n",
            "Epoch 51/75\n",
            "175/175 - 1s - loss: 0.6098 - auc_2: 0.7071 - accuracy: 0.6604\n",
            "Epoch 52/75\n",
            "175/175 - 1s - loss: 0.6096 - auc_2: 0.7071 - accuracy: 0.6596\n",
            "Epoch 53/75\n",
            "175/175 - 1s - loss: 0.6097 - auc_2: 0.7072 - accuracy: 0.6606\n",
            "Epoch 54/75\n",
            "175/175 - 1s - loss: 0.6096 - auc_2: 0.7073 - accuracy: 0.6601\n",
            "Epoch 55/75\n",
            "175/175 - 1s - loss: 0.6095 - auc_2: 0.7074 - accuracy: 0.6605\n",
            "Epoch 56/75\n",
            "175/175 - 1s - loss: 0.6094 - auc_2: 0.7076 - accuracy: 0.6604\n",
            "Epoch 57/75\n",
            "175/175 - 1s - loss: 0.6094 - auc_2: 0.7075 - accuracy: 0.6606\n",
            "Epoch 58/75\n",
            "175/175 - 1s - loss: 0.6092 - auc_2: 0.7079 - accuracy: 0.6607\n",
            "Epoch 59/75\n",
            "175/175 - 1s - loss: 0.6091 - auc_2: 0.7081 - accuracy: 0.6617\n",
            "Epoch 60/75\n",
            "175/175 - 1s - loss: 0.6091 - auc_2: 0.7079 - accuracy: 0.6608\n",
            "Epoch 61/75\n",
            "175/175 - 1s - loss: 0.6089 - auc_2: 0.7083 - accuracy: 0.6607\n",
            "Epoch 62/75\n",
            "175/175 - 1s - loss: 0.6090 - auc_2: 0.7083 - accuracy: 0.6607\n",
            "Epoch 63/75\n",
            "175/175 - 1s - loss: 0.6088 - auc_2: 0.7083 - accuracy: 0.6614\n",
            "Epoch 64/75\n",
            "175/175 - 1s - loss: 0.6087 - auc_2: 0.7085 - accuracy: 0.6605\n",
            "Epoch 65/75\n",
            "175/175 - 1s - loss: 0.6088 - auc_2: 0.7084 - accuracy: 0.6607\n",
            "Epoch 66/75\n",
            "175/175 - 1s - loss: 0.6086 - auc_2: 0.7087 - accuracy: 0.6608\n",
            "Epoch 67/75\n",
            "175/175 - 1s - loss: 0.6086 - auc_2: 0.7087 - accuracy: 0.6605\n",
            "Epoch 68/75\n",
            "175/175 - 1s - loss: 0.6085 - auc_2: 0.7089 - accuracy: 0.6611\n",
            "Epoch 69/75\n",
            "175/175 - 1s - loss: 0.6084 - auc_2: 0.7090 - accuracy: 0.6618\n",
            "Epoch 70/75\n",
            "175/175 - 1s - loss: 0.6083 - auc_2: 0.7091 - accuracy: 0.6607\n",
            "Epoch 71/75\n",
            "175/175 - 1s - loss: 0.6083 - auc_2: 0.7091 - accuracy: 0.6612\n",
            "Epoch 72/75\n",
            "175/175 - 1s - loss: 0.6082 - auc_2: 0.7091 - accuracy: 0.6609\n",
            "Epoch 73/75\n",
            "175/175 - 1s - loss: 0.6082 - auc_2: 0.7093 - accuracy: 0.6616\n",
            "Epoch 74/75\n",
            "175/175 - 1s - loss: 0.6081 - auc_2: 0.7093 - accuracy: 0.6613\n",
            "Epoch 75/75\n",
            "175/175 - 1s - loss: 0.6080 - auc_2: 0.7095 - accuracy: 0.6612\n",
            "235/235 - 0s\n",
            "235/235 - 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "175/175 - 1s - loss: 0.6284 - auc_2: 0.6944 - accuracy: 0.6414\n",
            "Epoch 2/75\n",
            "175/175 - 1s - loss: 0.6203 - auc_2: 0.6918 - accuracy: 0.6510\n",
            "Epoch 3/75\n",
            "175/175 - 1s - loss: 0.6192 - auc_2: 0.6935 - accuracy: 0.6521\n",
            "Epoch 4/75\n",
            "175/175 - 1s - loss: 0.6184 - auc_2: 0.6948 - accuracy: 0.6529\n",
            "Epoch 5/75\n",
            "175/175 - 1s - loss: 0.6177 - auc_2: 0.6958 - accuracy: 0.6537\n",
            "Epoch 6/75\n",
            "175/175 - 1s - loss: 0.6171 - auc_2: 0.6967 - accuracy: 0.6538\n",
            "Epoch 7/75\n",
            "175/175 - 1s - loss: 0.6166 - auc_2: 0.6974 - accuracy: 0.6550\n",
            "Epoch 8/75\n",
            "175/175 - 1s - loss: 0.6160 - auc_2: 0.6984 - accuracy: 0.6560\n",
            "Epoch 9/75\n",
            "175/175 - 1s - loss: 0.6156 - auc_2: 0.6989 - accuracy: 0.6558\n",
            "Epoch 10/75\n",
            "175/175 - 1s - loss: 0.6152 - auc_2: 0.6996 - accuracy: 0.6564\n",
            "Epoch 11/75\n",
            "175/175 - 1s - loss: 0.6147 - auc_2: 0.7004 - accuracy: 0.6567\n",
            "Epoch 12/75\n",
            "175/175 - 1s - loss: 0.6143 - auc_2: 0.7007 - accuracy: 0.6570\n",
            "Epoch 13/75\n",
            "175/175 - 1s - loss: 0.6140 - auc_2: 0.7013 - accuracy: 0.6569\n",
            "Epoch 14/75\n",
            "175/175 - 1s - loss: 0.6137 - auc_2: 0.7016 - accuracy: 0.6574\n",
            "Epoch 15/75\n",
            "175/175 - 1s - loss: 0.6134 - auc_2: 0.7021 - accuracy: 0.6579\n",
            "Epoch 16/75\n",
            "175/175 - 1s - loss: 0.6132 - auc_2: 0.7024 - accuracy: 0.6580\n",
            "Epoch 17/75\n",
            "175/175 - 1s - loss: 0.6128 - auc_2: 0.7030 - accuracy: 0.6582\n",
            "Epoch 18/75\n",
            "175/175 - 1s - loss: 0.6126 - auc_2: 0.7032 - accuracy: 0.6587\n",
            "Epoch 19/75\n",
            "175/175 - 1s - loss: 0.6124 - auc_2: 0.7037 - accuracy: 0.6588\n",
            "Epoch 20/75\n",
            "175/175 - 1s - loss: 0.6122 - auc_2: 0.7039 - accuracy: 0.6589\n",
            "Epoch 21/75\n",
            "175/175 - 1s - loss: 0.6121 - auc_2: 0.7041 - accuracy: 0.6588\n",
            "Epoch 22/75\n",
            "175/175 - 1s - loss: 0.6118 - auc_2: 0.7045 - accuracy: 0.6589\n",
            "Epoch 23/75\n",
            "175/175 - 1s - loss: 0.6117 - auc_2: 0.7046 - accuracy: 0.6587\n",
            "Epoch 24/75\n",
            "175/175 - 1s - loss: 0.6115 - auc_2: 0.7049 - accuracy: 0.6601\n",
            "Epoch 25/75\n",
            "175/175 - 1s - loss: 0.6113 - auc_2: 0.7052 - accuracy: 0.6596\n",
            "Epoch 26/75\n",
            "175/175 - 1s - loss: 0.6112 - auc_2: 0.7053 - accuracy: 0.6598\n",
            "Epoch 27/75\n",
            "175/175 - 1s - loss: 0.6110 - auc_2: 0.7055 - accuracy: 0.6597\n",
            "Epoch 28/75\n",
            "175/175 - 1s - loss: 0.6109 - auc_2: 0.7057 - accuracy: 0.6604\n",
            "Epoch 29/75\n",
            "175/175 - 1s - loss: 0.6107 - auc_2: 0.7061 - accuracy: 0.6600\n",
            "Epoch 30/75\n",
            "175/175 - 1s - loss: 0.6106 - auc_2: 0.7062 - accuracy: 0.6599\n",
            "Epoch 31/75\n",
            "175/175 - 1s - loss: 0.6105 - auc_2: 0.7064 - accuracy: 0.6602\n",
            "Epoch 32/75\n",
            "175/175 - 1s - loss: 0.6104 - auc_2: 0.7065 - accuracy: 0.6601\n",
            "Epoch 33/75\n",
            "175/175 - 1s - loss: 0.6103 - auc_2: 0.7066 - accuracy: 0.6603\n",
            "Epoch 34/75\n",
            "175/175 - 1s - loss: 0.6100 - auc_2: 0.7071 - accuracy: 0.6608\n",
            "Epoch 35/75\n",
            "175/175 - 1s - loss: 0.6100 - auc_2: 0.7071 - accuracy: 0.6606\n",
            "Epoch 36/75\n",
            "175/175 - 1s - loss: 0.6099 - auc_2: 0.7072 - accuracy: 0.6606\n",
            "Epoch 37/75\n",
            "175/175 - 1s - loss: 0.6098 - auc_2: 0.7073 - accuracy: 0.6601\n",
            "Epoch 38/75\n",
            "175/175 - 1s - loss: 0.6097 - auc_2: 0.7075 - accuracy: 0.6612\n",
            "Epoch 39/75\n",
            "175/175 - 1s - loss: 0.6095 - auc_2: 0.7079 - accuracy: 0.6612\n",
            "Epoch 40/75\n",
            "175/175 - 1s - loss: 0.6094 - auc_2: 0.7079 - accuracy: 0.6613\n",
            "Epoch 41/75\n",
            "175/175 - 1s - loss: 0.6093 - auc_2: 0.7080 - accuracy: 0.6612\n",
            "Epoch 42/75\n",
            "175/175 - 1s - loss: 0.6092 - auc_2: 0.7082 - accuracy: 0.6611\n",
            "Epoch 43/75\n",
            "175/175 - 1s - loss: 0.6091 - auc_2: 0.7083 - accuracy: 0.6621\n",
            "Epoch 44/75\n",
            "175/175 - 1s - loss: 0.6091 - auc_2: 0.7083 - accuracy: 0.6613\n",
            "Epoch 45/75\n",
            "175/175 - 1s - loss: 0.6089 - auc_2: 0.7085 - accuracy: 0.6619\n",
            "Epoch 46/75\n",
            "175/175 - 1s - loss: 0.6088 - auc_2: 0.7086 - accuracy: 0.6619\n",
            "Epoch 47/75\n",
            "175/175 - 1s - loss: 0.6086 - auc_2: 0.7091 - accuracy: 0.6616\n",
            "Epoch 48/75\n",
            "175/175 - 1s - loss: 0.6086 - auc_2: 0.7090 - accuracy: 0.6619\n",
            "Epoch 49/75\n",
            "175/175 - 1s - loss: 0.6084 - auc_2: 0.7092 - accuracy: 0.6623\n",
            "Epoch 50/75\n",
            "175/175 - 1s - loss: 0.6084 - auc_2: 0.7093 - accuracy: 0.6626\n",
            "Epoch 51/75\n",
            "175/175 - 1s - loss: 0.6084 - auc_2: 0.7092 - accuracy: 0.6626\n",
            "Epoch 52/75\n",
            "175/175 - 1s - loss: 0.6082 - auc_2: 0.7095 - accuracy: 0.6630\n",
            "Epoch 53/75\n",
            "175/175 - 1s - loss: 0.6081 - auc_2: 0.7097 - accuracy: 0.6621\n",
            "Epoch 54/75\n",
            "175/175 - 1s - loss: 0.6080 - auc_2: 0.7098 - accuracy: 0.6626\n",
            "Epoch 55/75\n",
            "175/175 - 1s - loss: 0.6079 - auc_2: 0.7099 - accuracy: 0.6624\n",
            "Epoch 56/75\n",
            "175/175 - 1s - loss: 0.6079 - auc_2: 0.7099 - accuracy: 0.6632\n",
            "Epoch 57/75\n",
            "175/175 - 1s - loss: 0.6077 - auc_2: 0.7102 - accuracy: 0.6629\n",
            "Epoch 58/75\n",
            "175/175 - 1s - loss: 0.6077 - auc_2: 0.7103 - accuracy: 0.6633\n",
            "Epoch 59/75\n",
            "175/175 - 1s - loss: 0.6075 - auc_2: 0.7104 - accuracy: 0.6634\n",
            "Epoch 60/75\n",
            "175/175 - 1s - loss: 0.6073 - auc_2: 0.7107 - accuracy: 0.6635\n",
            "Epoch 61/75\n",
            "175/175 - 1s - loss: 0.6074 - auc_2: 0.7105 - accuracy: 0.6631\n",
            "Epoch 62/75\n",
            "175/175 - 1s - loss: 0.6073 - auc_2: 0.7107 - accuracy: 0.6630\n",
            "Epoch 63/75\n",
            "175/175 - 1s - loss: 0.6072 - auc_2: 0.7109 - accuracy: 0.6639\n",
            "Epoch 64/75\n",
            "175/175 - 1s - loss: 0.6071 - auc_2: 0.7110 - accuracy: 0.6637\n",
            "Epoch 65/75\n",
            "175/175 - 1s - loss: 0.6070 - auc_2: 0.7110 - accuracy: 0.6634\n",
            "Epoch 66/75\n",
            "175/175 - 1s - loss: 0.6069 - auc_2: 0.7112 - accuracy: 0.6635\n",
            "Epoch 67/75\n",
            "175/175 - 1s - loss: 0.6068 - auc_2: 0.7113 - accuracy: 0.6633\n",
            "Epoch 68/75\n",
            "175/175 - 1s - loss: 0.6067 - auc_2: 0.7115 - accuracy: 0.6634\n",
            "Epoch 69/75\n",
            "175/175 - 1s - loss: 0.6067 - auc_2: 0.7116 - accuracy: 0.6641\n",
            "Epoch 70/75\n",
            "175/175 - 1s - loss: 0.6066 - auc_2: 0.7116 - accuracy: 0.6641\n",
            "Epoch 71/75\n",
            "175/175 - 1s - loss: 0.6066 - auc_2: 0.7118 - accuracy: 0.6637\n",
            "Epoch 72/75\n",
            "175/175 - 1s - loss: 0.6065 - auc_2: 0.7118 - accuracy: 0.6638\n",
            "Epoch 73/75\n",
            "175/175 - 1s - loss: 0.6064 - auc_2: 0.7118 - accuracy: 0.6644\n",
            "Epoch 74/75\n",
            "175/175 - 1s - loss: 0.6063 - auc_2: 0.7121 - accuracy: 0.6644\n",
            "Epoch 75/75\n",
            "175/175 - 1s - loss: 0.6062 - auc_2: 0.7121 - accuracy: 0.6645\n",
            "235/235 - 0s\n",
            "235/235 - 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "175/175 - 1s - loss: 0.6297 - auc_2: 0.6945 - accuracy: 0.6388\n",
            "Epoch 2/75\n",
            "175/175 - 1s - loss: 0.6214 - auc_2: 0.6903 - accuracy: 0.6488\n",
            "Epoch 3/75\n",
            "175/175 - 1s - loss: 0.6202 - auc_2: 0.6922 - accuracy: 0.6498\n",
            "Epoch 4/75\n",
            "175/175 - 1s - loss: 0.6193 - auc_2: 0.6935 - accuracy: 0.6511\n",
            "Epoch 5/75\n",
            "175/175 - 1s - loss: 0.6186 - auc_2: 0.6945 - accuracy: 0.6515\n",
            "Epoch 6/75\n",
            "175/175 - 1s - loss: 0.6180 - auc_2: 0.6954 - accuracy: 0.6527\n",
            "Epoch 7/75\n",
            "175/175 - 1s - loss: 0.6174 - auc_2: 0.6962 - accuracy: 0.6525\n",
            "Epoch 8/75\n",
            "175/175 - 1s - loss: 0.6169 - auc_2: 0.6970 - accuracy: 0.6539\n",
            "Epoch 9/75\n",
            "175/175 - 1s - loss: 0.6164 - auc_2: 0.6977 - accuracy: 0.6540\n",
            "Epoch 10/75\n",
            "175/175 - 1s - loss: 0.6160 - auc_2: 0.6982 - accuracy: 0.6541\n",
            "Epoch 11/75\n",
            "175/175 - 1s - loss: 0.6156 - auc_2: 0.6989 - accuracy: 0.6544\n",
            "Epoch 12/75\n",
            "175/175 - 1s - loss: 0.6152 - auc_2: 0.6994 - accuracy: 0.6550\n",
            "Epoch 13/75\n",
            "175/175 - 1s - loss: 0.6149 - auc_2: 0.6999 - accuracy: 0.6554\n",
            "Epoch 14/75\n",
            "175/175 - 1s - loss: 0.6146 - auc_2: 0.7003 - accuracy: 0.6556\n",
            "Epoch 15/75\n",
            "175/175 - 1s - loss: 0.6143 - auc_2: 0.7007 - accuracy: 0.6560\n",
            "Epoch 16/75\n",
            "175/175 - 1s - loss: 0.6141 - auc_2: 0.7011 - accuracy: 0.6566\n",
            "Epoch 17/75\n",
            "175/175 - 1s - loss: 0.6138 - auc_2: 0.7015 - accuracy: 0.6563\n",
            "Epoch 18/75\n",
            "175/175 - 1s - loss: 0.6137 - auc_2: 0.7016 - accuracy: 0.6568\n",
            "Epoch 19/75\n",
            "175/175 - 1s - loss: 0.6135 - auc_2: 0.7020 - accuracy: 0.6565\n",
            "Epoch 20/75\n",
            "175/175 - 1s - loss: 0.6133 - auc_2: 0.7022 - accuracy: 0.6566\n",
            "Epoch 21/75\n",
            "175/175 - 1s - loss: 0.6131 - auc_2: 0.7025 - accuracy: 0.6567\n",
            "Epoch 22/75\n",
            "175/175 - 1s - loss: 0.6129 - auc_2: 0.7028 - accuracy: 0.6573\n",
            "Epoch 23/75\n",
            "175/175 - 1s - loss: 0.6127 - auc_2: 0.7030 - accuracy: 0.6569\n",
            "Epoch 24/75\n",
            "175/175 - 1s - loss: 0.6126 - auc_2: 0.7033 - accuracy: 0.6579\n",
            "Epoch 25/75\n",
            "175/175 - 1s - loss: 0.6124 - auc_2: 0.7035 - accuracy: 0.6581\n",
            "Epoch 26/75\n",
            "175/175 - 1s - loss: 0.6123 - auc_2: 0.7038 - accuracy: 0.6578\n",
            "Epoch 27/75\n",
            "175/175 - 1s - loss: 0.6121 - auc_2: 0.7040 - accuracy: 0.6581\n",
            "Epoch 28/75\n",
            "175/175 - 1s - loss: 0.6119 - auc_2: 0.7041 - accuracy: 0.6585\n",
            "Epoch 29/75\n",
            "175/175 - 1s - loss: 0.6118 - auc_2: 0.7045 - accuracy: 0.6588\n",
            "Epoch 30/75\n",
            "175/175 - 1s - loss: 0.6117 - auc_2: 0.7045 - accuracy: 0.6585\n",
            "Epoch 31/75\n",
            "175/175 - 1s - loss: 0.6115 - auc_2: 0.7047 - accuracy: 0.6592\n",
            "Epoch 32/75\n",
            "175/175 - 1s - loss: 0.6115 - auc_2: 0.7048 - accuracy: 0.6589\n",
            "Epoch 33/75\n",
            "175/175 - 1s - loss: 0.6113 - auc_2: 0.7051 - accuracy: 0.6593\n",
            "Epoch 34/75\n",
            "175/175 - 1s - loss: 0.6112 - auc_2: 0.7053 - accuracy: 0.6587\n",
            "Epoch 35/75\n",
            "175/175 - 1s - loss: 0.6111 - auc_2: 0.7055 - accuracy: 0.6594\n",
            "Epoch 36/75\n",
            "175/175 - 1s - loss: 0.6109 - auc_2: 0.7056 - accuracy: 0.6593\n",
            "Epoch 37/75\n",
            "175/175 - 1s - loss: 0.6109 - auc_2: 0.7058 - accuracy: 0.6594\n",
            "Epoch 38/75\n",
            "175/175 - 1s - loss: 0.6107 - auc_2: 0.7059 - accuracy: 0.6594\n",
            "Epoch 39/75\n",
            "175/175 - 1s - loss: 0.6106 - auc_2: 0.7062 - accuracy: 0.6599\n",
            "Epoch 40/75\n",
            "175/175 - 1s - loss: 0.6105 - auc_2: 0.7063 - accuracy: 0.6602\n",
            "Epoch 41/75\n",
            "175/175 - 1s - loss: 0.6105 - auc_2: 0.7063 - accuracy: 0.6606\n",
            "Epoch 42/75\n",
            "175/175 - 1s - loss: 0.6103 - auc_2: 0.7065 - accuracy: 0.6602\n",
            "Epoch 43/75\n",
            "175/175 - 1s - loss: 0.6101 - auc_2: 0.7068 - accuracy: 0.6604\n",
            "Epoch 44/75\n",
            "175/175 - 1s - loss: 0.6100 - auc_2: 0.7069 - accuracy: 0.6601\n",
            "Epoch 45/75\n",
            "175/175 - 1s - loss: 0.6100 - auc_2: 0.7071 - accuracy: 0.6604\n",
            "Epoch 46/75\n",
            "175/175 - 1s - loss: 0.6099 - auc_2: 0.7071 - accuracy: 0.6604\n",
            "Epoch 47/75\n",
            "175/175 - 1s - loss: 0.6098 - auc_2: 0.7072 - accuracy: 0.6604\n",
            "Epoch 48/75\n",
            "175/175 - 1s - loss: 0.6097 - auc_2: 0.7073 - accuracy: 0.6606\n",
            "Epoch 49/75\n",
            "175/175 - 1s - loss: 0.6097 - auc_2: 0.7074 - accuracy: 0.6602\n",
            "Epoch 50/75\n",
            "175/175 - 1s - loss: 0.6095 - auc_2: 0.7077 - accuracy: 0.6612\n",
            "Epoch 51/75\n",
            "175/175 - 1s - loss: 0.6095 - auc_2: 0.7076 - accuracy: 0.6604\n",
            "Epoch 52/75\n",
            "175/175 - 1s - loss: 0.6093 - auc_2: 0.7079 - accuracy: 0.6614\n",
            "Epoch 53/75\n",
            "175/175 - 1s - loss: 0.6092 - auc_2: 0.7081 - accuracy: 0.6607\n",
            "Epoch 54/75\n",
            "175/175 - 1s - loss: 0.6092 - auc_2: 0.7082 - accuracy: 0.6613\n",
            "Epoch 55/75\n",
            "175/175 - 1s - loss: 0.6090 - auc_2: 0.7083 - accuracy: 0.6618\n",
            "Epoch 56/75\n",
            "175/175 - 1s - loss: 0.6090 - auc_2: 0.7084 - accuracy: 0.6615\n",
            "Epoch 57/75\n",
            "175/175 - 1s - loss: 0.6089 - auc_2: 0.7086 - accuracy: 0.6611\n",
            "Epoch 58/75\n",
            "175/175 - 1s - loss: 0.6088 - auc_2: 0.7086 - accuracy: 0.6615\n",
            "Epoch 59/75\n",
            "175/175 - 1s - loss: 0.6088 - auc_2: 0.7087 - accuracy: 0.6612\n",
            "Epoch 60/75\n",
            "175/175 - 1s - loss: 0.6088 - auc_2: 0.7087 - accuracy: 0.6622\n",
            "Epoch 61/75\n",
            "175/175 - 1s - loss: 0.6086 - auc_2: 0.7090 - accuracy: 0.6619\n",
            "Epoch 62/75\n",
            "175/175 - 1s - loss: 0.6086 - auc_2: 0.7091 - accuracy: 0.6620\n",
            "Epoch 63/75\n",
            "175/175 - 1s - loss: 0.6085 - auc_2: 0.7092 - accuracy: 0.6613\n",
            "Epoch 64/75\n",
            "175/175 - 1s - loss: 0.6084 - auc_2: 0.7092 - accuracy: 0.6615\n",
            "Epoch 65/75\n",
            "175/175 - 1s - loss: 0.6082 - auc_2: 0.7096 - accuracy: 0.6623\n",
            "Epoch 66/75\n",
            "175/175 - 1s - loss: 0.6081 - auc_2: 0.7096 - accuracy: 0.6622\n",
            "Epoch 67/75\n",
            "175/175 - 1s - loss: 0.6081 - auc_2: 0.7096 - accuracy: 0.6616\n",
            "Epoch 68/75\n",
            "175/175 - 1s - loss: 0.6081 - auc_2: 0.7096 - accuracy: 0.6618\n",
            "Epoch 69/75\n",
            "175/175 - 1s - loss: 0.6079 - auc_2: 0.7099 - accuracy: 0.6622\n",
            "Epoch 70/75\n",
            "175/175 - 1s - loss: 0.6080 - auc_2: 0.7098 - accuracy: 0.6619\n",
            "Epoch 71/75\n",
            "175/175 - 1s - loss: 0.6078 - auc_2: 0.7100 - accuracy: 0.6619\n",
            "Epoch 72/75\n",
            "175/175 - 1s - loss: 0.6077 - auc_2: 0.7103 - accuracy: 0.6625\n",
            "Epoch 73/75\n",
            "175/175 - 1s - loss: 0.6077 - auc_2: 0.7102 - accuracy: 0.6618\n",
            "Epoch 74/75\n",
            "175/175 - 1s - loss: 0.6076 - auc_2: 0.7104 - accuracy: 0.6624\n",
            "Epoch 75/75\n",
            "175/175 - 1s - loss: 0.6075 - auc_2: 0.7107 - accuracy: 0.6627\n",
            "235/235 - 0s\n",
            "235/235 - 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "162/162 - 1s - loss: 0.6434 - auc_2: 0.6910 - accuracy: 0.6241\n",
            "Epoch 2/75\n",
            "162/162 - 1s - loss: 0.6300 - auc_2: 0.6896 - accuracy: 0.6410\n",
            "Epoch 3/75\n",
            "162/162 - 1s - loss: 0.6291 - auc_2: 0.6909 - accuracy: 0.6411\n",
            "Epoch 4/75\n",
            "162/162 - 1s - loss: 0.6284 - auc_2: 0.6919 - accuracy: 0.6422\n",
            "Epoch 5/75\n",
            "162/162 - 1s - loss: 0.6277 - auc_2: 0.6929 - accuracy: 0.6425\n",
            "Epoch 6/75\n",
            "162/162 - 1s - loss: 0.6270 - auc_2: 0.6938 - accuracy: 0.6429\n",
            "Epoch 7/75\n",
            "162/162 - 1s - loss: 0.6265 - auc_2: 0.6946 - accuracy: 0.6437\n",
            "Epoch 8/75\n",
            "162/162 - 1s - loss: 0.6259 - auc_2: 0.6955 - accuracy: 0.6449\n",
            "Epoch 9/75\n",
            "162/162 - 1s - loss: 0.6255 - auc_2: 0.6961 - accuracy: 0.6444\n",
            "Epoch 10/75\n",
            "162/162 - 1s - loss: 0.6251 - auc_2: 0.6966 - accuracy: 0.6448\n",
            "Epoch 11/75\n",
            "162/162 - 1s - loss: 0.6246 - auc_2: 0.6975 - accuracy: 0.6457\n",
            "Epoch 12/75\n",
            "162/162 - 1s - loss: 0.6243 - auc_2: 0.6978 - accuracy: 0.6457\n",
            "Epoch 13/75\n",
            "162/162 - 1s - loss: 0.6239 - auc_2: 0.6985 - accuracy: 0.6465\n",
            "Epoch 14/75\n",
            "162/162 - 1s - loss: 0.6235 - auc_2: 0.6990 - accuracy: 0.6470\n",
            "Epoch 15/75\n",
            "162/162 - 1s - loss: 0.6233 - auc_2: 0.6992 - accuracy: 0.6466\n",
            "Epoch 16/75\n",
            "162/162 - 1s - loss: 0.6229 - auc_2: 0.6998 - accuracy: 0.6475\n",
            "Epoch 17/75\n",
            "162/162 - 1s - loss: 0.6228 - auc_2: 0.7000 - accuracy: 0.6473\n",
            "Epoch 18/75\n",
            "162/162 - 1s - loss: 0.6226 - auc_2: 0.7003 - accuracy: 0.6474\n",
            "Epoch 19/75\n",
            "162/162 - 1s - loss: 0.6223 - auc_2: 0.7007 - accuracy: 0.6476\n",
            "Epoch 20/75\n",
            "162/162 - 1s - loss: 0.6222 - auc_2: 0.7009 - accuracy: 0.6472\n",
            "Epoch 21/75\n",
            "162/162 - 1s - loss: 0.6219 - auc_2: 0.7013 - accuracy: 0.6484\n",
            "Epoch 22/75\n",
            "162/162 - 1s - loss: 0.6217 - auc_2: 0.7015 - accuracy: 0.6482\n",
            "Epoch 23/75\n",
            "162/162 - 1s - loss: 0.6215 - auc_2: 0.7019 - accuracy: 0.6488\n",
            "Epoch 24/75\n",
            "162/162 - 1s - loss: 0.6213 - auc_2: 0.7022 - accuracy: 0.6489\n",
            "Epoch 25/75\n",
            "162/162 - 1s - loss: 0.6212 - auc_2: 0.7023 - accuracy: 0.6491\n",
            "Epoch 26/75\n",
            "162/162 - 1s - loss: 0.6210 - auc_2: 0.7025 - accuracy: 0.6492\n",
            "Epoch 27/75\n",
            "162/162 - 1s - loss: 0.6208 - auc_2: 0.7028 - accuracy: 0.6496\n",
            "Epoch 28/75\n",
            "162/162 - 1s - loss: 0.6206 - auc_2: 0.7030 - accuracy: 0.6498\n",
            "Epoch 29/75\n",
            "162/162 - 1s - loss: 0.6206 - auc_2: 0.7032 - accuracy: 0.6500\n",
            "Epoch 30/75\n",
            "162/162 - 1s - loss: 0.6205 - auc_2: 0.7032 - accuracy: 0.6499\n",
            "Epoch 31/75\n",
            "162/162 - 1s - loss: 0.6203 - auc_2: 0.7035 - accuracy: 0.6503\n",
            "Epoch 32/75\n",
            "162/162 - 1s - loss: 0.6201 - auc_2: 0.7039 - accuracy: 0.6502\n",
            "Epoch 33/75\n",
            "162/162 - 1s - loss: 0.6199 - auc_2: 0.7041 - accuracy: 0.6501\n",
            "Epoch 34/75\n",
            "162/162 - 1s - loss: 0.6199 - auc_2: 0.7042 - accuracy: 0.6506\n",
            "Epoch 35/75\n",
            "162/162 - 1s - loss: 0.6198 - auc_2: 0.7043 - accuracy: 0.6512\n",
            "Epoch 36/75\n",
            "162/162 - 1s - loss: 0.6196 - auc_2: 0.7045 - accuracy: 0.6509\n",
            "Epoch 37/75\n",
            "162/162 - 1s - loss: 0.6195 - auc_2: 0.7047 - accuracy: 0.6509\n",
            "Epoch 38/75\n",
            "162/162 - 1s - loss: 0.6194 - auc_2: 0.7048 - accuracy: 0.6514\n",
            "Epoch 39/75\n",
            "162/162 - 1s - loss: 0.6193 - auc_2: 0.7050 - accuracy: 0.6515\n",
            "Epoch 40/75\n",
            "162/162 - 1s - loss: 0.6191 - auc_2: 0.7052 - accuracy: 0.6515\n",
            "Epoch 41/75\n",
            "162/162 - 1s - loss: 0.6189 - auc_2: 0.7055 - accuracy: 0.6520\n",
            "Epoch 42/75\n",
            "162/162 - 1s - loss: 0.6190 - auc_2: 0.7053 - accuracy: 0.6512\n",
            "Epoch 43/75\n",
            "162/162 - 1s - loss: 0.6189 - auc_2: 0.7055 - accuracy: 0.6517\n",
            "Epoch 44/75\n",
            "162/162 - 1s - loss: 0.6188 - auc_2: 0.7057 - accuracy: 0.6517\n",
            "Epoch 45/75\n",
            "162/162 - 1s - loss: 0.6186 - auc_2: 0.7059 - accuracy: 0.6522\n",
            "Epoch 46/75\n",
            "162/162 - 1s - loss: 0.6185 - auc_2: 0.7060 - accuracy: 0.6518\n",
            "Epoch 47/75\n",
            "162/162 - 1s - loss: 0.6185 - auc_2: 0.7061 - accuracy: 0.6517\n",
            "Epoch 48/75\n",
            "162/162 - 1s - loss: 0.6184 - auc_2: 0.7062 - accuracy: 0.6516\n",
            "Epoch 49/75\n",
            "162/162 - 1s - loss: 0.6182 - auc_2: 0.7065 - accuracy: 0.6520\n",
            "Epoch 50/75\n",
            "162/162 - 1s - loss: 0.6181 - auc_2: 0.7066 - accuracy: 0.6529\n",
            "Epoch 51/75\n",
            "162/162 - 1s - loss: 0.6181 - auc_2: 0.7067 - accuracy: 0.6528\n",
            "Epoch 52/75\n",
            "162/162 - 1s - loss: 0.6179 - auc_2: 0.7068 - accuracy: 0.6523\n",
            "Epoch 53/75\n",
            "162/162 - 1s - loss: 0.6179 - auc_2: 0.7070 - accuracy: 0.6532\n",
            "Epoch 54/75\n",
            "162/162 - 1s - loss: 0.6178 - auc_2: 0.7071 - accuracy: 0.6522\n",
            "Epoch 55/75\n",
            "162/162 - 1s - loss: 0.6177 - auc_2: 0.7073 - accuracy: 0.6527\n",
            "Epoch 56/75\n",
            "162/162 - 1s - loss: 0.6176 - auc_2: 0.7073 - accuracy: 0.6527\n",
            "Epoch 57/75\n",
            "162/162 - 1s - loss: 0.6176 - auc_2: 0.7074 - accuracy: 0.6530\n",
            "Epoch 58/75\n",
            "162/162 - 1s - loss: 0.6174 - auc_2: 0.7076 - accuracy: 0.6528\n",
            "Epoch 59/75\n",
            "162/162 - 1s - loss: 0.6173 - auc_2: 0.7078 - accuracy: 0.6533\n",
            "Epoch 60/75\n",
            "162/162 - 1s - loss: 0.6172 - auc_2: 0.7079 - accuracy: 0.6529\n",
            "Epoch 61/75\n",
            "162/162 - 1s - loss: 0.6171 - auc_2: 0.7080 - accuracy: 0.6534\n",
            "Epoch 62/75\n",
            "162/162 - 1s - loss: 0.6171 - auc_2: 0.7081 - accuracy: 0.6533\n",
            "Epoch 63/75\n",
            "162/162 - 1s - loss: 0.6170 - auc_2: 0.7081 - accuracy: 0.6533\n",
            "Epoch 64/75\n",
            "162/162 - 1s - loss: 0.6169 - auc_2: 0.7083 - accuracy: 0.6533\n",
            "Epoch 65/75\n",
            "162/162 - 1s - loss: 0.6168 - auc_2: 0.7084 - accuracy: 0.6531\n",
            "Epoch 66/75\n",
            "162/162 - 1s - loss: 0.6167 - auc_2: 0.7086 - accuracy: 0.6536\n",
            "Epoch 67/75\n",
            "162/162 - 1s - loss: 0.6167 - auc_2: 0.7086 - accuracy: 0.6537\n",
            "Epoch 68/75\n",
            "162/162 - 1s - loss: 0.6166 - auc_2: 0.7087 - accuracy: 0.6541\n",
            "Epoch 69/75\n",
            "162/162 - 1s - loss: 0.6164 - auc_2: 0.7090 - accuracy: 0.6531\n",
            "Epoch 70/75\n",
            "162/162 - 1s - loss: 0.6165 - auc_2: 0.7088 - accuracy: 0.6537\n",
            "Epoch 71/75\n",
            "162/162 - 1s - loss: 0.6163 - auc_2: 0.7091 - accuracy: 0.6539\n",
            "Epoch 72/75\n",
            "162/162 - 1s - loss: 0.6163 - auc_2: 0.7091 - accuracy: 0.6543\n",
            "Epoch 73/75\n",
            "162/162 - 1s - loss: 0.6162 - auc_2: 0.7093 - accuracy: 0.6538\n",
            "Epoch 74/75\n",
            "162/162 - 1s - loss: 0.6161 - auc_2: 0.7095 - accuracy: 0.6545\n",
            "Epoch 75/75\n",
            "162/162 - 1s - loss: 0.6160 - auc_2: 0.7096 - accuracy: 0.6548\n",
            "235/235 - 0s\n",
            "235/235 - 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "162/162 - 1s - loss: 0.6361 - auc_2: 0.6946 - accuracy: 0.6328\n",
            "Epoch 2/75\n",
            "162/162 - 1s - loss: 0.6285 - auc_2: 0.6918 - accuracy: 0.6423\n",
            "Epoch 3/75\n",
            "162/162 - 1s - loss: 0.6275 - auc_2: 0.6935 - accuracy: 0.6431\n",
            "Epoch 4/75\n",
            "162/162 - 1s - loss: 0.6268 - auc_2: 0.6944 - accuracy: 0.6438\n",
            "Epoch 5/75\n",
            "162/162 - 1s - loss: 0.6261 - auc_2: 0.6955 - accuracy: 0.6450\n",
            "Epoch 6/75\n",
            "162/162 - 1s - loss: 0.6255 - auc_2: 0.6963 - accuracy: 0.6448\n",
            "Epoch 7/75\n",
            "162/162 - 1s - loss: 0.6250 - auc_2: 0.6971 - accuracy: 0.6458\n",
            "Epoch 8/75\n",
            "162/162 - 1s - loss: 0.6246 - auc_2: 0.6976 - accuracy: 0.6459\n",
            "Epoch 9/75\n",
            "162/162 - 1s - loss: 0.6241 - auc_2: 0.6985 - accuracy: 0.6463\n",
            "Epoch 10/75\n",
            "162/162 - 1s - loss: 0.6237 - auc_2: 0.6990 - accuracy: 0.6473\n",
            "Epoch 11/75\n",
            "162/162 - 1s - loss: 0.6234 - auc_2: 0.6996 - accuracy: 0.6475\n",
            "Epoch 12/75\n",
            "162/162 - 1s - loss: 0.6230 - auc_2: 0.6999 - accuracy: 0.6473\n",
            "Epoch 13/75\n",
            "162/162 - 1s - loss: 0.6227 - auc_2: 0.7005 - accuracy: 0.6486\n",
            "Epoch 14/75\n",
            "162/162 - 1s - loss: 0.6223 - auc_2: 0.7010 - accuracy: 0.6486\n",
            "Epoch 15/75\n",
            "162/162 - 1s - loss: 0.6220 - auc_2: 0.7015 - accuracy: 0.6486\n",
            "Epoch 16/75\n",
            "162/162 - 1s - loss: 0.6218 - auc_2: 0.7019 - accuracy: 0.6487\n",
            "Epoch 17/75\n",
            "162/162 - 1s - loss: 0.6216 - auc_2: 0.7021 - accuracy: 0.6493\n",
            "Epoch 18/75\n",
            "162/162 - 1s - loss: 0.6213 - auc_2: 0.7025 - accuracy: 0.6492\n",
            "Epoch 19/75\n",
            "162/162 - 1s - loss: 0.6211 - auc_2: 0.7029 - accuracy: 0.6500\n",
            "Epoch 20/75\n",
            "162/162 - 1s - loss: 0.6208 - auc_2: 0.7033 - accuracy: 0.6500\n",
            "Epoch 21/75\n",
            "162/162 - 1s - loss: 0.6206 - auc_2: 0.7035 - accuracy: 0.6500\n",
            "Epoch 22/75\n",
            "162/162 - 1s - loss: 0.6204 - auc_2: 0.7037 - accuracy: 0.6506\n",
            "Epoch 23/75\n",
            "162/162 - 1s - loss: 0.6203 - auc_2: 0.7040 - accuracy: 0.6507\n",
            "Epoch 24/75\n",
            "162/162 - 1s - loss: 0.6200 - auc_2: 0.7044 - accuracy: 0.6512\n",
            "Epoch 25/75\n",
            "162/162 - 1s - loss: 0.6199 - auc_2: 0.7045 - accuracy: 0.6511\n",
            "Epoch 26/75\n",
            "162/162 - 1s - loss: 0.6198 - auc_2: 0.7047 - accuracy: 0.6509\n",
            "Epoch 27/75\n",
            "162/162 - 1s - loss: 0.6196 - auc_2: 0.7049 - accuracy: 0.6511\n",
            "Epoch 28/75\n",
            "162/162 - 1s - loss: 0.6194 - auc_2: 0.7052 - accuracy: 0.6514\n",
            "Epoch 29/75\n",
            "162/162 - 1s - loss: 0.6193 - auc_2: 0.7054 - accuracy: 0.6514\n",
            "Epoch 30/75\n",
            "162/162 - 1s - loss: 0.6191 - auc_2: 0.7058 - accuracy: 0.6521\n",
            "Epoch 31/75\n",
            "162/162 - 1s - loss: 0.6191 - auc_2: 0.7056 - accuracy: 0.6521\n",
            "Epoch 32/75\n",
            "162/162 - 1s - loss: 0.6188 - auc_2: 0.7061 - accuracy: 0.6519\n",
            "Epoch 33/75\n",
            "162/162 - 1s - loss: 0.6187 - auc_2: 0.7062 - accuracy: 0.6521\n",
            "Epoch 34/75\n",
            "162/162 - 1s - loss: 0.6186 - auc_2: 0.7064 - accuracy: 0.6525\n",
            "Epoch 35/75\n",
            "162/162 - 1s - loss: 0.6184 - auc_2: 0.7066 - accuracy: 0.6524\n",
            "Epoch 36/75\n",
            "162/162 - 1s - loss: 0.6183 - auc_2: 0.7067 - accuracy: 0.6528\n",
            "Epoch 37/75\n",
            "162/162 - 1s - loss: 0.6182 - auc_2: 0.7071 - accuracy: 0.6531\n",
            "Epoch 38/75\n",
            "162/162 - 1s - loss: 0.6181 - auc_2: 0.7070 - accuracy: 0.6526\n",
            "Epoch 39/75\n",
            "162/162 - 1s - loss: 0.6179 - auc_2: 0.7073 - accuracy: 0.6533\n",
            "Epoch 40/75\n",
            "162/162 - 1s - loss: 0.6178 - auc_2: 0.7075 - accuracy: 0.6535\n",
            "Epoch 41/75\n",
            "162/162 - 1s - loss: 0.6177 - auc_2: 0.7076 - accuracy: 0.6534\n",
            "Epoch 42/75\n",
            "162/162 - 1s - loss: 0.6176 - auc_2: 0.7077 - accuracy: 0.6533\n",
            "Epoch 43/75\n",
            "162/162 - 1s - loss: 0.6175 - auc_2: 0.7080 - accuracy: 0.6531\n",
            "Epoch 44/75\n",
            "162/162 - 1s - loss: 0.6173 - auc_2: 0.7083 - accuracy: 0.6538\n",
            "Epoch 45/75\n",
            "162/162 - 1s - loss: 0.6174 - auc_2: 0.7080 - accuracy: 0.6542\n",
            "Epoch 46/75\n",
            "162/162 - 1s - loss: 0.6172 - auc_2: 0.7084 - accuracy: 0.6543\n",
            "Epoch 47/75\n",
            "162/162 - 1s - loss: 0.6171 - auc_2: 0.7086 - accuracy: 0.6538\n",
            "Epoch 48/75\n",
            "162/162 - 1s - loss: 0.6170 - auc_2: 0.7086 - accuracy: 0.6543\n",
            "Epoch 49/75\n",
            "162/162 - 1s - loss: 0.6168 - auc_2: 0.7088 - accuracy: 0.6546\n",
            "Epoch 50/75\n",
            "162/162 - 1s - loss: 0.6168 - auc_2: 0.7089 - accuracy: 0.6544\n",
            "Epoch 51/75\n",
            "162/162 - 1s - loss: 0.6167 - auc_2: 0.7089 - accuracy: 0.6544\n",
            "Epoch 52/75\n",
            "162/162 - 1s - loss: 0.6165 - auc_2: 0.7094 - accuracy: 0.6545\n",
            "Epoch 53/75\n",
            "162/162 - 1s - loss: 0.6165 - auc_2: 0.7093 - accuracy: 0.6554\n",
            "Epoch 54/75\n",
            "162/162 - 1s - loss: 0.6164 - auc_2: 0.7094 - accuracy: 0.6545\n",
            "Epoch 55/75\n",
            "162/162 - 1s - loss: 0.6162 - auc_2: 0.7096 - accuracy: 0.6550\n",
            "Epoch 56/75\n",
            "162/162 - 1s - loss: 0.6162 - auc_2: 0.7097 - accuracy: 0.6555\n",
            "Epoch 57/75\n",
            "162/162 - 1s - loss: 0.6161 - auc_2: 0.7099 - accuracy: 0.6550\n",
            "Epoch 58/75\n",
            "162/162 - 1s - loss: 0.6160 - auc_2: 0.7100 - accuracy: 0.6550\n",
            "Epoch 59/75\n",
            "162/162 - 1s - loss: 0.6159 - auc_2: 0.7100 - accuracy: 0.6546\n",
            "Epoch 60/75\n",
            "162/162 - 1s - loss: 0.6159 - auc_2: 0.7102 - accuracy: 0.6560\n",
            "Epoch 61/75\n",
            "162/162 - 1s - loss: 0.6157 - auc_2: 0.7103 - accuracy: 0.6550\n",
            "Epoch 62/75\n",
            "162/162 - 1s - loss: 0.6156 - auc_2: 0.7105 - accuracy: 0.6560\n",
            "Epoch 63/75\n",
            "162/162 - 1s - loss: 0.6155 - auc_2: 0.7107 - accuracy: 0.6555\n",
            "Epoch 64/75\n",
            "162/162 - 1s - loss: 0.6155 - auc_2: 0.7107 - accuracy: 0.6560\n",
            "Epoch 65/75\n",
            "162/162 - 1s - loss: 0.6154 - auc_2: 0.7107 - accuracy: 0.6563\n",
            "Epoch 66/75\n",
            "162/162 - 1s - loss: 0.6154 - auc_2: 0.7109 - accuracy: 0.6556\n",
            "Epoch 67/75\n",
            "162/162 - 1s - loss: 0.6153 - auc_2: 0.7109 - accuracy: 0.6570\n",
            "Epoch 68/75\n",
            "162/162 - 1s - loss: 0.6152 - auc_2: 0.7110 - accuracy: 0.6563\n",
            "Epoch 69/75\n",
            "162/162 - 1s - loss: 0.6152 - auc_2: 0.7111 - accuracy: 0.6560\n",
            "Epoch 70/75\n",
            "162/162 - 1s - loss: 0.6151 - auc_2: 0.7113 - accuracy: 0.6560\n",
            "Epoch 71/75\n",
            "162/162 - 1s - loss: 0.6150 - auc_2: 0.7113 - accuracy: 0.6563\n",
            "Epoch 72/75\n",
            "162/162 - 1s - loss: 0.6149 - auc_2: 0.7115 - accuracy: 0.6562\n",
            "Epoch 73/75\n",
            "162/162 - 1s - loss: 0.6148 - auc_2: 0.7116 - accuracy: 0.6563\n",
            "Epoch 74/75\n",
            "162/162 - 1s - loss: 0.6148 - auc_2: 0.7117 - accuracy: 0.6563\n",
            "Epoch 75/75\n",
            "162/162 - 1s - loss: 0.6147 - auc_2: 0.7118 - accuracy: 0.6560\n",
            "235/235 - 0s\n",
            "235/235 - 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "162/162 - 1s - loss: 0.6416 - auc_2: 0.6916 - accuracy: 0.6263\n",
            "Epoch 2/75\n",
            "162/162 - 1s - loss: 0.6302 - auc_2: 0.6896 - accuracy: 0.6409\n",
            "Epoch 3/75\n",
            "162/162 - 1s - loss: 0.6291 - auc_2: 0.6912 - accuracy: 0.6425\n",
            "Epoch 4/75\n",
            "162/162 - 1s - loss: 0.6285 - auc_2: 0.6922 - accuracy: 0.6426\n",
            "Epoch 5/75\n",
            "162/162 - 1s - loss: 0.6279 - auc_2: 0.6929 - accuracy: 0.6425\n",
            "Epoch 6/75\n",
            "162/162 - 1s - loss: 0.6272 - auc_2: 0.6939 - accuracy: 0.6439\n",
            "Epoch 7/75\n",
            "162/162 - 1s - loss: 0.6268 - auc_2: 0.6945 - accuracy: 0.6439\n",
            "Epoch 8/75\n",
            "162/162 - 1s - loss: 0.6262 - auc_2: 0.6953 - accuracy: 0.6440\n",
            "Epoch 9/75\n",
            "162/162 - 1s - loss: 0.6257 - auc_2: 0.6960 - accuracy: 0.6451\n",
            "Epoch 10/75\n",
            "162/162 - 1s - loss: 0.6253 - auc_2: 0.6966 - accuracy: 0.6458\n",
            "Epoch 11/75\n",
            "162/162 - 1s - loss: 0.6249 - auc_2: 0.6971 - accuracy: 0.6461\n",
            "Epoch 12/75\n",
            "162/162 - 1s - loss: 0.6246 - auc_2: 0.6977 - accuracy: 0.6469\n",
            "Epoch 13/75\n",
            "162/162 - 1s - loss: 0.6242 - auc_2: 0.6983 - accuracy: 0.6464\n",
            "Epoch 14/75\n",
            "162/162 - 1s - loss: 0.6239 - auc_2: 0.6986 - accuracy: 0.6465\n",
            "Epoch 15/75\n",
            "162/162 - 1s - loss: 0.6236 - auc_2: 0.6990 - accuracy: 0.6470\n",
            "Epoch 16/75\n",
            "162/162 - 1s - loss: 0.6234 - auc_2: 0.6994 - accuracy: 0.6477\n",
            "Epoch 17/75\n",
            "162/162 - 1s - loss: 0.6231 - auc_2: 0.6997 - accuracy: 0.6475\n",
            "Epoch 18/75\n",
            "162/162 - 1s - loss: 0.6228 - auc_2: 0.7002 - accuracy: 0.6479\n",
            "Epoch 19/75\n",
            "162/162 - 1s - loss: 0.6227 - auc_2: 0.7003 - accuracy: 0.6484\n",
            "Epoch 20/75\n",
            "162/162 - 1s - loss: 0.6225 - auc_2: 0.7006 - accuracy: 0.6480\n",
            "Epoch 21/75\n",
            "162/162 - 1s - loss: 0.6223 - auc_2: 0.7009 - accuracy: 0.6484\n",
            "Epoch 22/75\n",
            "162/162 - 1s - loss: 0.6221 - auc_2: 0.7011 - accuracy: 0.6493\n",
            "Epoch 23/75\n",
            "162/162 - 1s - loss: 0.6218 - auc_2: 0.7016 - accuracy: 0.6488\n",
            "Epoch 24/75\n",
            "162/162 - 1s - loss: 0.6217 - auc_2: 0.7017 - accuracy: 0.6495\n",
            "Epoch 25/75\n",
            "162/162 - 1s - loss: 0.6216 - auc_2: 0.7020 - accuracy: 0.6490\n",
            "Epoch 26/75\n",
            "162/162 - 1s - loss: 0.6214 - auc_2: 0.7022 - accuracy: 0.6492\n",
            "Epoch 27/75\n",
            "162/162 - 1s - loss: 0.6213 - auc_2: 0.7024 - accuracy: 0.6492\n",
            "Epoch 28/75\n",
            "162/162 - 1s - loss: 0.6211 - auc_2: 0.7027 - accuracy: 0.6496\n",
            "Epoch 29/75\n",
            "162/162 - 1s - loss: 0.6209 - auc_2: 0.7029 - accuracy: 0.6504\n",
            "Epoch 30/75\n",
            "162/162 - 1s - loss: 0.6209 - auc_2: 0.7030 - accuracy: 0.6494\n",
            "Epoch 31/75\n",
            "162/162 - 1s - loss: 0.6208 - auc_2: 0.7031 - accuracy: 0.6502\n",
            "Epoch 32/75\n",
            "162/162 - 1s - loss: 0.6206 - auc_2: 0.7034 - accuracy: 0.6502\n",
            "Epoch 33/75\n",
            "162/162 - 1s - loss: 0.6204 - auc_2: 0.7037 - accuracy: 0.6504\n",
            "Epoch 34/75\n",
            "162/162 - 1s - loss: 0.6203 - auc_2: 0.7038 - accuracy: 0.6504\n",
            "Epoch 35/75\n",
            "162/162 - 1s - loss: 0.6201 - auc_2: 0.7041 - accuracy: 0.6510\n",
            "Epoch 36/75\n",
            "162/162 - 1s - loss: 0.6200 - auc_2: 0.7042 - accuracy: 0.6508\n",
            "Epoch 37/75\n",
            "162/162 - 1s - loss: 0.6199 - auc_2: 0.7043 - accuracy: 0.6511\n",
            "Epoch 38/75\n",
            "162/162 - 1s - loss: 0.6198 - auc_2: 0.7046 - accuracy: 0.6509\n",
            "Epoch 39/75\n",
            "162/162 - 1s - loss: 0.6196 - auc_2: 0.7048 - accuracy: 0.6513\n",
            "Epoch 40/75\n",
            "162/162 - 1s - loss: 0.6196 - auc_2: 0.7049 - accuracy: 0.6515\n",
            "Epoch 41/75\n",
            "162/162 - 1s - loss: 0.6194 - auc_2: 0.7050 - accuracy: 0.6512\n",
            "Epoch 42/75\n",
            "162/162 - 1s - loss: 0.6194 - auc_2: 0.7050 - accuracy: 0.6511\n",
            "Epoch 43/75\n",
            "162/162 - 1s - loss: 0.6192 - auc_2: 0.7055 - accuracy: 0.6517\n",
            "Epoch 44/75\n",
            "162/162 - 1s - loss: 0.6192 - auc_2: 0.7055 - accuracy: 0.6519\n",
            "Epoch 45/75\n",
            "162/162 - 1s - loss: 0.6190 - auc_2: 0.7057 - accuracy: 0.6517\n",
            "Epoch 46/75\n",
            "162/162 - 1s - loss: 0.6190 - auc_2: 0.7057 - accuracy: 0.6519\n",
            "Epoch 47/75\n",
            "162/162 - 1s - loss: 0.6188 - auc_2: 0.7059 - accuracy: 0.6522\n",
            "Epoch 48/75\n",
            "162/162 - 1s - loss: 0.6187 - auc_2: 0.7061 - accuracy: 0.6518\n",
            "Epoch 49/75\n",
            "162/162 - 1s - loss: 0.6186 - auc_2: 0.7063 - accuracy: 0.6526\n",
            "Epoch 50/75\n",
            "162/162 - 1s - loss: 0.6185 - auc_2: 0.7064 - accuracy: 0.6524\n",
            "Epoch 51/75\n",
            "162/162 - 1s - loss: 0.6184 - auc_2: 0.7065 - accuracy: 0.6523\n",
            "Epoch 52/75\n",
            "162/162 - 1s - loss: 0.6183 - auc_2: 0.7067 - accuracy: 0.6522\n",
            "Epoch 53/75\n",
            "162/162 - 1s - loss: 0.6182 - auc_2: 0.7068 - accuracy: 0.6524\n",
            "Epoch 54/75\n",
            "162/162 - 1s - loss: 0.6182 - auc_2: 0.7068 - accuracy: 0.6522\n",
            "Epoch 55/75\n",
            "162/162 - 1s - loss: 0.6180 - auc_2: 0.7070 - accuracy: 0.6524\n",
            "Epoch 56/75\n",
            "162/162 - 1s - loss: 0.6180 - auc_2: 0.7072 - accuracy: 0.6523\n",
            "Epoch 57/75\n",
            "162/162 - 1s - loss: 0.6178 - auc_2: 0.7074 - accuracy: 0.6532\n",
            "Epoch 58/75\n",
            "162/162 - 1s - loss: 0.6177 - auc_2: 0.7076 - accuracy: 0.6534\n",
            "Epoch 59/75\n",
            "162/162 - 1s - loss: 0.6177 - auc_2: 0.7076 - accuracy: 0.6537\n",
            "Epoch 60/75\n",
            "162/162 - 1s - loss: 0.6175 - auc_2: 0.7078 - accuracy: 0.6535\n",
            "Epoch 61/75\n",
            "162/162 - 1s - loss: 0.6175 - auc_2: 0.7078 - accuracy: 0.6533\n",
            "Epoch 62/75\n",
            "162/162 - 1s - loss: 0.6174 - auc_2: 0.7080 - accuracy: 0.6537\n",
            "Epoch 63/75\n",
            "162/162 - 1s - loss: 0.6174 - auc_2: 0.7079 - accuracy: 0.6534\n",
            "Epoch 64/75\n",
            "162/162 - 1s - loss: 0.6174 - auc_2: 0.7081 - accuracy: 0.6536\n",
            "Epoch 65/75\n",
            "162/162 - 1s - loss: 0.6172 - auc_2: 0.7083 - accuracy: 0.6538\n",
            "Epoch 66/75\n",
            "162/162 - 1s - loss: 0.6171 - auc_2: 0.7085 - accuracy: 0.6543\n",
            "Epoch 67/75\n",
            "162/162 - 1s - loss: 0.6170 - auc_2: 0.7085 - accuracy: 0.6535\n",
            "Epoch 68/75\n",
            "162/162 - 1s - loss: 0.6170 - auc_2: 0.7085 - accuracy: 0.6543\n",
            "Epoch 69/75\n",
            "162/162 - 1s - loss: 0.6169 - auc_2: 0.7087 - accuracy: 0.6542\n",
            "Epoch 70/75\n",
            "162/162 - 1s - loss: 0.6168 - auc_2: 0.7087 - accuracy: 0.6538\n",
            "Epoch 71/75\n",
            "162/162 - 1s - loss: 0.6168 - auc_2: 0.7088 - accuracy: 0.6535\n",
            "Epoch 72/75\n",
            "162/162 - 1s - loss: 0.6167 - auc_2: 0.7090 - accuracy: 0.6544\n",
            "Epoch 73/75\n",
            "162/162 - 1s - loss: 0.6166 - auc_2: 0.7091 - accuracy: 0.6541\n",
            "Epoch 74/75\n",
            "162/162 - 1s - loss: 0.6166 - auc_2: 0.7091 - accuracy: 0.6540\n",
            "Epoch 75/75\n",
            "162/162 - 1s - loss: 0.6165 - auc_2: 0.7093 - accuracy: 0.6547\n",
            "235/235 - 0s\n",
            "235/235 - 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "152/152 - 1s - loss: 0.6392 - auc_2: 0.6965 - accuracy: 0.6315\n",
            "Epoch 2/75\n",
            "152/152 - 1s - loss: 0.6335 - auc_2: 0.6905 - accuracy: 0.6382\n",
            "Epoch 3/75\n",
            "152/152 - 1s - loss: 0.6325 - auc_2: 0.6919 - accuracy: 0.6390\n",
            "Epoch 4/75\n",
            "152/152 - 1s - loss: 0.6319 - auc_2: 0.6927 - accuracy: 0.6399\n",
            "Epoch 5/75\n",
            "152/152 - 1s - loss: 0.6313 - auc_2: 0.6936 - accuracy: 0.6403\n",
            "Epoch 6/75\n",
            "152/152 - 1s - loss: 0.6307 - auc_2: 0.6944 - accuracy: 0.6408\n",
            "Epoch 7/75\n",
            "152/152 - 1s - loss: 0.6302 - auc_2: 0.6952 - accuracy: 0.6418\n",
            "Epoch 8/75\n",
            "152/152 - 0s - loss: 0.6298 - auc_2: 0.6959 - accuracy: 0.6420\n",
            "Epoch 9/75\n",
            "152/152 - 1s - loss: 0.6294 - auc_2: 0.6964 - accuracy: 0.6421\n",
            "Epoch 10/75\n",
            "152/152 - 1s - loss: 0.6289 - auc_2: 0.6971 - accuracy: 0.6428\n",
            "Epoch 11/75\n",
            "152/152 - 1s - loss: 0.6286 - auc_2: 0.6975 - accuracy: 0.6430\n",
            "Epoch 12/75\n",
            "152/152 - 1s - loss: 0.6282 - auc_2: 0.6980 - accuracy: 0.6433\n",
            "Epoch 13/75\n",
            "152/152 - 0s - loss: 0.6279 - auc_2: 0.6985 - accuracy: 0.6435\n",
            "Epoch 14/75\n",
            "152/152 - 1s - loss: 0.6276 - auc_2: 0.6990 - accuracy: 0.6439\n",
            "Epoch 15/75\n",
            "152/152 - 1s - loss: 0.6273 - auc_2: 0.6994 - accuracy: 0.6443\n",
            "Epoch 16/75\n",
            "152/152 - 1s - loss: 0.6271 - auc_2: 0.6996 - accuracy: 0.6446\n",
            "Epoch 17/75\n",
            "152/152 - 1s - loss: 0.6268 - auc_2: 0.7001 - accuracy: 0.6447\n",
            "Epoch 18/75\n",
            "152/152 - 1s - loss: 0.6266 - auc_2: 0.7003 - accuracy: 0.6458\n",
            "Epoch 19/75\n",
            "152/152 - 1s - loss: 0.6264 - auc_2: 0.7007 - accuracy: 0.6460\n",
            "Epoch 20/75\n",
            "152/152 - 1s - loss: 0.6260 - auc_2: 0.7011 - accuracy: 0.6454\n",
            "Epoch 21/75\n",
            "152/152 - 1s - loss: 0.6258 - auc_2: 0.7015 - accuracy: 0.6460\n",
            "Epoch 22/75\n",
            "152/152 - 1s - loss: 0.6257 - auc_2: 0.7016 - accuracy: 0.6458\n",
            "Epoch 23/75\n",
            "152/152 - 1s - loss: 0.6255 - auc_2: 0.7020 - accuracy: 0.6456\n",
            "Epoch 24/75\n",
            "152/152 - 1s - loss: 0.6253 - auc_2: 0.7022 - accuracy: 0.6467\n",
            "Epoch 25/75\n",
            "152/152 - 1s - loss: 0.6251 - auc_2: 0.7024 - accuracy: 0.6465\n",
            "Epoch 26/75\n",
            "152/152 - 1s - loss: 0.6250 - auc_2: 0.7027 - accuracy: 0.6463\n",
            "Epoch 27/75\n",
            "152/152 - 1s - loss: 0.6248 - auc_2: 0.7029 - accuracy: 0.6468\n",
            "Epoch 28/75\n",
            "152/152 - 1s - loss: 0.6246 - auc_2: 0.7033 - accuracy: 0.6474\n",
            "Epoch 29/75\n",
            "152/152 - 1s - loss: 0.6244 - auc_2: 0.7035 - accuracy: 0.6463\n",
            "Epoch 30/75\n",
            "152/152 - 1s - loss: 0.6242 - auc_2: 0.7039 - accuracy: 0.6475\n",
            "Epoch 31/75\n",
            "152/152 - 1s - loss: 0.6242 - auc_2: 0.7038 - accuracy: 0.6475\n",
            "Epoch 32/75\n",
            "152/152 - 1s - loss: 0.6239 - auc_2: 0.7042 - accuracy: 0.6479\n",
            "Epoch 33/75\n",
            "152/152 - 1s - loss: 0.6237 - auc_2: 0.7045 - accuracy: 0.6481\n",
            "Epoch 34/75\n",
            "152/152 - 1s - loss: 0.6236 - auc_2: 0.7045 - accuracy: 0.6477\n",
            "Epoch 35/75\n",
            "152/152 - 1s - loss: 0.6235 - auc_2: 0.7048 - accuracy: 0.6486\n",
            "Epoch 36/75\n",
            "152/152 - 1s - loss: 0.6234 - auc_2: 0.7049 - accuracy: 0.6480\n",
            "Epoch 37/75\n",
            "152/152 - 1s - loss: 0.6232 - auc_2: 0.7052 - accuracy: 0.6490\n",
            "Epoch 38/75\n",
            "152/152 - 1s - loss: 0.6231 - auc_2: 0.7054 - accuracy: 0.6488\n",
            "Epoch 39/75\n",
            "152/152 - 1s - loss: 0.6229 - auc_2: 0.7056 - accuracy: 0.6488\n",
            "Epoch 40/75\n",
            "152/152 - 1s - loss: 0.6229 - auc_2: 0.7057 - accuracy: 0.6488\n",
            "Epoch 41/75\n",
            "152/152 - 1s - loss: 0.6227 - auc_2: 0.7060 - accuracy: 0.6494\n",
            "Epoch 42/75\n",
            "152/152 - 1s - loss: 0.6226 - auc_2: 0.7062 - accuracy: 0.6496\n",
            "Epoch 43/75\n",
            "152/152 - 1s - loss: 0.6224 - auc_2: 0.7063 - accuracy: 0.6494\n",
            "Epoch 44/75\n",
            "152/152 - 1s - loss: 0.6223 - auc_2: 0.7065 - accuracy: 0.6495\n",
            "Epoch 45/75\n",
            "152/152 - 1s - loss: 0.6222 - auc_2: 0.7068 - accuracy: 0.6500\n",
            "Epoch 46/75\n",
            "152/152 - 1s - loss: 0.6220 - auc_2: 0.7069 - accuracy: 0.6499\n",
            "Epoch 47/75\n",
            "152/152 - 1s - loss: 0.6220 - auc_2: 0.7070 - accuracy: 0.6506\n",
            "Epoch 48/75\n",
            "152/152 - 1s - loss: 0.6218 - auc_2: 0.7072 - accuracy: 0.6501\n",
            "Epoch 49/75\n",
            "152/152 - 1s - loss: 0.6217 - auc_2: 0.7073 - accuracy: 0.6506\n",
            "Epoch 50/75\n",
            "152/152 - 1s - loss: 0.6216 - auc_2: 0.7076 - accuracy: 0.6495\n",
            "Epoch 51/75\n",
            "152/152 - 1s - loss: 0.6215 - auc_2: 0.7075 - accuracy: 0.6501\n",
            "Epoch 52/75\n",
            "152/152 - 1s - loss: 0.6213 - auc_2: 0.7079 - accuracy: 0.6508\n",
            "Epoch 53/75\n",
            "152/152 - 1s - loss: 0.6212 - auc_2: 0.7080 - accuracy: 0.6507\n",
            "Epoch 54/75\n",
            "152/152 - 1s - loss: 0.6213 - auc_2: 0.7079 - accuracy: 0.6507\n",
            "Epoch 55/75\n",
            "152/152 - 1s - loss: 0.6210 - auc_2: 0.7083 - accuracy: 0.6511\n",
            "Epoch 56/75\n",
            "152/152 - 1s - loss: 0.6209 - auc_2: 0.7084 - accuracy: 0.6508\n",
            "Epoch 57/75\n",
            "152/152 - 1s - loss: 0.6209 - auc_2: 0.7085 - accuracy: 0.6507\n",
            "Epoch 58/75\n",
            "152/152 - 1s - loss: 0.6208 - auc_2: 0.7085 - accuracy: 0.6509\n",
            "Epoch 59/75\n",
            "152/152 - 1s - loss: 0.6207 - auc_2: 0.7087 - accuracy: 0.6510\n",
            "Epoch 60/75\n",
            "152/152 - 1s - loss: 0.6206 - auc_2: 0.7088 - accuracy: 0.6510\n",
            "Epoch 61/75\n",
            "152/152 - 1s - loss: 0.6204 - auc_2: 0.7091 - accuracy: 0.6513\n",
            "Epoch 62/75\n",
            "152/152 - 1s - loss: 0.6204 - auc_2: 0.7092 - accuracy: 0.6513\n",
            "Epoch 63/75\n",
            "152/152 - 1s - loss: 0.6203 - auc_2: 0.7092 - accuracy: 0.6519\n",
            "Epoch 64/75\n",
            "152/152 - 1s - loss: 0.6202 - auc_2: 0.7095 - accuracy: 0.6514\n",
            "Epoch 65/75\n",
            "152/152 - 1s - loss: 0.6201 - auc_2: 0.7095 - accuracy: 0.6512\n",
            "Epoch 66/75\n",
            "152/152 - 1s - loss: 0.6199 - auc_2: 0.7098 - accuracy: 0.6516\n",
            "Epoch 67/75\n",
            "152/152 - 1s - loss: 0.6199 - auc_2: 0.7099 - accuracy: 0.6528\n",
            "Epoch 68/75\n",
            "152/152 - 1s - loss: 0.6198 - auc_2: 0.7098 - accuracy: 0.6515\n",
            "Epoch 69/75\n",
            "152/152 - 1s - loss: 0.6198 - auc_2: 0.7099 - accuracy: 0.6519\n",
            "Epoch 70/75\n",
            "152/152 - 1s - loss: 0.6196 - auc_2: 0.7103 - accuracy: 0.6528\n",
            "Epoch 71/75\n",
            "152/152 - 1s - loss: 0.6196 - auc_2: 0.7102 - accuracy: 0.6522\n",
            "Epoch 72/75\n",
            "152/152 - 1s - loss: 0.6195 - auc_2: 0.7104 - accuracy: 0.6530\n",
            "Epoch 73/75\n",
            "152/152 - 1s - loss: 0.6194 - auc_2: 0.7105 - accuracy: 0.6525\n",
            "Epoch 74/75\n",
            "152/152 - 1s - loss: 0.6193 - auc_2: 0.7106 - accuracy: 0.6516\n",
            "Epoch 75/75\n",
            "152/152 - 1s - loss: 0.6192 - auc_2: 0.7107 - accuracy: 0.6523\n",
            "235/235 - 0s\n",
            "235/235 - 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "152/152 - 0s - loss: 0.6400 - auc_2: 0.6958 - accuracy: 0.6301\n",
            "Epoch 2/75\n",
            "152/152 - 1s - loss: 0.6328 - auc_2: 0.6918 - accuracy: 0.6385\n",
            "Epoch 3/75\n",
            "152/152 - 1s - loss: 0.6319 - auc_2: 0.6928 - accuracy: 0.6389\n",
            "Epoch 4/75\n",
            "152/152 - 1s - loss: 0.6311 - auc_2: 0.6940 - accuracy: 0.6402\n",
            "Epoch 5/75\n",
            "152/152 - 1s - loss: 0.6304 - auc_2: 0.6949 - accuracy: 0.6404\n",
            "Epoch 6/75\n",
            "152/152 - 1s - loss: 0.6300 - auc_2: 0.6955 - accuracy: 0.6410\n",
            "Epoch 7/75\n",
            "152/152 - 1s - loss: 0.6293 - auc_2: 0.6964 - accuracy: 0.6420\n",
            "Epoch 8/75\n",
            "152/152 - 1s - loss: 0.6289 - auc_2: 0.6970 - accuracy: 0.6426\n",
            "Epoch 9/75\n",
            "152/152 - 1s - loss: 0.6284 - auc_2: 0.6977 - accuracy: 0.6425\n",
            "Epoch 10/75\n",
            "152/152 - 1s - loss: 0.6280 - auc_2: 0.6983 - accuracy: 0.6435\n",
            "Epoch 11/75\n",
            "152/152 - 1s - loss: 0.6277 - auc_2: 0.6988 - accuracy: 0.6435\n",
            "Epoch 12/75\n",
            "152/152 - 1s - loss: 0.6273 - auc_2: 0.6994 - accuracy: 0.6449\n",
            "Epoch 13/75\n",
            "152/152 - 1s - loss: 0.6271 - auc_2: 0.6997 - accuracy: 0.6443\n",
            "Epoch 14/75\n",
            "152/152 - 1s - loss: 0.6267 - auc_2: 0.7002 - accuracy: 0.6445\n",
            "Epoch 15/75\n",
            "152/152 - 1s - loss: 0.6264 - auc_2: 0.7006 - accuracy: 0.6454\n",
            "Epoch 16/75\n",
            "152/152 - 1s - loss: 0.6260 - auc_2: 0.7010 - accuracy: 0.6449\n",
            "Epoch 17/75\n",
            "152/152 - 1s - loss: 0.6258 - auc_2: 0.7015 - accuracy: 0.6460\n",
            "Epoch 18/75\n",
            "152/152 - 1s - loss: 0.6256 - auc_2: 0.7017 - accuracy: 0.6457\n",
            "Epoch 19/75\n",
            "152/152 - 1s - loss: 0.6254 - auc_2: 0.7020 - accuracy: 0.6464\n",
            "Epoch 20/75\n",
            "152/152 - 1s - loss: 0.6251 - auc_2: 0.7025 - accuracy: 0.6470\n",
            "Epoch 21/75\n",
            "152/152 - 1s - loss: 0.6249 - auc_2: 0.7027 - accuracy: 0.6460\n",
            "Epoch 22/75\n",
            "152/152 - 1s - loss: 0.6248 - auc_2: 0.7029 - accuracy: 0.6468\n",
            "Epoch 23/75\n",
            "152/152 - 1s - loss: 0.6246 - auc_2: 0.7032 - accuracy: 0.6467\n",
            "Epoch 24/75\n",
            "152/152 - 1s - loss: 0.6244 - auc_2: 0.7035 - accuracy: 0.6471\n",
            "Epoch 25/75\n",
            "152/152 - 1s - loss: 0.6242 - auc_2: 0.7037 - accuracy: 0.6474\n",
            "Epoch 26/75\n",
            "152/152 - 1s - loss: 0.6240 - auc_2: 0.7039 - accuracy: 0.6473\n",
            "Epoch 27/75\n",
            "152/152 - 1s - loss: 0.6238 - auc_2: 0.7043 - accuracy: 0.6477\n",
            "Epoch 28/75\n",
            "152/152 - 1s - loss: 0.6238 - auc_2: 0.7044 - accuracy: 0.6472\n",
            "Epoch 29/75\n",
            "152/152 - 1s - loss: 0.6236 - auc_2: 0.7046 - accuracy: 0.6474\n",
            "Epoch 30/75\n",
            "152/152 - 1s - loss: 0.6234 - auc_2: 0.7051 - accuracy: 0.6481\n",
            "Epoch 31/75\n",
            "152/152 - 1s - loss: 0.6231 - auc_2: 0.7052 - accuracy: 0.6482\n",
            "Epoch 32/75\n",
            "152/152 - 1s - loss: 0.6231 - auc_2: 0.7054 - accuracy: 0.6480\n",
            "Epoch 33/75\n",
            "152/152 - 1s - loss: 0.6231 - auc_2: 0.7053 - accuracy: 0.6484\n",
            "Epoch 34/75\n",
            "152/152 - 1s - loss: 0.6229 - auc_2: 0.7056 - accuracy: 0.6488\n",
            "Epoch 35/75\n",
            "152/152 - 1s - loss: 0.6227 - auc_2: 0.7059 - accuracy: 0.6486\n",
            "Epoch 36/75\n",
            "152/152 - 1s - loss: 0.6226 - auc_2: 0.7061 - accuracy: 0.6490\n",
            "Epoch 37/75\n",
            "152/152 - 1s - loss: 0.6226 - auc_2: 0.7062 - accuracy: 0.6495\n",
            "Epoch 38/75\n",
            "152/152 - 1s - loss: 0.6224 - auc_2: 0.7064 - accuracy: 0.6494\n",
            "Epoch 39/75\n",
            "152/152 - 1s - loss: 0.6223 - auc_2: 0.7065 - accuracy: 0.6490\n",
            "Epoch 40/75\n",
            "152/152 - 1s - loss: 0.6221 - auc_2: 0.7068 - accuracy: 0.6492\n",
            "Epoch 41/75\n",
            "152/152 - 1s - loss: 0.6221 - auc_2: 0.7069 - accuracy: 0.6497\n",
            "Epoch 42/75\n",
            "152/152 - 1s - loss: 0.6219 - auc_2: 0.7072 - accuracy: 0.6494\n",
            "Epoch 43/75\n",
            "152/152 - 1s - loss: 0.6218 - auc_2: 0.7073 - accuracy: 0.6497\n",
            "Epoch 44/75\n",
            "152/152 - 1s - loss: 0.6218 - auc_2: 0.7072 - accuracy: 0.6486\n",
            "Epoch 45/75\n",
            "152/152 - 1s - loss: 0.6217 - auc_2: 0.7075 - accuracy: 0.6497\n",
            "Epoch 46/75\n",
            "152/152 - 1s - loss: 0.6215 - auc_2: 0.7078 - accuracy: 0.6506\n",
            "Epoch 47/75\n",
            "152/152 - 1s - loss: 0.6215 - auc_2: 0.7079 - accuracy: 0.6510\n",
            "Epoch 48/75\n",
            "152/152 - 1s - loss: 0.6213 - auc_2: 0.7080 - accuracy: 0.6503\n",
            "Epoch 49/75\n",
            "152/152 - 1s - loss: 0.6212 - auc_2: 0.7082 - accuracy: 0.6507\n",
            "Epoch 50/75\n",
            "152/152 - 1s - loss: 0.6211 - auc_2: 0.7083 - accuracy: 0.6511\n",
            "Epoch 51/75\n",
            "152/152 - 1s - loss: 0.6209 - auc_2: 0.7086 - accuracy: 0.6507\n",
            "Epoch 52/75\n",
            "152/152 - 1s - loss: 0.6209 - auc_2: 0.7088 - accuracy: 0.6508\n",
            "Epoch 53/75\n",
            "152/152 - 1s - loss: 0.6208 - auc_2: 0.7088 - accuracy: 0.6510\n",
            "Epoch 54/75\n",
            "152/152 - 0s - loss: 0.6207 - auc_2: 0.7089 - accuracy: 0.6507\n",
            "Epoch 55/75\n",
            "152/152 - 1s - loss: 0.6207 - auc_2: 0.7090 - accuracy: 0.6514\n",
            "Epoch 56/75\n",
            "152/152 - 1s - loss: 0.6204 - auc_2: 0.7094 - accuracy: 0.6511\n",
            "Epoch 57/75\n",
            "152/152 - 1s - loss: 0.6205 - auc_2: 0.7093 - accuracy: 0.6518\n",
            "Epoch 58/75\n",
            "152/152 - 1s - loss: 0.6204 - auc_2: 0.7094 - accuracy: 0.6518\n",
            "Epoch 59/75\n",
            "152/152 - 1s - loss: 0.6203 - auc_2: 0.7096 - accuracy: 0.6510\n",
            "Epoch 60/75\n",
            "152/152 - 0s - loss: 0.6202 - auc_2: 0.7096 - accuracy: 0.6515\n",
            "Epoch 61/75\n",
            "152/152 - 1s - loss: 0.6201 - auc_2: 0.7099 - accuracy: 0.6522\n",
            "Epoch 62/75\n",
            "152/152 - 1s - loss: 0.6200 - auc_2: 0.7100 - accuracy: 0.6517\n",
            "Epoch 63/75\n",
            "152/152 - 1s - loss: 0.6199 - auc_2: 0.7101 - accuracy: 0.6524\n",
            "Epoch 64/75\n",
            "152/152 - 1s - loss: 0.6198 - auc_2: 0.7102 - accuracy: 0.6519\n",
            "Epoch 65/75\n",
            "152/152 - 1s - loss: 0.6198 - auc_2: 0.7102 - accuracy: 0.6517\n",
            "Epoch 66/75\n",
            "152/152 - 1s - loss: 0.6197 - auc_2: 0.7104 - accuracy: 0.6521\n",
            "Epoch 67/75\n",
            "152/152 - 1s - loss: 0.6196 - auc_2: 0.7106 - accuracy: 0.6523\n",
            "Epoch 68/75\n",
            "152/152 - 1s - loss: 0.6195 - auc_2: 0.7106 - accuracy: 0.6523\n",
            "Epoch 69/75\n",
            "152/152 - 1s - loss: 0.6195 - auc_2: 0.7107 - accuracy: 0.6522\n",
            "Epoch 70/75\n",
            "152/152 - 1s - loss: 0.6194 - auc_2: 0.7109 - accuracy: 0.6522\n",
            "Epoch 71/75\n",
            "152/152 - 1s - loss: 0.6194 - auc_2: 0.7109 - accuracy: 0.6525\n",
            "Epoch 72/75\n",
            "152/152 - 1s - loss: 0.6192 - auc_2: 0.7111 - accuracy: 0.6529\n",
            "Epoch 73/75\n",
            "152/152 - 1s - loss: 0.6192 - auc_2: 0.7112 - accuracy: 0.6526\n",
            "Epoch 74/75\n",
            "152/152 - 1s - loss: 0.6191 - auc_2: 0.7112 - accuracy: 0.6524\n",
            "Epoch 75/75\n",
            "152/152 - 1s - loss: 0.6191 - auc_2: 0.7113 - accuracy: 0.6522\n",
            "235/235 - 0s\n",
            "235/235 - 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "152/152 - 1s - loss: 0.6397 - auc_2: 0.6964 - accuracy: 0.6312\n",
            "Epoch 2/75\n",
            "152/152 - 1s - loss: 0.6340 - auc_2: 0.6902 - accuracy: 0.6385\n",
            "Epoch 3/75\n",
            "152/152 - 1s - loss: 0.6330 - auc_2: 0.6916 - accuracy: 0.6394\n",
            "Epoch 4/75\n",
            "152/152 - 1s - loss: 0.6324 - auc_2: 0.6925 - accuracy: 0.6399\n",
            "Epoch 5/75\n",
            "152/152 - 1s - loss: 0.6317 - auc_2: 0.6934 - accuracy: 0.6403\n",
            "Epoch 6/75\n",
            "152/152 - 1s - loss: 0.6313 - auc_2: 0.6940 - accuracy: 0.6410\n",
            "Epoch 7/75\n",
            "152/152 - 1s - loss: 0.6307 - auc_2: 0.6948 - accuracy: 0.6419\n",
            "Epoch 8/75\n",
            "152/152 - 1s - loss: 0.6303 - auc_2: 0.6954 - accuracy: 0.6422\n",
            "Epoch 9/75\n",
            "152/152 - 1s - loss: 0.6298 - auc_2: 0.6962 - accuracy: 0.6427\n",
            "Epoch 10/75\n",
            "152/152 - 1s - loss: 0.6294 - auc_2: 0.6967 - accuracy: 0.6429\n",
            "Epoch 11/75\n",
            "152/152 - 1s - loss: 0.6290 - auc_2: 0.6974 - accuracy: 0.6435\n",
            "Epoch 12/75\n",
            "152/152 - 1s - loss: 0.6286 - auc_2: 0.6979 - accuracy: 0.6441\n",
            "Epoch 13/75\n",
            "152/152 - 1s - loss: 0.6282 - auc_2: 0.6985 - accuracy: 0.6446\n",
            "Epoch 14/75\n",
            "152/152 - 1s - loss: 0.6279 - auc_2: 0.6989 - accuracy: 0.6441\n",
            "Epoch 15/75\n",
            "152/152 - 1s - loss: 0.6277 - auc_2: 0.6992 - accuracy: 0.6452\n",
            "Epoch 16/75\n",
            "152/152 - 1s - loss: 0.6273 - auc_2: 0.6999 - accuracy: 0.6455\n",
            "Epoch 17/75\n",
            "152/152 - 1s - loss: 0.6271 - auc_2: 0.7002 - accuracy: 0.6451\n",
            "Epoch 18/75\n",
            "152/152 - 1s - loss: 0.6268 - auc_2: 0.7005 - accuracy: 0.6457\n",
            "Epoch 19/75\n",
            "152/152 - 1s - loss: 0.6266 - auc_2: 0.7008 - accuracy: 0.6459\n",
            "Epoch 20/75\n",
            "152/152 - 1s - loss: 0.6263 - auc_2: 0.7012 - accuracy: 0.6465\n",
            "Epoch 21/75\n",
            "152/152 - 1s - loss: 0.6261 - auc_2: 0.7015 - accuracy: 0.6457\n",
            "Epoch 22/75\n",
            "152/152 - 1s - loss: 0.6258 - auc_2: 0.7019 - accuracy: 0.6464\n",
            "Epoch 23/75\n",
            "152/152 - 1s - loss: 0.6257 - auc_2: 0.7021 - accuracy: 0.6465\n",
            "Epoch 24/75\n",
            "152/152 - 1s - loss: 0.6254 - auc_2: 0.7026 - accuracy: 0.6474\n",
            "Epoch 25/75\n",
            "152/152 - 1s - loss: 0.6253 - auc_2: 0.7027 - accuracy: 0.6466\n",
            "Epoch 26/75\n",
            "152/152 - 1s - loss: 0.6250 - auc_2: 0.7031 - accuracy: 0.6478\n",
            "Epoch 27/75\n",
            "152/152 - 1s - loss: 0.6250 - auc_2: 0.7031 - accuracy: 0.6475\n",
            "Epoch 28/75\n",
            "152/152 - 1s - loss: 0.6246 - auc_2: 0.7036 - accuracy: 0.6476\n",
            "Epoch 29/75\n",
            "152/152 - 1s - loss: 0.6245 - auc_2: 0.7037 - accuracy: 0.6481\n",
            "Epoch 30/75\n",
            "152/152 - 1s - loss: 0.6244 - auc_2: 0.7040 - accuracy: 0.6480\n",
            "Epoch 31/75\n",
            "152/152 - 1s - loss: 0.6241 - auc_2: 0.7043 - accuracy: 0.6483\n",
            "Epoch 32/75\n",
            "152/152 - 1s - loss: 0.6241 - auc_2: 0.7044 - accuracy: 0.6491\n",
            "Epoch 33/75\n",
            "152/152 - 1s - loss: 0.6240 - auc_2: 0.7047 - accuracy: 0.6487\n",
            "Epoch 34/75\n",
            "152/152 - 1s - loss: 0.6238 - auc_2: 0.7049 - accuracy: 0.6486\n",
            "Epoch 35/75\n",
            "152/152 - 1s - loss: 0.6237 - auc_2: 0.7050 - accuracy: 0.6486\n",
            "Epoch 36/75\n",
            "152/152 - 1s - loss: 0.6235 - auc_2: 0.7052 - accuracy: 0.6496\n",
            "Epoch 37/75\n",
            "152/152 - 1s - loss: 0.6234 - auc_2: 0.7054 - accuracy: 0.6488\n",
            "Epoch 38/75\n",
            "152/152 - 1s - loss: 0.6232 - auc_2: 0.7057 - accuracy: 0.6495\n",
            "Epoch 39/75\n",
            "152/152 - 1s - loss: 0.6232 - auc_2: 0.7059 - accuracy: 0.6500\n",
            "Epoch 40/75\n",
            "152/152 - 1s - loss: 0.6230 - auc_2: 0.7060 - accuracy: 0.6502\n",
            "Epoch 41/75\n",
            "152/152 - 1s - loss: 0.6229 - auc_2: 0.7062 - accuracy: 0.6500\n",
            "Epoch 42/75\n",
            "152/152 - 1s - loss: 0.6228 - auc_2: 0.7064 - accuracy: 0.6504\n",
            "Epoch 43/75\n",
            "152/152 - 1s - loss: 0.6225 - auc_2: 0.7067 - accuracy: 0.6502\n",
            "Epoch 44/75\n",
            "152/152 - 1s - loss: 0.6225 - auc_2: 0.7066 - accuracy: 0.6502\n",
            "Epoch 45/75\n",
            "152/152 - 1s - loss: 0.6224 - auc_2: 0.7068 - accuracy: 0.6499\n",
            "Epoch 46/75\n",
            "152/152 - 1s - loss: 0.6223 - auc_2: 0.7070 - accuracy: 0.6501\n",
            "Epoch 47/75\n",
            "152/152 - 1s - loss: 0.6222 - auc_2: 0.7072 - accuracy: 0.6506\n",
            "Epoch 48/75\n",
            "152/152 - 1s - loss: 0.6221 - auc_2: 0.7074 - accuracy: 0.6504\n",
            "Epoch 49/75\n",
            "152/152 - 1s - loss: 0.6219 - auc_2: 0.7076 - accuracy: 0.6506\n",
            "Epoch 50/75\n",
            "152/152 - 1s - loss: 0.6217 - auc_2: 0.7078 - accuracy: 0.6506\n",
            "Epoch 51/75\n",
            "152/152 - 1s - loss: 0.6218 - auc_2: 0.7078 - accuracy: 0.6506\n",
            "Epoch 52/75\n",
            "152/152 - 1s - loss: 0.6217 - auc_2: 0.7079 - accuracy: 0.6509\n",
            "Epoch 53/75\n",
            "152/152 - 1s - loss: 0.6215 - auc_2: 0.7082 - accuracy: 0.6520\n",
            "Epoch 54/75\n",
            "152/152 - 1s - loss: 0.6214 - auc_2: 0.7082 - accuracy: 0.6514\n",
            "Epoch 55/75\n",
            "152/152 - 1s - loss: 0.6213 - auc_2: 0.7084 - accuracy: 0.6511\n",
            "Epoch 56/75\n",
            "152/152 - 1s - loss: 0.6213 - auc_2: 0.7084 - accuracy: 0.6513\n",
            "Epoch 57/75\n",
            "152/152 - 1s - loss: 0.6211 - auc_2: 0.7087 - accuracy: 0.6519\n",
            "Epoch 58/75\n",
            "152/152 - 1s - loss: 0.6210 - auc_2: 0.7087 - accuracy: 0.6509\n",
            "Epoch 59/75\n",
            "152/152 - 1s - loss: 0.6209 - auc_2: 0.7089 - accuracy: 0.6524\n",
            "Epoch 60/75\n",
            "152/152 - 1s - loss: 0.6208 - auc_2: 0.7091 - accuracy: 0.6521\n",
            "Epoch 61/75\n",
            "152/152 - 1s - loss: 0.6208 - auc_2: 0.7092 - accuracy: 0.6516\n",
            "Epoch 62/75\n",
            "152/152 - 1s - loss: 0.6207 - auc_2: 0.7092 - accuracy: 0.6516\n",
            "Epoch 63/75\n",
            "152/152 - 1s - loss: 0.6206 - auc_2: 0.7093 - accuracy: 0.6518\n",
            "Epoch 64/75\n",
            "152/152 - 1s - loss: 0.6205 - auc_2: 0.7095 - accuracy: 0.6520\n",
            "Epoch 65/75\n",
            "152/152 - 1s - loss: 0.6203 - auc_2: 0.7098 - accuracy: 0.6525\n",
            "Epoch 66/75\n",
            "152/152 - 1s - loss: 0.6203 - auc_2: 0.7098 - accuracy: 0.6522\n",
            "Epoch 67/75\n",
            "152/152 - 1s - loss: 0.6202 - auc_2: 0.7100 - accuracy: 0.6525\n",
            "Epoch 68/75\n",
            "152/152 - 1s - loss: 0.6202 - auc_2: 0.7098 - accuracy: 0.6529\n",
            "Epoch 69/75\n",
            "152/152 - 1s - loss: 0.6201 - auc_2: 0.7101 - accuracy: 0.6530\n",
            "Epoch 70/75\n",
            "152/152 - 1s - loss: 0.6201 - auc_2: 0.7101 - accuracy: 0.6525\n",
            "Epoch 71/75\n",
            "152/152 - 1s - loss: 0.6199 - auc_2: 0.7103 - accuracy: 0.6527\n",
            "Epoch 72/75\n",
            "152/152 - 1s - loss: 0.6199 - auc_2: 0.7103 - accuracy: 0.6521\n",
            "Epoch 73/75\n",
            "152/152 - 1s - loss: 0.6197 - auc_2: 0.7106 - accuracy: 0.6533\n",
            "Epoch 74/75\n",
            "152/152 - 1s - loss: 0.6197 - auc_2: 0.7106 - accuracy: 0.6527\n",
            "Epoch 75/75\n",
            "152/152 - 1s - loss: 0.6196 - auc_2: 0.7108 - accuracy: 0.6527\n",
            "235/235 - 0s\n",
            "235/235 - 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "144/144 - 0s - loss: 0.6410 - auc_2: 0.6965 - accuracy: 0.6291\n",
            "Epoch 2/75\n",
            "144/144 - 0s - loss: 0.6347 - auc_2: 0.6901 - accuracy: 0.6387\n",
            "Epoch 3/75\n",
            "144/144 - 0s - loss: 0.6335 - auc_2: 0.6919 - accuracy: 0.6395\n",
            "Epoch 4/75\n",
            "144/144 - 0s - loss: 0.6329 - auc_2: 0.6926 - accuracy: 0.6394\n",
            "Epoch 5/75\n",
            "144/144 - 0s - loss: 0.6322 - auc_2: 0.6936 - accuracy: 0.6409\n",
            "Epoch 6/75\n",
            "144/144 - 1s - loss: 0.6318 - auc_2: 0.6942 - accuracy: 0.6414\n",
            "Epoch 7/75\n",
            "144/144 - 1s - loss: 0.6311 - auc_2: 0.6952 - accuracy: 0.6422\n",
            "Epoch 8/75\n",
            "144/144 - 0s - loss: 0.6307 - auc_2: 0.6958 - accuracy: 0.6422\n",
            "Epoch 9/75\n",
            "144/144 - 0s - loss: 0.6302 - auc_2: 0.6966 - accuracy: 0.6435\n",
            "Epoch 10/75\n",
            "144/144 - 0s - loss: 0.6298 - auc_2: 0.6970 - accuracy: 0.6429\n",
            "Epoch 11/75\n",
            "144/144 - 1s - loss: 0.6294 - auc_2: 0.6977 - accuracy: 0.6437\n",
            "Epoch 12/75\n",
            "144/144 - 1s - loss: 0.6290 - auc_2: 0.6982 - accuracy: 0.6438\n",
            "Epoch 13/75\n",
            "144/144 - 1s - loss: 0.6287 - auc_2: 0.6987 - accuracy: 0.6441\n",
            "Epoch 14/75\n",
            "144/144 - 0s - loss: 0.6284 - auc_2: 0.6992 - accuracy: 0.6447\n",
            "Epoch 15/75\n",
            "144/144 - 0s - loss: 0.6282 - auc_2: 0.6995 - accuracy: 0.6442\n",
            "Epoch 16/75\n",
            "144/144 - 0s - loss: 0.6278 - auc_2: 0.7001 - accuracy: 0.6455\n",
            "Epoch 17/75\n",
            "144/144 - 1s - loss: 0.6276 - auc_2: 0.7005 - accuracy: 0.6452\n",
            "Epoch 18/75\n",
            "144/144 - 1s - loss: 0.6273 - auc_2: 0.7008 - accuracy: 0.6448\n",
            "Epoch 19/75\n",
            "144/144 - 1s - loss: 0.6271 - auc_2: 0.7011 - accuracy: 0.6457\n",
            "Epoch 20/75\n",
            "144/144 - 1s - loss: 0.6270 - auc_2: 0.7013 - accuracy: 0.6464\n",
            "Epoch 21/75\n",
            "144/144 - 1s - loss: 0.6266 - auc_2: 0.7017 - accuracy: 0.6469\n",
            "Epoch 22/75\n",
            "144/144 - 0s - loss: 0.6265 - auc_2: 0.7019 - accuracy: 0.6468\n",
            "Epoch 23/75\n",
            "144/144 - 0s - loss: 0.6263 - auc_2: 0.7023 - accuracy: 0.6470\n",
            "Epoch 24/75\n",
            "144/144 - 0s - loss: 0.6261 - auc_2: 0.7025 - accuracy: 0.6476\n",
            "Epoch 25/75\n",
            "144/144 - 1s - loss: 0.6258 - auc_2: 0.7030 - accuracy: 0.6476\n",
            "Epoch 26/75\n",
            "144/144 - 0s - loss: 0.6257 - auc_2: 0.7031 - accuracy: 0.6474\n",
            "Epoch 27/75\n",
            "144/144 - 0s - loss: 0.6256 - auc_2: 0.7033 - accuracy: 0.6480\n",
            "Epoch 28/75\n",
            "144/144 - 0s - loss: 0.6253 - auc_2: 0.7036 - accuracy: 0.6477\n",
            "Epoch 29/75\n",
            "144/144 - 0s - loss: 0.6253 - auc_2: 0.7038 - accuracy: 0.6480\n",
            "Epoch 30/75\n",
            "144/144 - 1s - loss: 0.6251 - auc_2: 0.7040 - accuracy: 0.6478\n",
            "Epoch 31/75\n",
            "144/144 - 1s - loss: 0.6249 - auc_2: 0.7042 - accuracy: 0.6476\n",
            "Epoch 32/75\n",
            "144/144 - 1s - loss: 0.6247 - auc_2: 0.7045 - accuracy: 0.6488\n",
            "Epoch 33/75\n",
            "144/144 - 0s - loss: 0.6247 - auc_2: 0.7046 - accuracy: 0.6488\n",
            "Epoch 34/75\n",
            "144/144 - 1s - loss: 0.6245 - auc_2: 0.7049 - accuracy: 0.6483\n",
            "Epoch 35/75\n",
            "144/144 - 0s - loss: 0.6243 - auc_2: 0.7051 - accuracy: 0.6488\n",
            "Epoch 36/75\n",
            "144/144 - 1s - loss: 0.6242 - auc_2: 0.7054 - accuracy: 0.6496\n",
            "Epoch 37/75\n",
            "144/144 - 0s - loss: 0.6241 - auc_2: 0.7054 - accuracy: 0.6492\n",
            "Epoch 38/75\n",
            "144/144 - 1s - loss: 0.6240 - auc_2: 0.7055 - accuracy: 0.6490\n",
            "Epoch 39/75\n",
            "144/144 - 1s - loss: 0.6238 - auc_2: 0.7058 - accuracy: 0.6485\n",
            "Epoch 40/75\n",
            "144/144 - 1s - loss: 0.6238 - auc_2: 0.7059 - accuracy: 0.6492\n",
            "Epoch 41/75\n",
            "144/144 - 1s - loss: 0.6235 - auc_2: 0.7062 - accuracy: 0.6495\n",
            "Epoch 42/75\n",
            "144/144 - 1s - loss: 0.6235 - auc_2: 0.7063 - accuracy: 0.6494\n",
            "Epoch 43/75\n",
            "144/144 - 0s - loss: 0.6234 - auc_2: 0.7064 - accuracy: 0.6494\n",
            "Epoch 44/75\n",
            "144/144 - 0s - loss: 0.6232 - auc_2: 0.7066 - accuracy: 0.6497\n",
            "Epoch 45/75\n",
            "144/144 - 0s - loss: 0.6231 - auc_2: 0.7068 - accuracy: 0.6500\n",
            "Epoch 46/75\n",
            "144/144 - 1s - loss: 0.6230 - auc_2: 0.7070 - accuracy: 0.6500\n",
            "Epoch 47/75\n",
            "144/144 - 1s - loss: 0.6229 - auc_2: 0.7071 - accuracy: 0.6503\n",
            "Epoch 48/75\n",
            "144/144 - 1s - loss: 0.6228 - auc_2: 0.7072 - accuracy: 0.6499\n",
            "Epoch 49/75\n",
            "144/144 - 1s - loss: 0.6227 - auc_2: 0.7074 - accuracy: 0.6495\n",
            "Epoch 50/75\n",
            "144/144 - 1s - loss: 0.6226 - auc_2: 0.7075 - accuracy: 0.6501\n",
            "Epoch 51/75\n",
            "144/144 - 1s - loss: 0.6224 - auc_2: 0.7078 - accuracy: 0.6501\n",
            "Epoch 52/75\n",
            "144/144 - 1s - loss: 0.6223 - auc_2: 0.7080 - accuracy: 0.6499\n",
            "Epoch 53/75\n",
            "144/144 - 1s - loss: 0.6222 - auc_2: 0.7081 - accuracy: 0.6507\n",
            "Epoch 54/75\n",
            "144/144 - 1s - loss: 0.6221 - auc_2: 0.7082 - accuracy: 0.6504\n",
            "Epoch 55/75\n",
            "144/144 - 1s - loss: 0.6220 - auc_2: 0.7082 - accuracy: 0.6509\n",
            "Epoch 56/75\n",
            "144/144 - 1s - loss: 0.6219 - auc_2: 0.7085 - accuracy: 0.6508\n",
            "Epoch 57/75\n",
            "144/144 - 1s - loss: 0.6219 - auc_2: 0.7086 - accuracy: 0.6509\n",
            "Epoch 58/75\n",
            "144/144 - 1s - loss: 0.6218 - auc_2: 0.7088 - accuracy: 0.6515\n",
            "Epoch 59/75\n",
            "144/144 - 1s - loss: 0.6216 - auc_2: 0.7090 - accuracy: 0.6522\n",
            "Epoch 60/75\n",
            "144/144 - 1s - loss: 0.6216 - auc_2: 0.7089 - accuracy: 0.6510\n",
            "Epoch 61/75\n",
            "144/144 - 1s - loss: 0.6215 - auc_2: 0.7091 - accuracy: 0.6514\n",
            "Epoch 62/75\n",
            "144/144 - 0s - loss: 0.6213 - auc_2: 0.7092 - accuracy: 0.6514\n",
            "Epoch 63/75\n",
            "144/144 - 0s - loss: 0.6212 - auc_2: 0.7094 - accuracy: 0.6515\n",
            "Epoch 64/75\n",
            "144/144 - 0s - loss: 0.6212 - auc_2: 0.7095 - accuracy: 0.6511\n",
            "Epoch 65/75\n",
            "144/144 - 0s - loss: 0.6210 - auc_2: 0.7097 - accuracy: 0.6517\n",
            "Epoch 66/75\n",
            "144/144 - 0s - loss: 0.6209 - auc_2: 0.7100 - accuracy: 0.6519\n",
            "Epoch 67/75\n",
            "144/144 - 0s - loss: 0.6209 - auc_2: 0.7099 - accuracy: 0.6521\n",
            "Epoch 68/75\n",
            "144/144 - 1s - loss: 0.6208 - auc_2: 0.7100 - accuracy: 0.6520\n",
            "Epoch 69/75\n",
            "144/144 - 0s - loss: 0.6208 - auc_2: 0.7100 - accuracy: 0.6517\n",
            "Epoch 70/75\n",
            "144/144 - 1s - loss: 0.6207 - auc_2: 0.7102 - accuracy: 0.6524\n",
            "Epoch 71/75\n",
            "144/144 - 1s - loss: 0.6206 - auc_2: 0.7104 - accuracy: 0.6520\n",
            "Epoch 72/75\n",
            "144/144 - 1s - loss: 0.6205 - auc_2: 0.7104 - accuracy: 0.6524\n",
            "Epoch 73/75\n",
            "144/144 - 0s - loss: 0.6203 - auc_2: 0.7106 - accuracy: 0.6523\n",
            "Epoch 74/75\n",
            "144/144 - 0s - loss: 0.6202 - auc_2: 0.7108 - accuracy: 0.6535\n",
            "Epoch 75/75\n",
            "144/144 - 1s - loss: 0.6203 - auc_2: 0.7107 - accuracy: 0.6525\n",
            "235/235 - 0s\n",
            "235/235 - 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "144/144 - 1s - loss: 0.6393 - auc_2: 0.6972 - accuracy: 0.6319\n",
            "Epoch 2/75\n",
            "144/144 - 0s - loss: 0.6339 - auc_2: 0.6916 - accuracy: 0.6383\n",
            "Epoch 3/75\n",
            "144/144 - 0s - loss: 0.6329 - auc_2: 0.6930 - accuracy: 0.6392\n",
            "Epoch 4/75\n",
            "144/144 - 1s - loss: 0.6320 - auc_2: 0.6943 - accuracy: 0.6402\n",
            "Epoch 5/75\n",
            "144/144 - 0s - loss: 0.6314 - auc_2: 0.6951 - accuracy: 0.6406\n",
            "Epoch 6/75\n",
            "144/144 - 1s - loss: 0.6307 - auc_2: 0.6960 - accuracy: 0.6414\n",
            "Epoch 7/75\n",
            "144/144 - 1s - loss: 0.6300 - auc_2: 0.6971 - accuracy: 0.6422\n",
            "Epoch 8/75\n",
            "144/144 - 1s - loss: 0.6296 - auc_2: 0.6976 - accuracy: 0.6425\n",
            "Epoch 9/75\n",
            "144/144 - 0s - loss: 0.6291 - auc_2: 0.6983 - accuracy: 0.6428\n",
            "Epoch 10/75\n",
            "144/144 - 0s - loss: 0.6286 - auc_2: 0.6990 - accuracy: 0.6434\n",
            "Epoch 11/75\n",
            "144/144 - 0s - loss: 0.6284 - auc_2: 0.6995 - accuracy: 0.6437\n",
            "Epoch 12/75\n",
            "144/144 - 0s - loss: 0.6280 - auc_2: 0.7000 - accuracy: 0.6444\n",
            "Epoch 13/75\n",
            "144/144 - 1s - loss: 0.6277 - auc_2: 0.7004 - accuracy: 0.6444\n",
            "Epoch 14/75\n",
            "144/144 - 0s - loss: 0.6275 - auc_2: 0.7008 - accuracy: 0.6453\n",
            "Epoch 15/75\n",
            "144/144 - 0s - loss: 0.6273 - auc_2: 0.7011 - accuracy: 0.6453\n",
            "Epoch 16/75\n",
            "144/144 - 0s - loss: 0.6269 - auc_2: 0.7016 - accuracy: 0.6456\n",
            "Epoch 17/75\n",
            "144/144 - 0s - loss: 0.6267 - auc_2: 0.7020 - accuracy: 0.6461\n",
            "Epoch 18/75\n",
            "144/144 - 0s - loss: 0.6264 - auc_2: 0.7023 - accuracy: 0.6454\n",
            "Epoch 19/75\n",
            "144/144 - 1s - loss: 0.6262 - auc_2: 0.7027 - accuracy: 0.6464\n",
            "Epoch 20/75\n",
            "144/144 - 1s - loss: 0.6260 - auc_2: 0.7029 - accuracy: 0.6463\n",
            "Epoch 21/75\n",
            "144/144 - 1s - loss: 0.6258 - auc_2: 0.7032 - accuracy: 0.6464\n",
            "Epoch 22/75\n",
            "144/144 - 1s - loss: 0.6256 - auc_2: 0.7036 - accuracy: 0.6464\n",
            "Epoch 23/75\n",
            "144/144 - 0s - loss: 0.6253 - auc_2: 0.7040 - accuracy: 0.6470\n",
            "Epoch 24/75\n",
            "144/144 - 0s - loss: 0.6252 - auc_2: 0.7041 - accuracy: 0.6475\n",
            "Epoch 25/75\n",
            "144/144 - 1s - loss: 0.6250 - auc_2: 0.7044 - accuracy: 0.6477\n",
            "Epoch 26/75\n",
            "144/144 - 1s - loss: 0.6248 - auc_2: 0.7046 - accuracy: 0.6471\n",
            "Epoch 27/75\n",
            "144/144 - 0s - loss: 0.6246 - auc_2: 0.7050 - accuracy: 0.6482\n",
            "Epoch 28/75\n",
            "144/144 - 1s - loss: 0.6244 - auc_2: 0.7053 - accuracy: 0.6480\n",
            "Epoch 29/75\n",
            "144/144 - 1s - loss: 0.6243 - auc_2: 0.7054 - accuracy: 0.6482\n",
            "Epoch 30/75\n",
            "144/144 - 1s - loss: 0.6241 - auc_2: 0.7056 - accuracy: 0.6481\n",
            "Epoch 31/75\n",
            "144/144 - 0s - loss: 0.6239 - auc_2: 0.7060 - accuracy: 0.6486\n",
            "Epoch 32/75\n",
            "144/144 - 1s - loss: 0.6238 - auc_2: 0.7061 - accuracy: 0.6490\n",
            "Epoch 33/75\n",
            "144/144 - 1s - loss: 0.6237 - auc_2: 0.7063 - accuracy: 0.6483\n",
            "Epoch 34/75\n",
            "144/144 - 0s - loss: 0.6236 - auc_2: 0.7064 - accuracy: 0.6493\n",
            "Epoch 35/75\n",
            "144/144 - 1s - loss: 0.6233 - auc_2: 0.7068 - accuracy: 0.6492\n",
            "Epoch 36/75\n",
            "144/144 - 0s - loss: 0.6232 - auc_2: 0.7071 - accuracy: 0.6493\n",
            "Epoch 37/75\n",
            "144/144 - 0s - loss: 0.6231 - auc_2: 0.7070 - accuracy: 0.6496\n",
            "Epoch 38/75\n",
            "144/144 - 1s - loss: 0.6230 - auc_2: 0.7073 - accuracy: 0.6498\n",
            "Epoch 39/75\n",
            "144/144 - 1s - loss: 0.6228 - auc_2: 0.7076 - accuracy: 0.6502\n",
            "Epoch 40/75\n",
            "144/144 - 1s - loss: 0.6228 - auc_2: 0.7076 - accuracy: 0.6501\n",
            "Epoch 41/75\n",
            "144/144 - 1s - loss: 0.6226 - auc_2: 0.7078 - accuracy: 0.6506\n",
            "Epoch 42/75\n",
            "144/144 - 0s - loss: 0.6225 - auc_2: 0.7080 - accuracy: 0.6508\n",
            "Epoch 43/75\n",
            "144/144 - 0s - loss: 0.6224 - auc_2: 0.7081 - accuracy: 0.6503\n",
            "Epoch 44/75\n",
            "144/144 - 1s - loss: 0.6223 - auc_2: 0.7082 - accuracy: 0.6510\n",
            "Epoch 45/75\n",
            "144/144 - 1s - loss: 0.6221 - auc_2: 0.7085 - accuracy: 0.6509\n",
            "Epoch 46/75\n",
            "144/144 - 1s - loss: 0.6220 - auc_2: 0.7086 - accuracy: 0.6508\n",
            "Epoch 47/75\n",
            "144/144 - 1s - loss: 0.6219 - auc_2: 0.7087 - accuracy: 0.6516\n",
            "Epoch 48/75\n",
            "144/144 - 0s - loss: 0.6218 - auc_2: 0.7089 - accuracy: 0.6517\n",
            "Epoch 49/75\n",
            "144/144 - 1s - loss: 0.6217 - auc_2: 0.7091 - accuracy: 0.6510\n",
            "Epoch 50/75\n",
            "144/144 - 1s - loss: 0.6216 - auc_2: 0.7093 - accuracy: 0.6514\n",
            "Epoch 51/75\n",
            "144/144 - 0s - loss: 0.6215 - auc_2: 0.7093 - accuracy: 0.6516\n",
            "Epoch 52/75\n",
            "144/144 - 0s - loss: 0.6214 - auc_2: 0.7095 - accuracy: 0.6513\n",
            "Epoch 53/75\n",
            "144/144 - 1s - loss: 0.6212 - auc_2: 0.7097 - accuracy: 0.6524\n",
            "Epoch 54/75\n",
            "144/144 - 1s - loss: 0.6213 - auc_2: 0.7097 - accuracy: 0.6514\n",
            "Epoch 55/75\n",
            "144/144 - 0s - loss: 0.6210 - auc_2: 0.7101 - accuracy: 0.6522\n",
            "Epoch 56/75\n",
            "144/144 - 1s - loss: 0.6211 - auc_2: 0.7100 - accuracy: 0.6520\n",
            "Epoch 57/75\n",
            "144/144 - 0s - loss: 0.6209 - auc_2: 0.7102 - accuracy: 0.6520\n",
            "Epoch 58/75\n",
            "144/144 - 0s - loss: 0.6208 - auc_2: 0.7103 - accuracy: 0.6526\n",
            "Epoch 59/75\n",
            "144/144 - 0s - loss: 0.6208 - auc_2: 0.7104 - accuracy: 0.6518\n",
            "Epoch 60/75\n",
            "144/144 - 0s - loss: 0.6206 - auc_2: 0.7106 - accuracy: 0.6530\n",
            "Epoch 61/75\n",
            "144/144 - 1s - loss: 0.6206 - auc_2: 0.7106 - accuracy: 0.6521\n",
            "Epoch 62/75\n",
            "144/144 - 1s - loss: 0.6204 - auc_2: 0.7109 - accuracy: 0.6531\n",
            "Epoch 63/75\n",
            "144/144 - 1s - loss: 0.6204 - auc_2: 0.7109 - accuracy: 0.6526\n",
            "Epoch 64/75\n",
            "144/144 - 1s - loss: 0.6203 - auc_2: 0.7111 - accuracy: 0.6530\n",
            "Epoch 65/75\n",
            "144/144 - 0s - loss: 0.6201 - auc_2: 0.7113 - accuracy: 0.6529\n",
            "Epoch 66/75\n",
            "144/144 - 1s - loss: 0.6200 - auc_2: 0.7114 - accuracy: 0.6531\n",
            "Epoch 67/75\n",
            "144/144 - 1s - loss: 0.6200 - auc_2: 0.7115 - accuracy: 0.6536\n",
            "Epoch 68/75\n",
            "144/144 - 1s - loss: 0.6199 - auc_2: 0.7116 - accuracy: 0.6531\n",
            "Epoch 69/75\n",
            "144/144 - 1s - loss: 0.6198 - auc_2: 0.7116 - accuracy: 0.6530\n",
            "Epoch 70/75\n",
            "144/144 - 0s - loss: 0.6198 - auc_2: 0.7117 - accuracy: 0.6530\n",
            "Epoch 71/75\n",
            "144/144 - 1s - loss: 0.6197 - auc_2: 0.7119 - accuracy: 0.6540\n",
            "Epoch 72/75\n",
            "144/144 - 1s - loss: 0.6196 - auc_2: 0.7121 - accuracy: 0.6539\n",
            "Epoch 73/75\n",
            "144/144 - 1s - loss: 0.6195 - auc_2: 0.7121 - accuracy: 0.6541\n",
            "Epoch 74/75\n",
            "144/144 - 0s - loss: 0.6195 - auc_2: 0.7122 - accuracy: 0.6539\n",
            "Epoch 75/75\n",
            "144/144 - 0s - loss: 0.6194 - auc_2: 0.7123 - accuracy: 0.6534\n",
            "235/235 - 0s\n",
            "235/235 - 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "144/144 - 1s - loss: 0.6423 - auc_2: 0.6956 - accuracy: 0.6284\n",
            "Epoch 2/75\n",
            "144/144 - 0s - loss: 0.6352 - auc_2: 0.6904 - accuracy: 0.6386\n",
            "Epoch 3/75\n",
            "144/144 - 1s - loss: 0.6341 - auc_2: 0.6917 - accuracy: 0.6400\n",
            "Epoch 4/75\n",
            "144/144 - 1s - loss: 0.6335 - auc_2: 0.6926 - accuracy: 0.6397\n",
            "Epoch 5/75\n",
            "144/144 - 1s - loss: 0.6329 - auc_2: 0.6934 - accuracy: 0.6409\n",
            "Epoch 6/75\n",
            "144/144 - 1s - loss: 0.6324 - auc_2: 0.6941 - accuracy: 0.6413\n",
            "Epoch 7/75\n",
            "144/144 - 0s - loss: 0.6320 - auc_2: 0.6947 - accuracy: 0.6418\n",
            "Epoch 8/75\n",
            "144/144 - 0s - loss: 0.6316 - auc_2: 0.6951 - accuracy: 0.6422\n",
            "Epoch 9/75\n",
            "144/144 - 0s - loss: 0.6312 - auc_2: 0.6957 - accuracy: 0.6427\n",
            "Epoch 10/75\n",
            "144/144 - 0s - loss: 0.6307 - auc_2: 0.6963 - accuracy: 0.6426\n",
            "Epoch 11/75\n",
            "144/144 - 1s - loss: 0.6304 - auc_2: 0.6969 - accuracy: 0.6432\n",
            "Epoch 12/75\n",
            "144/144 - 1s - loss: 0.6300 - auc_2: 0.6974 - accuracy: 0.6436\n",
            "Epoch 13/75\n",
            "144/144 - 0s - loss: 0.6296 - auc_2: 0.6979 - accuracy: 0.6440\n",
            "Epoch 14/75\n",
            "144/144 - 0s - loss: 0.6294 - auc_2: 0.6982 - accuracy: 0.6439\n",
            "Epoch 15/75\n",
            "144/144 - 0s - loss: 0.6291 - auc_2: 0.6988 - accuracy: 0.6443\n",
            "Epoch 16/75\n",
            "144/144 - 1s - loss: 0.6288 - auc_2: 0.6991 - accuracy: 0.6441\n",
            "Epoch 17/75\n",
            "144/144 - 1s - loss: 0.6285 - auc_2: 0.6996 - accuracy: 0.6450\n",
            "Epoch 18/75\n",
            "144/144 - 1s - loss: 0.6282 - auc_2: 0.6999 - accuracy: 0.6448\n",
            "Epoch 19/75\n",
            "144/144 - 0s - loss: 0.6280 - auc_2: 0.7002 - accuracy: 0.6449\n",
            "Epoch 20/75\n",
            "144/144 - 1s - loss: 0.6278 - auc_2: 0.7004 - accuracy: 0.6463\n",
            "Epoch 21/75\n",
            "144/144 - 0s - loss: 0.6275 - auc_2: 0.7010 - accuracy: 0.6455\n",
            "Epoch 22/75\n",
            "144/144 - 0s - loss: 0.6274 - auc_2: 0.7010 - accuracy: 0.6461\n",
            "Epoch 23/75\n",
            "144/144 - 0s - loss: 0.6271 - auc_2: 0.7014 - accuracy: 0.6460\n",
            "Epoch 24/75\n",
            "144/144 - 0s - loss: 0.6268 - auc_2: 0.7019 - accuracy: 0.6464\n",
            "Epoch 25/75\n",
            "144/144 - 0s - loss: 0.6267 - auc_2: 0.7021 - accuracy: 0.6462\n",
            "Epoch 26/75\n",
            "144/144 - 1s - loss: 0.6266 - auc_2: 0.7022 - accuracy: 0.6462\n",
            "Epoch 27/75\n",
            "144/144 - 1s - loss: 0.6264 - auc_2: 0.7025 - accuracy: 0.6468\n",
            "Epoch 28/75\n",
            "144/144 - 1s - loss: 0.6262 - auc_2: 0.7028 - accuracy: 0.6473\n",
            "Epoch 29/75\n",
            "144/144 - 0s - loss: 0.6261 - auc_2: 0.7030 - accuracy: 0.6468\n",
            "Epoch 30/75\n",
            "144/144 - 1s - loss: 0.6259 - auc_2: 0.7032 - accuracy: 0.6476\n",
            "Epoch 31/75\n",
            "144/144 - 1s - loss: 0.6257 - auc_2: 0.7034 - accuracy: 0.6473\n",
            "Epoch 32/75\n",
            "144/144 - 0s - loss: 0.6256 - auc_2: 0.7035 - accuracy: 0.6475\n",
            "Epoch 33/75\n",
            "144/144 - 0s - loss: 0.6256 - auc_2: 0.7036 - accuracy: 0.6476\n",
            "Epoch 34/75\n",
            "144/144 - 0s - loss: 0.6254 - auc_2: 0.7038 - accuracy: 0.6472\n",
            "Epoch 35/75\n",
            "144/144 - 0s - loss: 0.6252 - auc_2: 0.7041 - accuracy: 0.6482\n",
            "Epoch 36/75\n",
            "144/144 - 0s - loss: 0.6251 - auc_2: 0.7043 - accuracy: 0.6476\n",
            "Epoch 37/75\n",
            "144/144 - 0s - loss: 0.6250 - auc_2: 0.7044 - accuracy: 0.6483\n",
            "Epoch 38/75\n",
            "144/144 - 0s - loss: 0.6249 - auc_2: 0.7045 - accuracy: 0.6486\n",
            "Epoch 39/75\n",
            "144/144 - 0s - loss: 0.6247 - auc_2: 0.7048 - accuracy: 0.6484\n",
            "Epoch 40/75\n",
            "144/144 - 1s - loss: 0.6247 - auc_2: 0.7049 - accuracy: 0.6492\n",
            "Epoch 41/75\n",
            "144/144 - 1s - loss: 0.6246 - auc_2: 0.7050 - accuracy: 0.6476\n",
            "Epoch 42/75\n",
            "144/144 - 1s - loss: 0.6245 - auc_2: 0.7052 - accuracy: 0.6487\n",
            "Epoch 43/75\n",
            "144/144 - 1s - loss: 0.6244 - auc_2: 0.7053 - accuracy: 0.6481\n",
            "Epoch 44/75\n",
            "144/144 - 1s - loss: 0.6243 - auc_2: 0.7054 - accuracy: 0.6488\n",
            "Epoch 45/75\n",
            "144/144 - 1s - loss: 0.6242 - auc_2: 0.7056 - accuracy: 0.6492\n",
            "Epoch 46/75\n",
            "144/144 - 1s - loss: 0.6240 - auc_2: 0.7058 - accuracy: 0.6493\n",
            "Epoch 47/75\n",
            "144/144 - 0s - loss: 0.6239 - auc_2: 0.7060 - accuracy: 0.6493\n",
            "Epoch 48/75\n",
            "144/144 - 1s - loss: 0.6238 - auc_2: 0.7061 - accuracy: 0.6494\n",
            "Epoch 49/75\n",
            "144/144 - 1s - loss: 0.6238 - auc_2: 0.7062 - accuracy: 0.6494\n",
            "Epoch 50/75\n",
            "144/144 - 1s - loss: 0.6237 - auc_2: 0.7063 - accuracy: 0.6491\n",
            "Epoch 51/75\n",
            "144/144 - 0s - loss: 0.6234 - auc_2: 0.7066 - accuracy: 0.6499\n",
            "Epoch 52/75\n",
            "144/144 - 1s - loss: 0.6234 - auc_2: 0.7066 - accuracy: 0.6493\n",
            "Epoch 53/75\n",
            "144/144 - 1s - loss: 0.6234 - auc_2: 0.7068 - accuracy: 0.6496\n",
            "Epoch 54/75\n",
            "144/144 - 1s - loss: 0.6233 - auc_2: 0.7069 - accuracy: 0.6495\n",
            "Epoch 55/75\n",
            "144/144 - 1s - loss: 0.6231 - auc_2: 0.7071 - accuracy: 0.6502\n",
            "Epoch 56/75\n",
            "144/144 - 0s - loss: 0.6232 - auc_2: 0.7071 - accuracy: 0.6507\n",
            "Epoch 57/75\n",
            "144/144 - 0s - loss: 0.6230 - auc_2: 0.7072 - accuracy: 0.6500\n",
            "Epoch 58/75\n",
            "144/144 - 0s - loss: 0.6229 - auc_2: 0.7075 - accuracy: 0.6496\n",
            "Epoch 59/75\n",
            "144/144 - 0s - loss: 0.6227 - auc_2: 0.7077 - accuracy: 0.6508\n",
            "Epoch 60/75\n",
            "144/144 - 1s - loss: 0.6228 - auc_2: 0.7075 - accuracy: 0.6511\n",
            "Epoch 61/75\n",
            "144/144 - 1s - loss: 0.6226 - auc_2: 0.7079 - accuracy: 0.6511\n",
            "Epoch 62/75\n",
            "144/144 - 0s - loss: 0.6224 - auc_2: 0.7080 - accuracy: 0.6510\n",
            "Epoch 63/75\n",
            "144/144 - 1s - loss: 0.6225 - auc_2: 0.7079 - accuracy: 0.6511\n",
            "Epoch 64/75\n",
            "144/144 - 1s - loss: 0.6225 - auc_2: 0.7081 - accuracy: 0.6510\n",
            "Epoch 65/75\n",
            "144/144 - 0s - loss: 0.6223 - auc_2: 0.7083 - accuracy: 0.6510\n",
            "Epoch 66/75\n",
            "144/144 - 0s - loss: 0.6221 - auc_2: 0.7084 - accuracy: 0.6514\n",
            "Epoch 67/75\n",
            "144/144 - 1s - loss: 0.6222 - auc_2: 0.7083 - accuracy: 0.6509\n",
            "Epoch 68/75\n",
            "144/144 - 0s - loss: 0.6221 - auc_2: 0.7086 - accuracy: 0.6519\n",
            "Epoch 69/75\n",
            "144/144 - 0s - loss: 0.6220 - auc_2: 0.7086 - accuracy: 0.6514\n",
            "Epoch 70/75\n",
            "144/144 - 0s - loss: 0.6219 - auc_2: 0.7087 - accuracy: 0.6514\n",
            "Epoch 71/75\n",
            "144/144 - 1s - loss: 0.6218 - auc_2: 0.7090 - accuracy: 0.6519\n",
            "Epoch 72/75\n",
            "144/144 - 0s - loss: 0.6218 - auc_2: 0.7089 - accuracy: 0.6515\n",
            "Epoch 73/75\n",
            "144/144 - 1s - loss: 0.6217 - auc_2: 0.7090 - accuracy: 0.6518\n",
            "Epoch 74/75\n",
            "144/144 - 0s - loss: 0.6217 - auc_2: 0.7092 - accuracy: 0.6521\n",
            "Epoch 75/75\n",
            "144/144 - 0s - loss: 0.6215 - auc_2: 0.7094 - accuracy: 0.6521\n",
            "235/235 - 0s\n",
            "235/235 - 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed: 25.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "703/703 - 3s - loss: 0.4016 - auc_2: 0.7559 - accuracy: 0.8456\n",
            "Epoch 2/75\n",
            "703/703 - 3s - loss: 0.3968 - auc_2: 0.6941 - accuracy: 0.8468\n",
            "Epoch 3/75\n",
            "703/703 - 3s - loss: 0.3961 - auc_2: 0.6959 - accuracy: 0.8468\n",
            "Epoch 4/75\n",
            "703/703 - 3s - loss: 0.3956 - auc_2: 0.6972 - accuracy: 0.8468\n",
            "Epoch 5/75\n",
            "703/703 - 3s - loss: 0.3952 - auc_2: 0.6983 - accuracy: 0.8469\n",
            "Epoch 6/75\n",
            "703/703 - 3s - loss: 0.3949 - auc_2: 0.6991 - accuracy: 0.8469\n",
            "Epoch 7/75\n",
            "703/703 - 2s - loss: 0.3947 - auc_2: 0.6997 - accuracy: 0.8469\n",
            "Epoch 8/75\n",
            "703/703 - 3s - loss: 0.3945 - auc_2: 0.7003 - accuracy: 0.8469\n",
            "Epoch 9/75\n",
            "703/703 - 3s - loss: 0.3942 - auc_2: 0.7011 - accuracy: 0.8470\n",
            "Epoch 10/75\n",
            "703/703 - 3s - loss: 0.3941 - auc_2: 0.7012 - accuracy: 0.8470\n",
            "Epoch 11/75\n",
            "703/703 - 3s - loss: 0.3940 - auc_2: 0.7016 - accuracy: 0.8470\n",
            "Epoch 12/75\n",
            "703/703 - 2s - loss: 0.3938 - auc_2: 0.7021 - accuracy: 0.8470\n",
            "Epoch 13/75\n",
            "703/703 - 2s - loss: 0.3938 - auc_2: 0.7022 - accuracy: 0.8470\n",
            "Epoch 14/75\n",
            "703/703 - 3s - loss: 0.3936 - auc_2: 0.7025 - accuracy: 0.8470\n",
            "Epoch 15/75\n",
            "703/703 - 3s - loss: 0.3935 - auc_2: 0.7027 - accuracy: 0.8470\n",
            "Epoch 16/75\n",
            "703/703 - 3s - loss: 0.3935 - auc_2: 0.7029 - accuracy: 0.8470\n",
            "Epoch 17/75\n",
            "703/703 - 3s - loss: 0.3934 - auc_2: 0.7030 - accuracy: 0.8470\n",
            "Epoch 18/75\n",
            "703/703 - 3s - loss: 0.3933 - auc_2: 0.7034 - accuracy: 0.8470\n",
            "Epoch 19/75\n",
            "703/703 - 2s - loss: 0.3933 - auc_2: 0.7034 - accuracy: 0.8471\n",
            "Epoch 20/75\n",
            "703/703 - 3s - loss: 0.3932 - auc_2: 0.7037 - accuracy: 0.8470\n",
            "Epoch 21/75\n",
            "703/703 - 2s - loss: 0.3931 - auc_2: 0.7038 - accuracy: 0.8470\n",
            "Epoch 22/75\n",
            "703/703 - 2s - loss: 0.3930 - auc_2: 0.7040 - accuracy: 0.8471\n",
            "Epoch 23/75\n",
            "703/703 - 2s - loss: 0.3930 - auc_2: 0.7041 - accuracy: 0.8471\n",
            "Epoch 24/75\n",
            "703/703 - 3s - loss: 0.3930 - auc_2: 0.7042 - accuracy: 0.8470\n",
            "Epoch 25/75\n",
            "703/703 - 2s - loss: 0.3929 - auc_2: 0.7044 - accuracy: 0.8471\n",
            "Epoch 26/75\n",
            "703/703 - 3s - loss: 0.3929 - auc_2: 0.7045 - accuracy: 0.8470\n",
            "Epoch 27/75\n",
            "703/703 - 2s - loss: 0.3928 - auc_2: 0.7047 - accuracy: 0.8471\n",
            "Epoch 28/75\n",
            "703/703 - 2s - loss: 0.3927 - auc_2: 0.7049 - accuracy: 0.8471\n",
            "Epoch 29/75\n",
            "703/703 - 3s - loss: 0.3927 - auc_2: 0.7049 - accuracy: 0.8471\n",
            "Epoch 30/75\n",
            "703/703 - 3s - loss: 0.3927 - auc_2: 0.7052 - accuracy: 0.8470\n",
            "Epoch 31/75\n",
            "703/703 - 3s - loss: 0.3926 - auc_2: 0.7052 - accuracy: 0.8470\n",
            "Epoch 32/75\n",
            "703/703 - 3s - loss: 0.3926 - auc_2: 0.7053 - accuracy: 0.8471\n",
            "Epoch 33/75\n",
            "703/703 - 3s - loss: 0.3925 - auc_2: 0.7054 - accuracy: 0.8470\n",
            "Epoch 34/75\n",
            "703/703 - 2s - loss: 0.3925 - auc_2: 0.7055 - accuracy: 0.8471\n",
            "Epoch 35/75\n",
            "703/703 - 3s - loss: 0.3924 - auc_2: 0.7057 - accuracy: 0.8471\n",
            "Epoch 36/75\n",
            "703/703 - 3s - loss: 0.3924 - auc_2: 0.7058 - accuracy: 0.8470\n",
            "Epoch 37/75\n",
            "703/703 - 3s - loss: 0.3924 - auc_2: 0.7058 - accuracy: 0.8471\n",
            "Epoch 38/75\n",
            "703/703 - 3s - loss: 0.3923 - auc_2: 0.7058 - accuracy: 0.8471\n",
            "Epoch 39/75\n",
            "703/703 - 3s - loss: 0.3923 - auc_2: 0.7059 - accuracy: 0.8472\n",
            "Epoch 40/75\n",
            "703/703 - 3s - loss: 0.3923 - auc_2: 0.7061 - accuracy: 0.8472\n",
            "Epoch 41/75\n",
            "703/703 - 3s - loss: 0.3923 - auc_2: 0.7061 - accuracy: 0.8472\n",
            "Epoch 42/75\n",
            "703/703 - 3s - loss: 0.3922 - auc_2: 0.7062 - accuracy: 0.8471\n",
            "Epoch 43/75\n",
            "703/703 - 3s - loss: 0.3922 - auc_2: 0.7062 - accuracy: 0.8471\n",
            "Epoch 44/75\n",
            "703/703 - 3s - loss: 0.3922 - auc_2: 0.7063 - accuracy: 0.8472\n",
            "Epoch 45/75\n",
            "703/703 - 2s - loss: 0.3921 - auc_2: 0.7065 - accuracy: 0.8470\n",
            "Epoch 46/75\n",
            "703/703 - 3s - loss: 0.3921 - auc_2: 0.7066 - accuracy: 0.8471\n",
            "Epoch 47/75\n",
            "703/703 - 3s - loss: 0.3921 - auc_2: 0.7066 - accuracy: 0.8472\n",
            "Epoch 48/75\n",
            "703/703 - 3s - loss: 0.3921 - auc_2: 0.7066 - accuracy: 0.8472\n",
            "Epoch 49/75\n",
            "703/703 - 3s - loss: 0.3920 - auc_2: 0.7067 - accuracy: 0.8471\n",
            "Epoch 50/75\n",
            "703/703 - 3s - loss: 0.3920 - auc_2: 0.7068 - accuracy: 0.8471\n",
            "Epoch 51/75\n",
            "703/703 - 3s - loss: 0.3920 - auc_2: 0.7068 - accuracy: 0.8471\n",
            "Epoch 52/75\n",
            "703/703 - 3s - loss: 0.3919 - auc_2: 0.7069 - accuracy: 0.8471\n",
            "Epoch 53/75\n",
            "703/703 - 3s - loss: 0.3920 - auc_2: 0.7069 - accuracy: 0.8471\n",
            "Epoch 54/75\n",
            "703/703 - 3s - loss: 0.3919 - auc_2: 0.7070 - accuracy: 0.8471\n",
            "Epoch 55/75\n",
            "703/703 - 3s - loss: 0.3918 - auc_2: 0.7072 - accuracy: 0.8472\n",
            "Epoch 56/75\n",
            "703/703 - 3s - loss: 0.3918 - auc_2: 0.7072 - accuracy: 0.8471\n",
            "Epoch 57/75\n",
            "703/703 - 3s - loss: 0.3919 - auc_2: 0.7071 - accuracy: 0.8471\n",
            "Epoch 58/75\n",
            "703/703 - 3s - loss: 0.3918 - auc_2: 0.7073 - accuracy: 0.8472\n",
            "Epoch 59/75\n",
            "703/703 - 2s - loss: 0.3918 - auc_2: 0.7073 - accuracy: 0.8472\n",
            "Epoch 60/75\n",
            "703/703 - 3s - loss: 0.3918 - auc_2: 0.7073 - accuracy: 0.8472\n",
            "Epoch 61/75\n",
            "703/703 - 3s - loss: 0.3917 - auc_2: 0.7075 - accuracy: 0.8472\n",
            "Epoch 62/75\n",
            "703/703 - 3s - loss: 0.3917 - auc_2: 0.7074 - accuracy: 0.8472\n",
            "Epoch 63/75\n",
            "703/703 - 3s - loss: 0.3917 - auc_2: 0.7076 - accuracy: 0.8472\n",
            "Epoch 64/75\n",
            "703/703 - 2s - loss: 0.3917 - auc_2: 0.7075 - accuracy: 0.8471\n",
            "Epoch 65/75\n",
            "703/703 - 3s - loss: 0.3917 - auc_2: 0.7076 - accuracy: 0.8472\n",
            "Epoch 66/75\n",
            "703/703 - 3s - loss: 0.3916 - auc_2: 0.7076 - accuracy: 0.8472\n",
            "Epoch 67/75\n",
            "703/703 - 2s - loss: 0.3916 - auc_2: 0.7077 - accuracy: 0.8472\n",
            "Epoch 68/75\n",
            "703/703 - 2s - loss: 0.3916 - auc_2: 0.7078 - accuracy: 0.8471\n",
            "Epoch 69/75\n",
            "703/703 - 3s - loss: 0.3916 - auc_2: 0.7078 - accuracy: 0.8471\n",
            "Epoch 70/75\n",
            "703/703 - 2s - loss: 0.3915 - auc_2: 0.7079 - accuracy: 0.8472\n",
            "Epoch 71/75\n",
            "703/703 - 3s - loss: 0.3915 - auc_2: 0.7080 - accuracy: 0.8471\n",
            "Epoch 72/75\n",
            "703/703 - 3s - loss: 0.3915 - auc_2: 0.7080 - accuracy: 0.8472\n",
            "Epoch 73/75\n",
            "703/703 - 2s - loss: 0.3915 - auc_2: 0.7080 - accuracy: 0.8471\n",
            "Epoch 74/75\n",
            "703/703 - 3s - loss: 0.3915 - auc_2: 0.7080 - accuracy: 0.8472\n",
            "Epoch 75/75\n",
            "703/703 - 3s - loss: 0.3914 - auc_2: 0.7081 - accuracy: 0.8472\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=0, shuffle=True),\n",
              "             error_score=nan,\n",
              "             estimator=Pipeline(memory=None,\n",
              "                                steps=[('under',\n",
              "                                        RandomUnderSampler(random_state=None,\n",
              "                                                           ratio=None,\n",
              "                                                           replacement=False,\n",
              "                                                           return_indices=False,\n",
              "                                                           sampling_strategy='auto')),\n",
              "                                       ('model',\n",
              "                                        <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f1c8b2f6128>)],\n",
              "                                verb...\n",
              "                      'average_precision': make_scorer(average_precision_score, needs_proba=True),\n",
              "                      'balanced_accuracy': make_scorer(balanced_accuracy_score),\n",
              "                      'f1': make_scorer(f1_score),\n",
              "                      'loan_loss': make_scorer(calcCostRev, greater_is_better=False, needs_proba=True, cost=(1, 3.7), returnThreshold=False),\n",
              "                      'neg_brier_score': make_scorer(brier_score_loss, needs_proba=True),\n",
              "                      'roc_auc': make_scorer(roc_auc_score, needs_proba=True)},\n",
              "             verbose=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBlpmZvc5P1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Assign results of cross validation.\n",
        "results_Grid3_NN = gridNNFinal.cv_results_"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0awmlXTxQEZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "a9bf8db3-d480-4486-94e1-8133447b0669"
      },
      "source": [
        "#Best parameters based on loan loss:\n",
        "ind = np.argmin(results_Grid3_NN['rank_test_loan_loss'])\n",
        "print('Parameters:', results_Grid3_NN['params'][ind])\n",
        "print('ROC-AUC:', results_Grid3_NN['mean_test_roc_auc'][ind])\n",
        "print('F1:', results_Grid3_NN['mean_test_f1'][ind])\n",
        "print('Accuracy:', results_Grid3_NN['mean_test_accuracy'][ind])\n",
        "print('Balanced Accuracy:', results_Grid3_NN['mean_test_balanced_accuracy'][ind])\n",
        "print('Loan Loss:', results_Grid3_NN['mean_test_loan_loss'][ind])"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters: {'model__batch_size': 1000, 'model__epochs': 75, 'under': RandomUnderSampler(random_state=0, ratio=None, replacement=False,\n",
            "                   return_indices=False, sampling_strategy=0.6)}\n",
            "ROC-AUC: 0.6953844693161911\n",
            "F1: 0.33445862103763235\n",
            "Accuracy: 0.765853066863268\n",
            "Balanced Accuracy: 0.6095152393170457\n",
            "Loan Loss: -114485.96666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsThZOEB_Zhm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "53817368-1727-4f19-e006-afc8abe6830f"
      },
      "source": [
        "#Best parameters based on loan loss:\n",
        "ind = np.argmin(results_Grid3_NN['rank_test_loan_loss'])\n",
        "print('Parameters:', results_Grid3_NN['params'][ind])\n",
        "print('ROC-AUC:', results_Grid3_NN['mean_test_roc_auc'][ind])\n",
        "print('F1:', results_Grid3_NN['mean_test_f1'][ind])\n",
        "print('Accuracy:', results_Grid3_NN['mean_test_accuracy'][ind])\n",
        "print('Balanced Accuracy:', results_Grid3_NN['mean_test_balanced_accuracy'][ind])\n",
        "print('Loan Loss:', results_Grid3_NN['mean_test_loan_loss'][ind])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters: {'model__batch_size': 1000, 'model__epochs': 75, 'under': RandomUnderSampler(random_state=0, ratio=None, replacement=False,\n",
            "                   return_indices=False, sampling_strategy=0.7)}\n",
            "ROC-AUC: 0.6953253375609237\n",
            "F1: 0.3475188306723995\n",
            "Accuracy: 0.7353731171588599\n",
            "Balanced Accuracy: 0.6227642051630206\n",
            "Loan Loss: -114235.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6quH1TAiAKl",
        "colab_type": "text"
      },
      "source": [
        "# Final NN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QQ42YkfJiQ_U",
        "colab": {}
      },
      "source": [
        "#Setup pipeline.\n",
        "stepsNN = [('under', RandomUnderSampler(random_state=rs, sampling_strategy=0.7)), ('model', KerasClassifier(build_fn=create_model2, verbose=2))]\n",
        "pipelineNN = Pipeline(steps=stepsNN)"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjGCXXi_iUDa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7a04aaaa-818a-4401-b710-f9c3f54612a7"
      },
      "source": [
        "#Train pipeline. Orig\n",
        "pipelineNN.fit(X=dfPostImpute[trainAll], y = trainLabels, model__batch_size = 1000, model__epochs = 75)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "262/262 - 1s - loss: 0.6295 - auc: 0.6769 - accuracy: 0.6405\n",
            "Epoch 2/75\n",
            "262/262 - 1s - loss: 0.6207 - auc: 0.6911 - accuracy: 0.6499\n",
            "Epoch 3/75\n",
            "262/262 - 1s - loss: 0.6195 - auc: 0.6929 - accuracy: 0.6505\n",
            "Epoch 4/75\n",
            "262/262 - 1s - loss: 0.6187 - auc: 0.6941 - accuracy: 0.6521\n",
            "Epoch 5/75\n",
            "262/262 - 1s - loss: 0.6180 - auc: 0.6952 - accuracy: 0.6519\n",
            "Epoch 6/75\n",
            "262/262 - 1s - loss: 0.6172 - auc: 0.6963 - accuracy: 0.6531\n",
            "Epoch 7/75\n",
            "262/262 - 1s - loss: 0.6167 - auc: 0.6972 - accuracy: 0.6530\n",
            "Epoch 8/75\n",
            "262/262 - 1s - loss: 0.6161 - auc: 0.6980 - accuracy: 0.6542\n",
            "Epoch 9/75\n",
            "262/262 - 1s - loss: 0.6156 - auc: 0.6987 - accuracy: 0.6541\n",
            "Epoch 10/75\n",
            "262/262 - 1s - loss: 0.6152 - auc: 0.6993 - accuracy: 0.6551\n",
            "Epoch 11/75\n",
            "262/262 - 1s - loss: 0.6150 - auc: 0.6997 - accuracy: 0.6556\n",
            "Epoch 12/75\n",
            "262/262 - 1s - loss: 0.6147 - auc: 0.7000 - accuracy: 0.6551\n",
            "Epoch 13/75\n",
            "262/262 - 1s - loss: 0.6143 - auc: 0.7006 - accuracy: 0.6560\n",
            "Epoch 14/75\n",
            "262/262 - 1s - loss: 0.6142 - auc: 0.7009 - accuracy: 0.6560\n",
            "Epoch 15/75\n",
            "262/262 - 1s - loss: 0.6140 - auc: 0.7012 - accuracy: 0.6562\n",
            "Epoch 16/75\n",
            "262/262 - 1s - loss: 0.6137 - auc: 0.7016 - accuracy: 0.6563\n",
            "Epoch 17/75\n",
            "262/262 - 1s - loss: 0.6135 - auc: 0.7019 - accuracy: 0.6564\n",
            "Epoch 18/75\n",
            "262/262 - 1s - loss: 0.6133 - auc: 0.7022 - accuracy: 0.6568\n",
            "Epoch 19/75\n",
            "262/262 - 1s - loss: 0.6132 - auc: 0.7024 - accuracy: 0.6571\n",
            "Epoch 20/75\n",
            "262/262 - 1s - loss: 0.6131 - auc: 0.7026 - accuracy: 0.6568\n",
            "Epoch 21/75\n",
            "262/262 - 1s - loss: 0.6129 - auc: 0.7029 - accuracy: 0.6576\n",
            "Epoch 22/75\n",
            "262/262 - 1s - loss: 0.6127 - auc: 0.7031 - accuracy: 0.6572\n",
            "Epoch 23/75\n",
            "262/262 - 1s - loss: 0.6126 - auc: 0.7033 - accuracy: 0.6579\n",
            "Epoch 24/75\n",
            "262/262 - 1s - loss: 0.6124 - auc: 0.7035 - accuracy: 0.6571\n",
            "Epoch 25/75\n",
            "262/262 - 1s - loss: 0.6122 - auc: 0.7038 - accuracy: 0.6584\n",
            "Epoch 26/75\n",
            "262/262 - 1s - loss: 0.6122 - auc: 0.7038 - accuracy: 0.6577\n",
            "Epoch 27/75\n",
            "262/262 - 1s - loss: 0.6120 - auc: 0.7041 - accuracy: 0.6580\n",
            "Epoch 28/75\n",
            "262/262 - 1s - loss: 0.6118 - auc: 0.7044 - accuracy: 0.6584\n",
            "Epoch 29/75\n",
            "262/262 - 1s - loss: 0.6118 - auc: 0.7044 - accuracy: 0.6582\n",
            "Epoch 30/75\n",
            "262/262 - 1s - loss: 0.6117 - auc: 0.7045 - accuracy: 0.6586\n",
            "Epoch 31/75\n",
            "262/262 - 1s - loss: 0.6116 - auc: 0.7048 - accuracy: 0.6592\n",
            "Epoch 32/75\n",
            "262/262 - 1s - loss: 0.6114 - auc: 0.7049 - accuracy: 0.6586\n",
            "Epoch 33/75\n",
            "262/262 - 1s - loss: 0.6113 - auc: 0.7052 - accuracy: 0.6591\n",
            "Epoch 34/75\n",
            "262/262 - 1s - loss: 0.6113 - auc: 0.7051 - accuracy: 0.6588\n",
            "Epoch 35/75\n",
            "262/262 - 1s - loss: 0.6111 - auc: 0.7054 - accuracy: 0.6589\n",
            "Epoch 36/75\n",
            "262/262 - 1s - loss: 0.6111 - auc: 0.7054 - accuracy: 0.6592\n",
            "Epoch 37/75\n",
            "262/262 - 1s - loss: 0.6110 - auc: 0.7056 - accuracy: 0.6588\n",
            "Epoch 38/75\n",
            "262/262 - 1s - loss: 0.6109 - auc: 0.7057 - accuracy: 0.6593\n",
            "Epoch 39/75\n",
            "262/262 - 1s - loss: 0.6108 - auc: 0.7058 - accuracy: 0.6596\n",
            "Epoch 40/75\n",
            "262/262 - 1s - loss: 0.6107 - auc: 0.7059 - accuracy: 0.6595\n",
            "Epoch 41/75\n",
            "262/262 - 1s - loss: 0.6106 - auc: 0.7061 - accuracy: 0.6596\n",
            "Epoch 42/75\n",
            "262/262 - 1s - loss: 0.6105 - auc: 0.7062 - accuracy: 0.6599\n",
            "Epoch 43/75\n",
            "262/262 - 1s - loss: 0.6104 - auc: 0.7063 - accuracy: 0.6593\n",
            "Epoch 44/75\n",
            "262/262 - 1s - loss: 0.6105 - auc: 0.7063 - accuracy: 0.6596\n",
            "Epoch 45/75\n",
            "262/262 - 1s - loss: 0.6103 - auc: 0.7065 - accuracy: 0.6593\n",
            "Epoch 46/75\n",
            "262/262 - 1s - loss: 0.6103 - auc: 0.7065 - accuracy: 0.6596\n",
            "Epoch 47/75\n",
            "262/262 - 1s - loss: 0.6103 - auc: 0.7066 - accuracy: 0.6595\n",
            "Epoch 48/75\n",
            "262/262 - 1s - loss: 0.6102 - auc: 0.7067 - accuracy: 0.6592\n",
            "Epoch 49/75\n",
            "262/262 - 1s - loss: 0.6102 - auc: 0.7067 - accuracy: 0.6601\n",
            "Epoch 50/75\n",
            "262/262 - 1s - loss: 0.6101 - auc: 0.7069 - accuracy: 0.6598\n",
            "Epoch 51/75\n",
            "262/262 - 1s - loss: 0.6099 - auc: 0.7071 - accuracy: 0.6600\n",
            "Epoch 52/75\n",
            "262/262 - 1s - loss: 0.6099 - auc: 0.7071 - accuracy: 0.6605\n",
            "Epoch 53/75\n",
            "262/262 - 1s - loss: 0.6098 - auc: 0.7071 - accuracy: 0.6596\n",
            "Epoch 54/75\n",
            "262/262 - 1s - loss: 0.6098 - auc: 0.7071 - accuracy: 0.6600\n",
            "Epoch 55/75\n",
            "262/262 - 1s - loss: 0.6097 - auc: 0.7073 - accuracy: 0.6602\n",
            "Epoch 56/75\n",
            "262/262 - 1s - loss: 0.6096 - auc: 0.7075 - accuracy: 0.6601\n",
            "Epoch 57/75\n",
            "262/262 - 1s - loss: 0.6096 - auc: 0.7074 - accuracy: 0.6602\n",
            "Epoch 58/75\n",
            "262/262 - 1s - loss: 0.6096 - auc: 0.7075 - accuracy: 0.6600\n",
            "Epoch 59/75\n",
            "262/262 - 1s - loss: 0.6095 - auc: 0.7076 - accuracy: 0.6606\n",
            "Epoch 60/75\n",
            "262/262 - 1s - loss: 0.6094 - auc: 0.7078 - accuracy: 0.6606\n",
            "Epoch 61/75\n",
            "262/262 - 1s - loss: 0.6094 - auc: 0.7079 - accuracy: 0.6609\n",
            "Epoch 62/75\n",
            "262/262 - 1s - loss: 0.6094 - auc: 0.7078 - accuracy: 0.6605\n",
            "Epoch 63/75\n",
            "262/262 - 1s - loss: 0.6093 - auc: 0.7079 - accuracy: 0.6601\n",
            "Epoch 64/75\n",
            "262/262 - 1s - loss: 0.6092 - auc: 0.7080 - accuracy: 0.6609\n",
            "Epoch 65/75\n",
            "262/262 - 1s - loss: 0.6092 - auc: 0.7081 - accuracy: 0.6605\n",
            "Epoch 66/75\n",
            "262/262 - 1s - loss: 0.6091 - auc: 0.7081 - accuracy: 0.6606\n",
            "Epoch 67/75\n",
            "262/262 - 1s - loss: 0.6091 - auc: 0.7082 - accuracy: 0.6607\n",
            "Epoch 68/75\n",
            "262/262 - 1s - loss: 0.6091 - auc: 0.7081 - accuracy: 0.6610\n",
            "Epoch 69/75\n",
            "262/262 - 1s - loss: 0.6090 - auc: 0.7084 - accuracy: 0.6608\n",
            "Epoch 70/75\n",
            "262/262 - 1s - loss: 0.6090 - auc: 0.7084 - accuracy: 0.6613\n",
            "Epoch 71/75\n",
            "262/262 - 1s - loss: 0.6090 - auc: 0.7084 - accuracy: 0.6611\n",
            "Epoch 72/75\n",
            "262/262 - 1s - loss: 0.6088 - auc: 0.7086 - accuracy: 0.6610\n",
            "Epoch 73/75\n",
            "262/262 - 1s - loss: 0.6089 - auc: 0.7085 - accuracy: 0.6614\n",
            "Epoch 74/75\n",
            "262/262 - 1s - loss: 0.6088 - auc: 0.7086 - accuracy: 0.6612\n",
            "Epoch 75/75\n",
            "262/262 - 1s - loss: 0.6087 - auc: 0.7087 - accuracy: 0.6611\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('under',\n",
              "                 RandomUnderSampler(random_state=0, ratio=None,\n",
              "                                    replacement=False, return_indices=False,\n",
              "                                    sampling_strategy=0.7)),\n",
              "                ('model',\n",
              "                 <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7ff5dbe4d5c0>)],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F8HRzOTWkSPO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7c544c70-35d2-4ec1-ba18-0a158b34021e"
      },
      "source": [
        "#Predict class labels\n",
        "y_hat_NN = pipelineNN.predict(dfPostImpute[testAll])"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11429/11429 - 10s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4l5lGfaMkSPe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4b1654c5-4e7b-44d9-e386-95345f5be9e2"
      },
      "source": [
        "#Predict probabilities\n",
        "y_prob_NN = pipelineNN.predict_proba(dfPostImpute[testAll])"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11429/11429 - 10s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "f98F1wFzkSPq",
        "colab": {}
      },
      "source": [
        "#Unpack class labels into an array\n",
        "y_hat_NN = np.array([i[0] for i in y_hat_NN])"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBdVsadVmHSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a series with predictions.\n",
        "resultsNN = {'id': dfFinal[testAll].id.values, 'true_class': testLabels, 'predict_class_NN': y_hat_NN, \n",
        "                 'prob_NN':y_prob_NN[:,1]}"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jldHr9rymdns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert series with predictions to dataframe.\n",
        "df_Results_NN = pd.DataFrame(resultsNN)"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EODxeA5MA-bu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save dataframe to csv file.\n",
        "df_Results_NN.to_csv('results_NN_New.csv')"
      ],
      "execution_count": 148,
      "outputs": []
    }
  ]
}